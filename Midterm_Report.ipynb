{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Prediction Models - Midterm Report\n",
    "## Kevin Yang, Eric Lee, Derek Young\n",
    "\n",
    "Our main goal is to build prediction models for NBA team performance. As a first step, we will scrape data from `stats.nba.com` and store relevant data in a local `sqlite` database.\n",
    "\n",
    "On a broad level, we have decided to focus our project on predicting the outcome of a given nba game. On a high level, our approach will involve determining the most important features in determining game outcomes, and then training a supervised machine learning model on these features over many previous games. There should be certain nuances that we should be careful to account for when modeling nba games. One of these is injuries. We need to find some way of determining the effect that an injured player will have on the result of a game.\n",
    "\n",
    "In this deliverable, we will focus on data collection and understanding the data. We have provided snippets of code to demonstrate some of the work we have done. \n",
    "\n",
    "We will first write a simple scraping function to get player game logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "# Use svg backend for better quality\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_player_gamelogs(player_id, season):\n",
    "    \"\"\" Given a player id (int or string) and a season (string, ex: 2016-17), returns a (header, log_list) where the\n",
    "        header represents a key describing the format of a log in log list\n",
    "    Input:\n",
    "        player_id (int or string): player ID number\n",
    "        season (str): season string, ex: 2016-17\n",
    "    Output:\n",
    "        (header, log_list): header is a key describing the format of a log in log list\n",
    "    \"\"\"\n",
    "    \n",
    "    player_url = (\"http://stats.nba.com/stats/playergamelog?DateFrom=&DateTo=&LeagueID=00&PlayerID=\" \n",
    "                  + str(player_id) + \"&Season=\" + season + \"&SeasonType=Regular+Season\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:39.0) Gecko/20100101 Firefox/39.0'}\n",
    "    \n",
    "    # request the URL and parse the JSON\n",
    "    response = requests.get(player_url, headers = headers)\n",
    "    response.raise_for_status() # raise exception if invalid response\n",
    "    response_json = response.json()\n",
    "    log_list = response_json['resultSets'][0]['rowSet']\n",
    "    header = response_json['resultSets'][0]['headers']\n",
    "    \n",
    "    return (header, log_list)\n",
    "\n",
    "def convert_to_df(header, log_list):\n",
    "    \"\"\" Given a header and a log_list, where header is a key describing the format of a log in log list and log_list\n",
    "    contains a list of game logs, convert_to_dataframe returns this data in dataframe form\n",
    "    Input:\n",
    "        header (list): list of column labels\n",
    "        log_list (list): 2D list containing game logs \n",
    "    Output:\n",
    "        (pd.DataFrame): DataFrame containig the given data\n",
    "    \"\"\"\n",
    "    index = np.arange(1, len(log_list) + 1)\n",
    "    df = pd.DataFrame(index = index, columns = header)\n",
    "    \n",
    "    logs = np.array(log_list)\n",
    "    logs_transpose = logs.T\n",
    "    \n",
    "    for i in xrange(len(header)):\n",
    "        curr_header = header[i]\n",
    "        df[curr_header] = logs_transpose[i]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "#jeremy lin\n",
    "player_id = 202391\n",
    "season = \"2016-17\"\n",
    "\n",
    "(header, plog_list) = get_player_gamelogs(player_id, season) \n",
    "\n",
    "player_df = convert_to_df(header, plog_list)\n",
    "\n",
    "print player_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that extracts player game logs, we might be interested in understanding the importance of thhese player statistics as a predictor for team wins or losses. We can create some bar charts comparing player statistics in wins or losses. \n",
    "\n",
    "Additionally, instead of treating wins and losses as binary variables, we can also consider the relationship between player statistics and the point differential in any given game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_player_wl(player_id, season):\n",
    "    \"\"\" Given a player id (int or string) and a season (string, ex: 2016-17), displays graphs comparing the players\n",
    "    performance in wins and losses\n",
    "    Input:\n",
    "        player_id (int or string): player ID number\n",
    "        season (str): season string, ex: 2016-17\n",
    "    Output:\n",
    "        (header, log_list): header is a key describing the format of a log in log list\n",
    "    \"\"\"\n",
    "    \n",
    "    (headers, log_list) = get_player_gamelogs(player_id, season)\n",
    "    \n",
    "    df = convert_to_df(headers, log_list)\n",
    "    \n",
    "    # get rows corresponding to wins / losses\n",
    "    df_w = df[df['WL'] == 'W']\n",
    "    df_l = df[df['WL'] == 'L']\n",
    "    \n",
    "    # get numerical columns\n",
    "    num_list = ['MIN','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB',\n",
    "                  'AST','STL','BLK','TOV','PF','PTS','PLUS_MINUS']\n",
    "    \n",
    "    # get numerical columns\n",
    "    w_num = df_w.loc[:,['MIN','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB',\n",
    "                  'AST','STL','BLK','TOV','PF','PTS','PLUS_MINUS']]\n",
    "    l_num = df_l.loc[:,['MIN','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB',\n",
    "                  'AST','STL','BLK','TOV','PF','PTS','PLUS_MINUS']]\n",
    "    \n",
    "    w_mean_list = []\n",
    "    w_std_list = []\n",
    "    l_mean_list = []\n",
    "    l_std_list = []\n",
    "    \n",
    "    for i in num_list:\n",
    "        w_float_list = w_num[i].values.astype(float)\n",
    "        l_float_list = l_num[i].values.astype(float)\n",
    "        w_mean_list.append(w_float_list.mean())\n",
    "        l_mean_list.append(l_float_list.mean())\n",
    "        w_std_list.append(w_float_list.std())\n",
    "        l_std_list.append(l_float_list.std())\n",
    "    \n",
    "    n_groups = 20\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = .35\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    rects1 = plt.bar(index, w_mean_list, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='b',\n",
    "                     yerr=w_std_list,\n",
    "                     error_kw=error_config,\n",
    "                     label='Wins')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, l_mean_list, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='r',\n",
    "                     yerr=l_std_list,\n",
    "                     error_kw=error_config,\n",
    "                     label='Losses')\n",
    "\n",
    "\n",
    "    plt.xlabel('Player Stats')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Comparing Player Stats in Wins and Losses')\n",
    "    #plt.xticks(index + bar_width, ('A', 'B', 'C', 'D', 'E'))\n",
    "    plt.xticks(index + bar_width, num_list)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# jeremy lin\n",
    "# player_id = 202391\n",
    "# season = \"2016-17\"\n",
    "\n",
    "#lebron james\n",
    "player_id = 2544\n",
    "season = \"2015-16\"\n",
    "display_player_wl(player_id, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is especially interesting because it demonstrates that the performance of a player (in this case, Lebron James) in a given game does not necessarily correlate with more wins. For example, on average Lebron gets more rebounds and (slightly) more points in losses. This is likely because in many wins the games might have been blowout games, so then Lebron would have played less. To account for this, we might wish to analyze the distribution of certain stats depending on the final point differential. To find this, we will work on creating a database of game IDs.\n",
    "\n",
    "While creating this database of game IDs, we are also creating a database of team specific data. The team specific data is important because we suspect that many features that can be extracted from team data would be predictive for game resuls. These team-specific features, along with some player-specfic features, will be used in a supervised learning model to predict the result of an NBA game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_league_gamelogs(season):\n",
    "    \"\"\" Given a season (string, ex: 2016-17), returns a (header, log_list) where the\n",
    "        header represents a key describing the format of a log in log list\n",
    "    Input:\n",
    "        season (str): season string, ex: 2016-17\n",
    "    Output:\n",
    "        (header, log_list): header is a key describing the format of a log in log list\n",
    "    \"\"\"\n",
    "    league_log_url = (\"http://stats.nba.com/stats/leaguegamelog?Counter=1000&DateFrom=&DateTo=&\" + \n",
    "                  \"Direction=DESC&LeagueID=00&PlayerOrTeam=T&Season=\" + str(season) + \n",
    "                  \"&SeasonType=Regular+Season&Sorter=PTS\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:39.0) Gecko/20100101 Firefox/39.0'}\n",
    "\n",
    "    # request the URL and parse the JSON\n",
    "    response = requests.get(league_log_url, headers = headers)\n",
    "    response.raise_for_status() # raise exception if invalid response\n",
    "    response_json = response.json()\n",
    "    log_list = response_json['resultSets'][0]['rowSet']\n",
    "    header = response_json['resultSets'][0]['headers']\n",
    "    \n",
    "    return (header, log_list)\n",
    "\n",
    "def generate_year_list(start, yrs):\n",
    "    \"\"\" Generate a year list to pass into load_all_gamlogs\n",
    "    Input:\n",
    "        start (int): The first year we are interested in loading\n",
    "        yrs (int): How many years since start that we are including\n",
    "    Output:\n",
    "        (List): List of years\n",
    "    \"\"\"\n",
    "    year_list = []\n",
    "    curr_yr = start\n",
    "    for i in xrange(yrs):\n",
    "        nextyr = curr_yr + 1 \n",
    "        year_list.append(str(curr_yr)+\"-\"+str(nextyr)[2:])\n",
    "        curr_yr = nextyr\n",
    "    return year_list\n",
    "    \n",
    "def load_all_gamelogs(conn, start, yrs):\n",
    "    \"\"\" Load nba gamelog data for the past yrs years as a games tables into an SQLite database given in conn\n",
    "    Input:\n",
    "        conn (sqlite3.Connection): Connection object corresponding to the database; used to perform SQL commands.\n",
    "        yrs (int): Number of years to include in table\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    year_list = generate_year_list(start,yrs) #['2010-11', '2011-12', '2012-13', '2013-14', '2015-16', '2016-17']\n",
    "    \n",
    "    # clear league_log table\n",
    "    cursor.execute('drop table if exists league_log')\n",
    "    \n",
    "    # create big table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS league_log (\n",
    "    season_id TEXT, \n",
    "    team_id INTEGER,\n",
    "    team_abbreviation TEXT,\n",
    "    team_name TEXT,\n",
    "    game_id INTEGER,\n",
    "    game_date INTEGER,\n",
    "    matchup INTEGER,\n",
    "    wl STRING,\n",
    "    min INTEGER,\n",
    "    fgm INTEGER,\n",
    "    fga INTEGER,\n",
    "    fg_pct REAL,\n",
    "    fg3m INTEGER,\n",
    "    fg3a INTEGER,\n",
    "    fg3_pct REAL,\n",
    "    ftm INTEGER,\n",
    "    fta INTEGER,\n",
    "    ft_pct REAL,\n",
    "    oreb INTEGER,\n",
    "    dreb INTEGER,\n",
    "    reb INTEGER,\n",
    "    ast INTEGER,\n",
    "    stl INTEGER,\n",
    "    blk INTEGER,\n",
    "    tov INTEGER,\n",
    "    pf INTEGER,\n",
    "    pts INTEGER,\n",
    "    plus_minus INTEGER\n",
    "    )\"\"\")\n",
    "    \n",
    "    for year in year_list:\n",
    "        (header, log_list) = get_league_gamelogs(year)\n",
    "        \n",
    "        question_marks = \"(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ,?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        query_string = \"INSERT INTO league_log VALUES \" + question_marks\n",
    "        for log in log_list:\n",
    "            cursor.execute(query_string,\n",
    "                          (log[0],log[1],log[2],log[3],log[4],log[5],log[6],log[7],\n",
    "                          log[8], log[9], log[10], log[11], log[12], log[13], log[14],\n",
    "                          log[15],log[16], log[17], log[18], log[19], log[20], log[21],\n",
    "                          log[22], log[23], log[24], log[25], log[26], log[27]))\n",
    "            \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(r\"db/league.db\")\n",
    "conn.text_factory = str\n",
    "\n",
    "start_year = 1946\n",
    "length = 2017 - start_year\n",
    "\n",
    "# TEST SET WILL BE SEASON 2015-16 + 2016-17??\n",
    "# WHAT SHOULD TRAINING SET AND VALIDATION SET BE?\n",
    "\n",
    "#print generate_year_list(start_year,length)\n",
    "#load_all_gamelogs(conn, start_year, length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113790\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>matchup</th>\n",
       "      <th>wl</th>\n",
       "      <th>min</th>\n",
       "      <th>fgm</th>\n",
       "      <th>...</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>plus_minus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600208</td>\n",
       "      <td>1947-02-06</td>\n",
       "      <td>CHS vs. PIT</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>109</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600284</td>\n",
       "      <td>1947-03-09</td>\n",
       "      <td>CHS @ CLR</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>107</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600280</td>\n",
       "      <td>1947-03-08</td>\n",
       "      <td>CHS vs. PRO</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610036</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Capitols</td>\n",
       "      <td>24600199</td>\n",
       "      <td>1947-02-02</td>\n",
       "      <td>WAS @ CLR</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610036</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Capitols</td>\n",
       "      <td>24600320</td>\n",
       "      <td>1947-03-26</td>\n",
       "      <td>WAS vs. CHS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>105</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season_id     team_id team_abbreviation            team_name   game_id  \\\n",
       "0     21946  1610610025               CHS        Chicago Stags  24600208   \n",
       "1     21946  1610610025               CHS        Chicago Stags  24600284   \n",
       "2     21946  1610610025               CHS        Chicago Stags  24600280   \n",
       "3     21946  1610610036               WAS  Washington Capitols  24600199   \n",
       "4     21946  1610610036               WAS  Washington Capitols  24600320   \n",
       "\n",
       "    game_date      matchup wl  min   fgm     ...      oreb  dreb  reb  ast  \\\n",
       "0  1947-02-06  CHS vs. PIT  W    0  48.0     ...       NaN   NaN  NaN  NaN   \n",
       "1  1947-03-09    CHS @ CLR  W    0  36.0     ...       NaN   NaN  NaN  NaN   \n",
       "2  1947-03-08  CHS vs. PRO  W    0  43.0     ...       NaN   NaN  NaN  NaN   \n",
       "3  1947-02-02    WAS @ CLR  W    0  43.0     ...       NaN   NaN  NaN  NaN   \n",
       "4  1947-03-26  WAS vs. CHS  W    0  42.0     ...       NaN   NaN  NaN  NaN   \n",
       "\n",
       "   stl  blk  tov    pf  pts  plus_minus  \n",
       "0  NaN  NaN  NaN  28.0  109          24  \n",
       "1  NaN  NaN  NaN  27.0  107          30  \n",
       "2  NaN  NaN  NaN  33.0  107          26  \n",
       "3  NaN  NaN  NaN  15.0  107          26  \n",
       "4  NaN  NaN  NaN  16.0  105          28  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_df = pd.read_sql_query('SELECT * FROM league_log', conn)\n",
    "print len(league_df)\n",
    "league_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded some league game logs into our database `league.db`. We can now write some data validation functions for our data, as we might be missing certain games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    year_list = df['season_id'].unique().tolist()\n",
    "    \n",
    "    for year in year_list:\n",
    "        df_temp = df[df['season_id'] == year]\n",
    "        \n",
    "        if year == '22011':\n",
    "            # lockout year\n",
    "            assert(df_temp.shape[0] == 1980)\n",
    "        elif year == '22016':\n",
    "            # current ongoing year\n",
    "            continue\n",
    "        else:\n",
    "            #normal 82 game sched\n",
    "            assert(df_temp.shape[0] == 2460) \n",
    "        \n",
    "#validate_data(league_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Understanding the Data\n",
    "Now that we have stored key data points on each game, we wish to process the data to describe key features of our data, and then better understand these features through analyses and visualizations.\n",
    "\n",
    "We first want to create a large league df with extra features, including the following:\n",
    "1. Home W/L Percentage\n",
    "2. Away W/L Percentage\n",
    "3. Home Average Point Differential\n",
    "4. Away Average Point Differential\n",
    "5. Home W/L Percentage in Previous 8 Games\n",
    "6. Away W/L Percentage in Previous 8 Games\n",
    "7. Away W/L Percentage as Away Team\n",
    "8. Home W/L Percentage as Home Team\n",
    "9. Indicator whether the team is on a back-to-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>matchup</th>\n",
       "      <th>wl</th>\n",
       "      <th>min</th>\n",
       "      <th>fgm</th>\n",
       "      <th>...</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>is_home</th>\n",
       "      <th>opp_team_id</th>\n",
       "      <th>wl_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600208</td>\n",
       "      <td>1947-02-06</td>\n",
       "      <td>CHS vs. PIT</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>109</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1610610031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600284</td>\n",
       "      <td>1947-03-09</td>\n",
       "      <td>CHS @ CLR</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>107</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600280</td>\n",
       "      <td>1947-03-08</td>\n",
       "      <td>CHS vs. PRO</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1610610032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610036</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Capitols</td>\n",
       "      <td>24600199</td>\n",
       "      <td>1947-02-02</td>\n",
       "      <td>WAS @ CLR</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610036</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Capitols</td>\n",
       "      <td>24600320</td>\n",
       "      <td>1947-03-26</td>\n",
       "      <td>WAS vs. CHS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>105</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>PHW</td>\n",
       "      <td>Philadelphia Warriors</td>\n",
       "      <td>24600157</td>\n",
       "      <td>1947-01-14</td>\n",
       "      <td>PHW @ HUS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>PHW</td>\n",
       "      <td>Philadelphia Warriors</td>\n",
       "      <td>24600310</td>\n",
       "      <td>1947-03-22</td>\n",
       "      <td>PHW @ PRO</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610034</td>\n",
       "      <td>BOM</td>\n",
       "      <td>St. Louis Bombers</td>\n",
       "      <td>24600129</td>\n",
       "      <td>1947-01-01</td>\n",
       "      <td>BOM @ CHS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>103</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600221</td>\n",
       "      <td>1947-02-12</td>\n",
       "      <td>CHS @ PIT</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>24600309</td>\n",
       "      <td>1947-03-21</td>\n",
       "      <td>CHS @ HUS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>99</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1610610035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season_id     team_id team_abbreviation              team_name   game_id  \\\n",
       "0     21946  1610610025               CHS          Chicago Stags  24600208   \n",
       "1     21946  1610610025               CHS          Chicago Stags  24600284   \n",
       "2     21946  1610610025               CHS          Chicago Stags  24600280   \n",
       "3     21946  1610610036               WAS    Washington Capitols  24600199   \n",
       "4     21946  1610610036               WAS    Washington Capitols  24600320   \n",
       "5     21946  1610612744               PHW  Philadelphia Warriors  24600157   \n",
       "6     21946  1610612744               PHW  Philadelphia Warriors  24600310   \n",
       "7     21946  1610610034               BOM      St. Louis Bombers  24600129   \n",
       "8     21946  1610610025               CHS          Chicago Stags  24600221   \n",
       "9     21946  1610610025               CHS          Chicago Stags  24600309   \n",
       "\n",
       "   game_date      matchup wl  min   fgm    ...      ast  stl  blk  tov    pf  \\\n",
       "0 1947-02-06  CHS vs. PIT  W    0  48.0    ...      NaN  NaN  NaN  NaN  28.0   \n",
       "1 1947-03-09    CHS @ CLR  W    0  36.0    ...      NaN  NaN  NaN  NaN  27.0   \n",
       "2 1947-03-08  CHS vs. PRO  W    0  43.0    ...      NaN  NaN  NaN  NaN  33.0   \n",
       "3 1947-02-02    WAS @ CLR  W    0  43.0    ...      NaN  NaN  NaN  NaN  15.0   \n",
       "4 1947-03-26  WAS vs. CHS  W    0  42.0    ...      NaN  NaN  NaN  NaN  16.0   \n",
       "5 1947-01-14    PHW @ HUS  W    0  44.0    ...      NaN  NaN  NaN  NaN   NaN   \n",
       "6 1947-03-22    PHW @ PRO  W    0  35.0    ...      NaN  NaN  NaN  NaN   NaN   \n",
       "7 1947-01-01    BOM @ CHS  W    0  39.0    ...      NaN  NaN  NaN  NaN  29.0   \n",
       "8 1947-02-12    CHS @ PIT  W    0  40.0    ...      NaN  NaN  NaN  NaN   NaN   \n",
       "9 1947-03-21    CHS @ HUS  W    0  43.0    ...      NaN  NaN  NaN  NaN  24.0   \n",
       "\n",
       "   pts  plus_minus  is_home  opp_team_id  wl_binary  \n",
       "0  109          24        1   1610610031          1  \n",
       "1  107          30        0   1610610026          1  \n",
       "2  107          26        1   1610610032          1  \n",
       "3  107          26        0   1610610026          1  \n",
       "4  105          28        1   1610610025          1  \n",
       "5  104          30        0   1610610035          1  \n",
       "6  103          21        0   1610610032          1  \n",
       "7  103          13        0   1610610025          1  \n",
       "8  101          19        0   1610610031          1  \n",
       "9   99          16        0   1610610035          1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(league_df):\n",
    "    \"\"\" Given a dataframe league_df, returns new league_df by converting the 'game_date' column to datetime if \n",
    "    necessary, and adds is_home indicator and opp_team_id indicator\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing league logs\n",
    "    Output:\n",
    "        pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # convert to datetime, note this is in place!\n",
    "    league_df['game_date'] = league_df['game_date'].apply(pd.to_datetime)\n",
    "    \n",
    "    # add new columns\n",
    "    is_home = np.zeros(len(league_df), dtype=np.int64)\n",
    "    opp_team_id = np.zeros(len(league_df), dtype=np.int64)\n",
    "    wl_binary = np.zeros(len(league_df), dtype = np.int64)\n",
    "    \n",
    "    \n",
    "    league_df = league_df.assign(is_home = is_home)\n",
    "    league_df = league_df.assign(opp_team_id = opp_team_id)\n",
    "    league_df = league_df.assign(wl_binary = wl_binary)\n",
    "    \n",
    "    \n",
    "    # add home indicator variable\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        matchup = row['matchup']\n",
    "        if \"@\" in matchup:\n",
    "            league_df.set_value(index, \"is_home\", 0)\n",
    "        else:\n",
    "            league_df.set_value(index, \"is_home\", 1)\n",
    "            \n",
    "    # add opposing team ID\n",
    "    for (index,row) in league_df.iterrows():\n",
    "        game_id = row['game_id']\n",
    "        team_id = row['team_id']\n",
    "        \n",
    "        # find other game with the same game ID\n",
    "        df_game = league_df[league_df['game_id'] == game_id]\n",
    "        assert(len(df_game) == 2)\n",
    "        found_opp = False\n",
    "        for (inner_index,inner_row) in df_game.iterrows():\n",
    "            curr_team_id = inner_row['team_id']\n",
    "            if curr_team_id == team_id:\n",
    "                continue\n",
    "            else:\n",
    "                # found opposing team, update opposing team ID\n",
    "                league_df.set_value(index, 'opp_team_id', curr_team_id)\n",
    "                found_opp = True\n",
    "        assert(found_opp)\n",
    "        \n",
    "    # add binary representation of wins and losses\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        wl = row['wl']\n",
    "        if wl == 'W':\n",
    "            league_df.set_value(index, 'wl_binary', 1)\n",
    "        else:\n",
    "            league_df.set_value(index, 'wl_binary', 0)\n",
    "    \n",
    "    return league_df\n",
    "league_df = preprocess(league_df)\n",
    "league_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df1 = league_df.sort_values('game_date')\n",
    "new_df1[new_df1[\"team_abbreviation\"] == \"DAL\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Detroit, Michigan': (42.3486635, -83.0567374), 'Houston, Texas': (29.7589382, -95.3676973), 'Charlotte, North Carolina': (35.2270869, -80.8431267), 'Minneapolis, Minnesota': (44.9772995, -93.2654691), 'Orlando, Florida': (28.5421175, -81.3790461), 'Philadelphia, Pennsylvania': (39.9523993, -75.1635898), 'Cleveland, Ohio': (41.5051613, -81.6934445), 'Dallas, Texas': (32.7762719, -96.7968558), 'Memphis, Tennessee': (35.1490215, -90.0516284), 'Salt Lake City, Utah': (40.7670126, -111.8904307), 'Newark, New Jersey': (40.735657, -74.1723666), 'Portland, Oregon': (45.5202471, -122.6741948), 'Boston, Massachusetts': (42.3604823, -71.0595677), 'Toronto, Ontario': (43.6529206, -79.3849007), 'Seattle, Washington': (47.6038321, -122.3300623), 'Denver, Colorado': (39.7391536, -104.9847033), 'Sacramento, California': (38.5815719, -121.4943995), 'Washington D.C., Virginia': (38.8927292, -77.0419093), 'Chicago, Illinois': (41.8755546, -87.6244211), 'Oakland, California': (37.8044557, -122.2713562), 'Brooklyn, New York': (40.6501038, -73.9495822), 'New York City, New York': (40.7305991, -73.9865811), 'Oklahoma City, Oklahoma': (35.4729886, -97.5170535), 'San Antonio, Texas': (29.4246002, -98.4951404), 'Miami, Florida': (25.7742658, -80.1936588), 'Indianapolis, Indiana': (39.7683331, -86.1583501), 'Phoenix, Arizona': (33.4485866, -112.0773455), 'Milwaukee, Wisconsin': (43.0349931, -87.9224969), 'Atlanta, Georgia': (33.7490987, -84.3901848), 'Los Angeles, California': (34.0543942, -118.2439408), 'New Orleans, Louisiana': (29.9499323, -90.0701155)}\n"
     ]
    }
   ],
   "source": [
    "# LOCATION RELATED STUFF\n",
    "\n",
    "# set base year\n",
    "temp_df_1 = league_df[league_df['season_id'] >= '22005']\n",
    "team_names = temp_df_1['team_name'].unique().tolist()\n",
    "#print len(team_names), team_names\n",
    "\n",
    "team_id_list = temp_df_1['team_id'].unique().tolist()\n",
    "#print len(team_id_list), team_id_list\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Orleans/Oklahoma City Hornets']\n",
    "no_okc_seasons = temp_df['season_id'].unique().tolist()\n",
    "#print \"NO_OKC\", no_okc_seasons\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Charlotte Bobcats']\n",
    "bobcats = temp_df['season_id'].unique().tolist()\n",
    "#print \"BOB\", bobcats\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Jersey Nets']\n",
    "nj = temp_df['season_id'].unique().tolist()\n",
    "#print \"NJ\", nj\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Seattle SuperSonics']\n",
    "seattle = temp_df['season_id'].unique().tolist()\n",
    "#print \"SUPER\", seattle\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Orleans Hornets']\n",
    "noh = temp_df['season_id'].unique().tolist()\n",
    "#print \"NOH\", noh\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Oklahoma City Thunder']\n",
    "thunder = temp_df['season_id'].unique().tolist()\n",
    "#print \"THUNDER\", thunder\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Brooklyn Nets']\n",
    "bkn = temp_df['season_id'].unique().tolist()\n",
    "#print \"BKN\", bkn\n",
    "\n",
    "# dictionary mapping of team_id to team_names?\n",
    "id_team = dict()\n",
    "for team_id in team_id_list:\n",
    "    temp_df = temp_df_1[temp_df_1['team_id'] == team_id]\n",
    "    id_team[team_id] = temp_df['team_name'].unique().tolist()\n",
    "#print id_team\n",
    "\n",
    "# dictionary mapping of team_name to seasons\n",
    "team_seasons = dict()\n",
    "for team_name in team_names:\n",
    "    temp_df = temp_df_1[temp_df_1['team_name'] == team_name]\n",
    "    team_seasons[team_name] = temp_df['season_id'].unique().tolist()\n",
    "#print team_seasons\n",
    "\n",
    "# sanity check\n",
    "for team_id in team_id_list:\n",
    "    names = id_team[team_id]\n",
    "    if len(names) == 0:\n",
    "        raise Fail(\"no names for ID\")\n",
    "    elif len(names) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        season_list = []\n",
    "        for name in names:\n",
    "            seasons = team_seasons[name]\n",
    "            season_list.append(seasons)\n",
    "            \n",
    "        common_years = list(reduce(set.intersection, map(set, season_list)))\n",
    "        #print len(common_years), names, common_years\n",
    "        assert(len(common_years) == 0)\n",
    "            \n",
    "# ['Dallas Mavericks', 'New Orleans/Oklahoma City Hornets', 'Milwaukee Bucks', 'San Antonio Spurs', \n",
    "#  'Philadelphia 76ers', 'Phoenix Suns', 'Denver Nuggets', 'Sacramento Kings', 'Atlanta Hawks', 'Miami Heat', \n",
    "#  'Toronto Raptors', 'New Jersey Nets', 'Houston Rockets', 'Boston Celtics', 'Golden State Warriors', \n",
    "#  'Utah Jazz', 'Seattle SuperSonics', 'Portland Trail Blazers', 'Indiana Pacers', 'Minnesota Timberwolves', \n",
    "#  'Washington Wizards', 'Chicago Bulls', 'New York Knicks', 'Cleveland Cavaliers', 'Charlotte Bobcats', \n",
    "#  'Detroit Pistons', 'Memphis Grizzlies', 'Orlando Magic', 'Los Angeles Clippers', 'Los Angeles Lakers', \n",
    "#  'New Orleans Hornets', 'Oklahoma City Thunder', 'Brooklyn Nets', 'New Orleans Pelicans', 'Charlotte Hornets', \n",
    "#  'LA Clippers']\n",
    "\n",
    "name_location = {'Dallas Mavericks': 'Dallas, Texas',\n",
    "                'New Orleans/Oklahoma City Hornets': 'Oklahoma City, Oklahoma',\n",
    "                'Milwaukee Bucks': 'Milwaukee, Wisconsin',\n",
    "                'San Antonio Spurs': 'San Antonio, Texas',\n",
    "                'Philadelphia 76ers': 'Philadelphia, Pennsylvania',\n",
    "                'Phoenix Suns': 'Phoenix, Arizona',\n",
    "                'Denver Nuggets': 'Denver, Colorado',\n",
    "                'Sacramento Kings': 'Sacramento, California',\n",
    "                'Atlanta Hawks': 'Atlanta, Georgia',\n",
    "                'Miami Heat' : 'Miami, Florida', \n",
    "                'Toronto Raptors': 'Toronto, Ontario', \n",
    "                'New Jersey Nets': 'Newark, New Jersey', \n",
    "                'Houston Rockets': 'Houston, Texas', \n",
    "                'Boston Celtics': 'Boston, Massachusetts', \n",
    "                'Golden State Warriors' : 'Oakland, California', \n",
    "                'Utah Jazz': 'Salt Lake City, Utah', \n",
    "                'Seattle SuperSonics' : 'Seattle, Washington', \n",
    "                'Portland Trail Blazers': 'Portland, Oregon', \n",
    "                'Indiana Pacers' : 'Indianapolis, Indiana', \n",
    "                'Minnesota Timberwolves' : 'Minneapolis, Minnesota', \n",
    "                'Washington Wizards': 'Washington D.C., Virginia',\n",
    "                'Chicago Bulls' : 'Chicago, Illinois', \n",
    "                'New York Knicks': 'New York City, New York', \n",
    "                'Cleveland Cavaliers' : 'Cleveland, Ohio', \n",
    "                'Charlotte Bobcats' : 'Charlotte, North Carolina',\n",
    "                'Detroit Pistons' : 'Detroit, Michigan', \n",
    "                'Memphis Grizzlies' : 'Memphis, Tennessee', \n",
    "                'Orlando Magic' : 'Orlando, Florida', \n",
    "                'Los Angeles Clippers' : 'Los Angeles, California', \n",
    "                'Los Angeles Lakers' : 'Los Angeles, California', \n",
    "                'New Orleans Hornets' : 'New Orleans, Louisiana', \n",
    "                'Oklahoma City Thunder': 'Oklahoma City, Oklahoma', \n",
    "                'Brooklyn Nets': 'Brooklyn, New York', \n",
    "                'New Orleans Pelicans' : 'New Orleans, Louisiana', \n",
    "                'Charlotte Hornets' : 'Charlotte, North Carolina', \n",
    "                'LA Clippers' : 'Los Angeles, California'}\n",
    "\n",
    "location_latlong = dict()\n",
    "\n",
    "geolocator = Nominatim()\n",
    "\n",
    "for key,value in name_location.iteritems():\n",
    "    geo_loc = geolocator.geocode(value)\n",
    "    (lat1, long1) = (geo_loc.latitude, geo_loc.longitude)\n",
    "    location_latlong[value] = (lat1,long1)\n",
    "\n",
    "print location_latlong\n",
    "\n",
    "def get_team_location(team_id, season_id):\n",
    "    \"\"\" Given a team id and the season_id, returns a string containing the location of the team stadium\n",
    "    Input: \n",
    "        team_id (int): team id\n",
    "        season_id (str): season id \n",
    "    Output:\n",
    "        (str) \n",
    "    \"\"\"\n",
    "    names = id_team[team_id]\n",
    "    \n",
    "    team_name = None\n",
    "    \n",
    "    for name in names:\n",
    "        seasons = team_seasons[name]\n",
    "        #print seasons, name\n",
    "        if season_id in seasons:\n",
    "            team_name = name\n",
    "            \n",
    "    if team_name == None:\n",
    "        print (team_id, season_id, names)\n",
    "        assert(False)\n",
    "    \n",
    "    return name_location[team_name]\n",
    "\n",
    "location = get_team_location(1610612742, '22015')\n",
    "location1 = get_team_location(1610612749, '22015')\n",
    "\n",
    "#print location, location1\n",
    "\n",
    "# geolocator = Nominatim()\n",
    "# geo_loc = geolocator.geocode(location)\n",
    "\n",
    "# (lat1, long1) = (geo_loc.latitude, geo_loc.longitude)\n",
    "\n",
    "# geo_loc1 = geolocator.geocode(location1)\n",
    "\n",
    "# (lat2, long2) = (geo_loc1.latitude, geo_loc1.longitude)\n",
    "\n",
    "#print vincenty((lat1,long1), (lat2,long2)).miles\n",
    "    \n",
    "#print Geocoder.geocode(location).valid_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_extra_features(league_df, new_years = False):\n",
    "    \"\"\" Given a dataframe league_df, returns a new df containing extra columns for each new feature.\n",
    "        If new_years = true, adds features that only work for data frames containing data >= 2005\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        new_years (bool): if the dataframe contains only data >= 2005\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    geolocator = Nominatim()\n",
    "    \n",
    "    seen_distances = dict()\n",
    "    \n",
    "    lookback = 8\n",
    "\n",
    "    #print league_df['game_date'].dtype\n",
    "    \n",
    "    #converted_row = pd.to_datetime(league_df['game_date'])\n",
    "    #print league_df['game_date'].dtype\n",
    "    \n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    \n",
    "    # add new columns\n",
    "    home_win_pct = np.zeros(len(new_df))\n",
    "    away_win_pct = np.zeros(len(new_df))\n",
    "    home_avg_pt_diff = np.zeros(len(new_df))\n",
    "    away_avg_pt_diff = np.zeros(len(new_df))\n",
    "    home_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_as_away = np.zeros(len(new_df))\n",
    "    home_win_pct_as_home = np.zeros(len(new_df))\n",
    "    home_back_to_back = np.zeros(len(new_df))\n",
    "    away_back_to_back = np.zeros(len(new_df))\n",
    "    home_game_count = np.zeros(len(new_df))\n",
    "    away_game_count = np.zeros(len(new_df))\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    new_df = new_df.assign(home_win_pct = home_win_pct)\n",
    "    new_df = new_df.assign(away_win_pct = away_win_pct)\n",
    "    new_df = new_df.assign(home_avg_pt_diff = home_avg_pt_diff)\n",
    "    new_df = new_df.assign(away_avg_pt_diff = away_avg_pt_diff)\n",
    "    new_df = new_df.assign(home_win_pct_N = home_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_N = away_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_as_away = away_win_pct_as_away)\n",
    "    new_df = new_df.assign(home_win_pct_as_home = home_win_pct_as_home)\n",
    "    new_df = new_df.assign(home_back_to_back = home_back_to_back)\n",
    "    new_df = new_df.assign(away_back_to_back = away_back_to_back)\n",
    "    new_df = new_df.assign(home_game_count = home_game_count)\n",
    "    new_df = new_df.assign(away_game_count = away_game_count)\n",
    "    \n",
    "    if (new_years):\n",
    "        new_df = new_df.assign(home_mileage = home_mileage)\n",
    "        new_df = new_df.assign(away_mileage = away_mileage)\n",
    "    \n",
    "    # add features\n",
    "    grouped = new_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        # initialize dictionary containing wins and losses for each team\n",
    "        win_dict = dict()\n",
    "        lose_dict = dict()\n",
    "        running_dict = dict()\n",
    "        \n",
    "        # stores list of game dates for each team\n",
    "        running_date_dict = dict()\n",
    "        \n",
    "        # total plus minus so far\n",
    "        plus_minus_dict = dict()\n",
    "        \n",
    "        # stores home and away game counts and w/l counts\n",
    "        wins_as_home = dict()\n",
    "        wins_as_away = dict()\n",
    "        games_as_home = dict()\n",
    "        games_as_away = dict()\n",
    "        \n",
    "        running_locations = dict()\n",
    "        \n",
    "        for team in season_df['team_id'].unique():\n",
    "            win_dict[team] = 0\n",
    "            lose_dict[team] = 0\n",
    "            running_dict[team] = []\n",
    "            plus_minus_dict[team] = 0\n",
    "            running_date_dict[team] = []\n",
    "            \n",
    "            # track wins at home, at away, and total games at home, at away\n",
    "            wins_as_home[team] = 0\n",
    "            wins_as_away[team] = 0\n",
    "            games_as_home[team] = 0\n",
    "            games_as_away[team] = 0\n",
    "            \n",
    "            # track list of locations played at\n",
    "            running_locations[team] = []\n",
    "        \n",
    "        # sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "        \n",
    "        seen_games = set()\n",
    "        \n",
    "        for (index, row) in season_df.iterrows():\n",
    "            is_home = row['is_home']\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            wl = row['wl']\n",
    "            game_id = row['game_id']\n",
    "            curr_team_plus_minus = row['plus_minus']\n",
    "            opp_team_plus_minus = -curr_team_plus_minus\n",
    "            game_date = row['game_date']\n",
    "            \n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            if is_home == 1:\n",
    "                home_team_id = team_id\n",
    "                away_team_id = opp_team_id\n",
    "            else:\n",
    "                home_team_id = opp_team_id\n",
    "                away_team_id = team_id\n",
    "\n",
    "            home_win_pct = 0\n",
    "            away_win_pct = 0\n",
    "\n",
    "            if win_dict[home_team_id] + lose_dict[home_team_id] > 0:\n",
    "                home_win_pct = (win_dict[home_team_id])/float(win_dict[home_team_id] + lose_dict[home_team_id])\n",
    "            if win_dict[away_team_id] + lose_dict[away_team_id] > 0:\n",
    "                away_win_pct = (win_dict[away_team_id])/float(win_dict[away_team_id] + lose_dict[away_team_id])\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct', home_win_pct)\n",
    "            new_df.set_value(index, 'away_win_pct', away_win_pct)\n",
    "\n",
    "            home_win_pct_N = 0\n",
    "            away_win_pct_N = 0\n",
    "            \n",
    "            home_games_count = len(running_dict[home_team_id])\n",
    "            away_games_count = len(running_dict[away_team_id])\n",
    "            \n",
    "            new_df.set_value(index, 'home_game_count', home_games_count)\n",
    "            new_df.set_value(index, 'away_game_count', away_games_count)\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                if home_games_count > lookback:\n",
    "                    lookback_games = running_dict[home_team_id][home_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[home_team_id]\n",
    "                home_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                if away_games_count > lookback:\n",
    "                    lookback_games = running_dict[away_team_id][away_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[away_team_id]\n",
    "                away_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_N', home_win_pct_N)\n",
    "            new_df.set_value(index, 'away_win_pct_N', away_win_pct_N)\n",
    "                \n",
    "            home_avg_pt_diff = 0\n",
    "            away_avg_pt_diff = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[home_team_id]\n",
    "                home_avg_pt_diff = running_pt_diff/float(home_games_count)\n",
    "            if away_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[away_team_id]\n",
    "                away_avg_pt_diff = running_pt_diff/float(away_games_count)\n",
    "                \n",
    "            new_df.set_value(index, 'home_avg_pt_diff', home_avg_pt_diff)\n",
    "            new_df.set_value(index, 'away_avg_pt_diff', away_avg_pt_diff)\n",
    "                \n",
    "            home_back_to_back = 0\n",
    "            away_back_to_back = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                most_recent_date = running_date_dict[home_team_id][home_games_count - 1]\n",
    "                #most_recent_date = datetime.strptime(most_recent_date, \"%Y-%m-%d\")\n",
    "                #curr_date = datetime.strptime(game_date, \"%Y-%m-%d\")\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # back to back\n",
    "                    home_back_to_back = 1\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                most_recent_date = running_date_dict[away_team_id][away_games_count - 1]\n",
    "                #most_recent_date = datetime.strptime(most_recent_date, \"%Y-%m-%d\")\n",
    "                #curr_date = datetime.strptime(game_date, \"%Y-%m-%d\")\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # back to back\n",
    "                    away_back_to_back = 1\n",
    "                    \n",
    "            new_df.set_value(index, 'home_back_to_back', home_back_to_back)\n",
    "            new_df.set_value(index, 'away_back_to_back', away_back_to_back)\n",
    "            \n",
    "            #update home_win_pct_as_home, away_win_pct_as_away\n",
    "            home_win_pct_as_home = 0\n",
    "            away_win_pct_as_away = 0\n",
    "            \n",
    "            home_games_as_home = games_as_home[home_team_id]\n",
    "            away_games_as_away = games_as_away[away_team_id]\n",
    "            \n",
    "            if (home_games_as_home > 0):\n",
    "                home_win_pct_as_home = (wins_as_home[home_team_id])/float(home_games_as_home)\n",
    "            if (away_games_as_away > 0):\n",
    "                away_win_pct_as_away = (wins_as_away[away_team_id])/float(away_games_as_away)\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_as_home', home_win_pct_as_home)\n",
    "            new_df.set_value(index, 'away_win_pct_as_away', away_win_pct_as_away)\n",
    "            \n",
    "            home_mileage = 0\n",
    "            away_mileage = 0\n",
    "            \n",
    "            curr_location = None\n",
    "            \n",
    "            if (new_years):\n",
    "                curr_location = get_team_location(home_team_id, season_id)\n",
    "            \n",
    "                #curr_geo = geolocator.geocode(curr_location)\n",
    "                #if (curr_geo == None):\n",
    "                #    print \"curr\", curr_location\n",
    "                \n",
    "                #(curr_lat, curr_long) = (curr_geo.latitude, curr_geo.longitude)\n",
    "                \n",
    "                (curr_lat, curr_long) = location_latlong[curr_location]\n",
    "\n",
    "                if home_games_count > 0:\n",
    "                    location_list = running_locations[home_team_id]\n",
    "                    assert(len(location_list) == home_games_count)\n",
    "                    last_location = location_list[len(location_list) - 1]\n",
    "                    #last_geo = geolocator.geocode(last_location)\n",
    "                    #if last_geo == None:\n",
    "                    #    print \"last home\", last_location\n",
    "                    #(last_lat, last_long) = (last_geo.latitude, last_geo.longitude)\n",
    "                    (last_lat, last_long) = location_latlong[last_location]\n",
    "                    \n",
    "                    str1 = curr_location + last_location\n",
    "                    str2 = last_location + curr_location\n",
    "                    \n",
    "                    if str1 in seen_distances:\n",
    "                        home_mileage = seen_distances[str1]\n",
    "                    elif str2 in seen_distances:\n",
    "                        home_mileage = seen_distances[str2]\n",
    "                    else:\n",
    "                        home_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                        seen_distances[str1] = home_mileage\n",
    "\n",
    "                if away_games_count > 0:\n",
    "                    location_list = running_locations[away_team_id]\n",
    "                    assert(len(location_list) == away_games_count)\n",
    "                    last_location = location_list[len(location_list) - 1]\n",
    "                    \n",
    "                    (last_lat, last_long) = location_latlong[last_location]\n",
    "                    \n",
    "                    str1 = curr_location + last_location\n",
    "                    str2 = last_location + curr_location\n",
    "                    \n",
    "                    if str1 in seen_distances:\n",
    "                        away_mileage = seen_distances[str1]\n",
    "                    elif str2 in seen_distances:\n",
    "                        away_mileage = seen_distances[str2]\n",
    "                    else:\n",
    "                        away_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                        seen_distances[str1] = away_mileage\n",
    "                    \n",
    "                    #last_location = running_locations[away_team_id][len(running_locations) - 1]\n",
    "#                     last_geo = geolocator.geocode(last_location)\n",
    "#                     if last_geo == None:\n",
    "#                         print \"last away\", last_location\n",
    "#                     (last_lat, last_long) = (last_geo.latitude, last_geo.longitude)\n",
    "\n",
    "#                     away_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "\n",
    "                new_df.set_value(index, 'home_mileage', home_mileage)\n",
    "                new_df.set_value(index, 'away_mileage', away_mileage)  \n",
    "                \n",
    "            # update running stats\n",
    "            if (wl == 'W'):\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[team_id] += 1\n",
    "                    lose_dict[opp_team_id] += 1\n",
    "                    running_dict[team_id].append(1)\n",
    "                    running_dict[opp_team_id].append(0)\n",
    "                    \n",
    "                    # update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_home[team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                    else:\n",
    "                        wins_as_away[team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                    \n",
    "            else:\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[opp_team_id] += 1\n",
    "                    lose_dict[team_id] += 1\n",
    "                    running_dict[opp_team_id].append(1)\n",
    "                    running_dict[team_id].append(0)\n",
    "                    \n",
    "                    # update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_away[opp_team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        \n",
    "                    else:\n",
    "                        wins_as_home[opp_team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "            if game_id in seen_games:\n",
    "                plus_minus_dict[team_id] += curr_team_plus_minus\n",
    "                plus_minus_dict[opp_team_id] += opp_team_plus_minus\n",
    "                running_date_dict[team_id].append(game_date)\n",
    "                running_date_dict[opp_team_id].append(game_date)\n",
    "                \n",
    "                #location = get_team_location[home_team_id]\n",
    "                \n",
    "                if (new_years):\n",
    "                    running_locations[home_team_id].append(curr_location)\n",
    "                    running_locations[away_team_id].append(curr_location)\n",
    "                \n",
    "            seen_games.add(game_id)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cutoff = 10\n",
    "# new_df = add_extra_features(league_df)\n",
    "\n",
    "# all games contains away games and home games, without any cutoff\n",
    "\n",
    "\n",
    "# all_games = new_df\n",
    "# home_games = new_df[new_df['is_home'] == 1]\n",
    "# home_games_with_cutoff = home_games[home_games['home_game_count'] >= cutoff]\n",
    "\n",
    "\n",
    "#print home_games_with_cutoff.head(20)\n",
    "#print home_games_with_cutoff[\"home_win_pct_as_home\"]\n",
    "#pd.DataFrame.to_csv(home_games_with_cutoff, 'home_games_with_cutoff.csv')\n",
    "#print len(home_games_with_cutoff[home_games_with_cutoff['season_id'] == '22015'])\n",
    "\n",
    "# new_years_df = league_df[league_df['season_id'] >= \"22005\"]\n",
    "# new_years_df = add_extra_features(new_years_df, True)\n",
    "\n",
    "new_years_df['pts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoff_test = home_games_with_cutoff[(home_games_with_cutoff['season_id'] == '22015') &\n",
    "                                    (home_games_with_cutoff['home_game_count'] >= 10)]\n",
    "print len(cutoff_test)\n",
    "\n",
    "#pd.DataFrame.to_csv(home_games_with_cutoff, 'home_games_with_cutoff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print home_games_with_cutoff[\"team_abbreviation\"].head(n=100)\n",
    "#print home_games_with_cutoff[\"home_win_pct\"].head(n=100)\n",
    "#print home_games_with_cutoff[\"away_win_pct\"].head(n=100)\n",
    "\n",
    "newdf = home_games_with_cutoff[(home_games_with_cutoff[\"team_abbreviation\"] ==\"DAL\")]\n",
    "#print newdf[\"home_win_pct\"].head()\n",
    "#print newdf[\"away_win_pct\"].head()\n",
    "#print newdf.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_point_diff(league_df, player_id, season):\n",
    "    \"\"\" Given a dataframe df, player id (int or string) and a season (string, ex: 2016-17), \n",
    "        returns a player log list df containing a new column pt_diff\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing league logs\n",
    "        player_id (int or string): player ID number\n",
    "        season (str): season string, ex: 2016-17\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    (headers, log_list) = get_player_gamelogs(player_id, season)\n",
    "    \n",
    "    df = convert_to_df(headers, log_list)\n",
    "    \n",
    "    # point_differentials\n",
    "    pt_diff = []\n",
    "    \n",
    "    for (index, row) in df.iterrows():\n",
    "        wl = row['WL']\n",
    "        game_id = int(row['Game_ID'])\n",
    "        \n",
    "        # there should be exactly one game with these properties\n",
    "        single_game_df = league_df[(league_df['game_id'] == game_id) & (league_df['wl'] == wl)]\n",
    "    \n",
    "        assert(len(single_game_df) == 1)\n",
    "        curr_pt_diff = single_game_df['plus_minus'].values[0]\n",
    "        pt_diff.append(curr_pt_diff)\n",
    "        \n",
    "    new_df = df.assign(pt_diff = np.array(pt_diff))\n",
    "    \n",
    "    return new_df\n",
    "        \n",
    "def graph_point_diff(league_df, player_id, season):\n",
    "    \"\"\" Given a dataframe df, player id (int or string) and a season (string, ex: 2016-17), \n",
    "        displays scatter plots comparing the players performance to resulting point differential\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        player_id (int or string): player ID number\n",
    "        season (str): season string, ex: 2016-17\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    new_df = add_point_diff(league_df, player_id, season)\n",
    "    \n",
    "    rows, cols = 4, 4\n",
    "    \n",
    "    f, axarr = plt.subplots(rows, cols)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # get numerical columns\n",
    "    num_list = ['MIN','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB',\n",
    "                  'AST','STL','BLK','TOV','PF','PTS','PLUS_MINUS']\n",
    "    \n",
    "    for i in xrange(rows):\n",
    "        for j in xrange(cols):\n",
    "            index = i*rows + j\n",
    "            \n",
    "            if index > 19:\n",
    "                continue\n",
    "            \n",
    "            curr_col = num_list[index]\n",
    "            y_array = np.array(new_df[curr_col].astype(float).values)\n",
    "            x_array = np.array(new_df['pt_diff'].astype(float).values)\n",
    "                \n",
    "            axarr[i,j].scatter(x_array, y_array)\n",
    "            axarr[i,j].title.set_text(curr_col)\n",
    "                \n",
    "# example jeremy lin\n",
    "# player_id = 202391\n",
    "# season = \"2016-17\"\n",
    "# team_id = 1610612751\n",
    "    \n",
    "#lebron james\n",
    "player_id = 2544\n",
    "season = \"2015-16\"\n",
    "\n",
    "#new_df = \n",
    "graph_point_diff(league_df, player_id, season)\n",
    "\n",
    "#new_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1610612746': 305, '1610612761': 249, '1610612762': 4226, '1610612763': 337, '1610612748': 24, '1610612749': 617, '1610612764': 205, '1610612765': 961, '1610612740': 13, '1610612741': 615, '1610612760': 1201, '1610612747': 233, '1610612744': 43, '1610612745': 43, '1610612739': 653, '1610612738': 141, '1610612737': 1050, '1610612759': 650, '1610612758': 30, '1610612751': 33, '1610612750': 830, '1610612753': 82, '1610612752': 33, '1610612755': 39, '1610612754': 715, '1610612757': 50, '1610612756': 39, '1610612742': 430, '1610612743': 5280, '1610612766': 751}\n"
     ]
    }
   ],
   "source": [
    "#temp_df = home_games_with_cutoff[home_games_with_cutoff['season_id']>=\"22005\"]\n",
    "temp_df = new_years_df[new_years_df['is_home'] == 1]\n",
    "\n",
    "temp_df.head()\n",
    "altitude = {'Chicago Stags': 615, 'Buffalo Braves': 600, 'Washington Bullets': 400, 'Toronto Huskies': 249, \n",
    "            'Los Angeles Lakers': 233, 'Chicago Bulls': 615, 'Washington Capitols': 200, 'Providence Steamrollers': 75, \n",
    "            'Charlotte Bobcats': 751, 'Capital Bullets': 200, 'New Orleans Pelicans': 13, 'San Diego Rockets': 62, \n",
    "            'Milwaukee Hawks': 617, 'Philadelphia 76ers': 39, 'Philadelphia Warriors': 39, 'Chicago Packers': 615, \n",
    "            'New Orleans Jazz': 20, 'Detroit Pistons': 961, 'Boston Celtics': 141, 'Miami Heat': 24, \n",
    "            'Minneapolis Lakers': 830, 'Orlando Magic': 82, 'Portland Trail Blazers': 50, 'Rochester Royals': 505, \n",
    "            'Golden State Warriors': 43, 'Sheboygan Redskins': 630, 'New York Knicks': 33, 'St. Louis Hawks': 465, \n",
    "            'Indianapolis Olympians': 715, 'Washington Wizards': 205, 'Kansas City Kings': 910, 'Utah Jazz': 4226, \n",
    "            'Ft. Wayne Zollner Pistons': 600, 'Pittsburgh Ironmen': 1365, 'New Jersey Nets': 33, 'New York Nets': 33, \n",
    "            'Dallas Mavericks': 430, 'Sacramento Kings': 30, 'New Orleans/Oklahoma City Hornets': 20, \n",
    "            'Los Angeles Clippers': 305, 'San Antonio Spurs': 650, 'Vancouver Grizzlies': 171, \n",
    "            'Oklahoma City Thunder': 1201, 'Waterloo Hawks': 1079, 'Charlotte Hornets': 751, 'Anderson Packers': 879, \n",
    "            'Syracuse Nationals': 380, 'Kansas City-Omaha Kings': 910, 'Cincinnati Royals': 482, 'Cleveland Rebels': 653, \n",
    "            'Milwaukee Bucks': 617, 'Phoenix Suns': 39, 'LA Clippers': 305, 'Memphis Grizzlies': 337, \n",
    "            'Tri-Cities Blackhawks': 1050, 'Toronto Raptors': 249, 'Houston Rockets': 43, 'New Orleans Hornets': 13, \n",
    "            'Chicago Zephyrs': 594, 'Minnesota Timberwolves': 830, 'Detroit Falcons': 600, 'Indiana Pacers': 715, \n",
    "            'San Diego Clippers': 62, 'Seattle SuperSonics': 518, 'Cleveland Cavaliers': 653, 'Atlanta Hawks': 1050, \n",
    "            'Brooklyn Nets': 33, 'Indianapolis Jets': 715, 'Baltimore Bullets': 480, 'San Francisco Warriors': 52, \n",
    "            'St. Louis Bombers': 465, 'Denver Nuggets': 5280}\n",
    "altitude_dict = {}\n",
    "curr_names = temp_df[\"team_name\"].tolist()\n",
    "for key in altitude:\n",
    "    if key not in curr_names:\n",
    "        continue\n",
    "    else:\n",
    "        filtered_df = temp_df[temp_df['team_name'] == key]\n",
    "        cor_id = filtered_df[\"team_id\"].iloc[0]\n",
    "        altitude_dict[str(cor_id)] = altitude[key]\n",
    "print altitude_dict\n",
    "### adding a new elevation column\n",
    "elevation = np.zeros(len(temp_df), dtype = np.int64)\n",
    "temp_df = temp_df.assign(elevation = elevation)\n",
    "\n",
    "for (index, row) in temp_df.iterrows():\n",
    "        location = row['is_home']\n",
    "        if location == 1: # at home\n",
    "            alt = altitude_dict[str(row[\"team_id\"])]\n",
    "            temp_df.set_value(index, 'elevation', alt)\n",
    "        else:\n",
    "            alt = altitude_dict[str(row[\"opp_team_id\"])]\n",
    "            temp_df.set_value(index, 'elevation', alt)\n",
    "temp_df\n",
    "\n",
    "df_with_elev_mileage = temp_df\n",
    "df_with_elev_mileage_with_cutoff = df_with_elev_mileage[df_with_elev_mileage['home_game_count'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame.to_csv(temp_df, 'home_games_with_cutoff_elev.csv')\n",
    "pd.DataFrame.to_csv(temp_df, 'home_games_with_cutoff_elev_mileage_2005.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injury Analysis\n",
    "Since injuries have a huge impact on the result of games, we would like our model to account for player injuries. For now, we will do some exploratory analysis to determine the impact a player's injury has on team performance. We will create dataframes for team's games that played the player and those that didn't, and then create a graph showing the difference in team performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_player_missedGames(player_id,team, yr, game_log, season):\n",
    "    \"\"\" Given a player id (int or string) and a season (string, ex: 2016-17), returns a (header, log_list) where the\n",
    "        header represents a key describing the format of a log in log list\n",
    "    Input:\n",
    "        player_id (int or string): player ID number\n",
    "        team (int): team_id number\n",
    "        yr (str): season string, ex: 2016-17\n",
    "        game_log (pd.DataFrame): Game_log\n",
    "        season (str): season_id \n",
    "    Output:\n",
    "        (DataFrame): a DataFrame of all games missed by a particular player in a particular season\n",
    "    \"\"\"\n",
    "    games_missed = pd.DataFrame(columns=('game_id',\"team\"))\n",
    "    \n",
    "    (header, plog_list) = get_player_gamelogs(player_id, yr) \n",
    "    player_df = convert_to_df(header, plog_list)\n",
    "    df = game_log.loc[game_log['season_id'] == season]\n",
    "    df = df.loc[df['team_id'] == team]\n",
    "    other_df = df.copy()\n",
    "    #now have dataframe of all games for a particular team in a particular season\n",
    "    i = 0\n",
    "    game_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        game = row['game_id']\n",
    "        if game in list(player_df.ix[:,2].astype(int)): # he did play in this game\n",
    "            df = df[df.game_id != game]\n",
    "            game_list.append(game)\n",
    "    \n",
    "    # return games that the player did not play in\n",
    "    other_df = other_df[other_df['game_id'].isin(game_list)]\n",
    "            \n",
    "    return df, other_df\n",
    "\n",
    "# example jeremy lin\n",
    "player_id = 202391\n",
    "season = \"2016-17\"\n",
    "team_id = 1610612751\n",
    "\n",
    "(missed_player_df, with_player_df) = get_player_missedGames(player_id,team_id,\"2016-17\",league_df,\"22016\")\n",
    "#(header, plog_list) = get_player_gamelogs(player_id, season) \n",
    "\n",
    "#player_df = convert_to_df(header, plog_list)\n",
    "\n",
    "# get numerical columns\n",
    "num_list = ['min','fgm','fga','fg_pct','fg3m','fg3a','fg3_pct','ftm','fta','ft_pct','oreb','dreb','reb',\n",
    "              'ast','stl','blk','tov','pf','pts','plus_minus']\n",
    "\n",
    "# get numerical columns\n",
    "w_num = with_player_df.loc[:,num_list]\n",
    "l_num = missed_player_df.loc[:,num_list]\n",
    "\n",
    "w_mean_list = []\n",
    "w_std_list = []\n",
    "l_mean_list = []\n",
    "l_std_list = []\n",
    "\n",
    "for i in num_list:\n",
    "    w_float_list = w_num[i].values.astype(float)\n",
    "    l_float_list = l_num[i].values.astype(float)\n",
    "    w_mean_list.append(w_float_list.mean())\n",
    "    l_mean_list.append(l_float_list.mean())\n",
    "    w_std_list.append(w_float_list.std())\n",
    "    l_std_list.append(l_float_list.std())\n",
    "\n",
    "n_groups = 20\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = .35\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(index, w_mean_list, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 yerr=w_std_list,\n",
    "                 error_kw=error_config,\n",
    "                 label='With Player')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, l_mean_list, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 yerr=l_std_list,\n",
    "                 error_kw=error_config,\n",
    "                 label='Without Player')\n",
    "\n",
    "\n",
    "plt.xlabel('Team Stats')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparing Player Stats in Wins and Losses')\n",
    "#plt.xticks(index + bar_width, ('A', 'B', 'C', 'D', 'E'))\n",
    "plt.xticks(index + bar_width, num_list)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# now, compare the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Exploratory Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the cutoff value\n",
    "At the beginning of every season, there is volatility in terms of the change in win-loss percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Graph Win-loss against number of games\n",
    "\n",
    "all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "print all_years_id\n",
    "print home_games_with_cutoff.head()\n",
    "print list(home_games_with_cutoff.columns.values)\n",
    "for year in all_years_id:\n",
    "    curr_year = home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==year)]\n",
    "    all_teams = curr_year[\"team_abbreviation\"].unique()\n",
    "    for team in all_teams:\n",
    "        newdf = curr_year[(curr_year[\"team_abbreviation\"] ==team)]\n",
    "        temp = newdf['home_win_pct'] - newdf['home_win_pct'].shift(-1) # difference in win_pct\n",
    "        plt.plot(newdf[\"home_game_count\"],temp)\n",
    "plt.axis([0,82,-1,1])\n",
    "plt.xlabel('Games Played')\n",
    "plt.ylabel('Change in Win-Percentage')\n",
    "plt.title('Win-Percentage change vs Games Played (all teams from 2004-2016)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Analysis\n",
    "For each of our proposed preditors that we mentioned earlier, we created bivariate scatterplots of these variables for the home and away teams. For these graphs, we inspect the previous season (2015-16). Each of the points are color coded: games that were won by the home team are blue while lost games are red. Hovering over each point shows the home team, the matchup of teams, and an whether or not the away team was playing a back to back game (1 for back to back, 0 for not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar\n",
    "from bokeh.charts import Scatter\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Avg Pt Diff Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Teams'\n",
    "p.yaxis.axis_label = 'Home Teams'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_avg_pt_diff\"], testYear[\"home_avg_pt_diff\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home W/L Percentage vs. Away W/L Percentage\n",
    "all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Avg Pt Diff Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Teams'\n",
    "p.yaxis.axis_label = 'Home Teams'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct\"], testYear[\"home_win_pct\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home W/L Percentage Previous N Games vs. Away W/L Percentage Previous N games\n",
    "all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Avg Pt Diff Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Teams'\n",
    "p.yaxis.axis_label = 'Home Teams'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct_N\"], testYear[\"home_win_pct_N\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home Team W/L Percentage as Home vs. Away W/L Percentage as Away \n",
    "all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Avg Pt Diff Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Teams'\n",
    "p.yaxis.axis_label = 'Home Teams'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct_as_away\"], testYear[\"home_win_pct_as_home\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing: Is back to back significant?\n",
    "We want to examine whether or not playing back to back games has a significant effect of lowering the chances that any given team will lose the next game. For each team, we look at their win loss percentages of back to back games compared to non back to back games across several seasons, and run a hypothesis test to see if the true mean difference in win loss percentage for regular games and back to back games is non-zero. We run this hypothesis test at an alpha level of 0.05. We look to see whether this was a significant effect for many teams in the league or just a few of them. \n",
    "\n",
    "Null Hypothesis: \n",
    "The true difference in win loss records between regular games and back to back games is zero.\n",
    "\n",
    "Alternative: \n",
    "The win loss record of regular games is higher than that of the win loss record of back to back games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "def teamPercentages(teamID, game_log):\n",
    "    \"\"\" Given a team id (int or string) returns a (list, list) representing win loss percentages for back to back \n",
    "        and regular games\n",
    "    Input:\n",
    "        teamID (int): team_id number\n",
    "        game_log (pd.DataFrame): Game_log - Needs all games (not just home games) listed\n",
    "    Output:\n",
    "        (list, list): a tuple of lists where each list contains the number of wins and number of games played for a \n",
    "                      given category, where the first list represents back to back games and the second list \n",
    "                      represents regular games.\n",
    "    \"\"\"\n",
    "    seasons = game_log[\"season_id\"].unique()\n",
    "    # Initialize lists which store the percentages for back to back games and regular games for each season\n",
    "    bbList = []\n",
    "    regList = []\n",
    "    # Initialize counters for games \n",
    "    bbWins = 0 \n",
    "    bbGames = 0\n",
    "    regWins = 0\n",
    "    regGames = 0\n",
    "    # Iterate through all seasons of the dataframe \n",
    "    for season in seasons:\n",
    "        # Get dataframe that only contains games from this season of the team of interest\n",
    "        currDf = game_log[(game_log[\"season_id\"] == season) & ((game_log[\"team_id\"] == teamID) | (game_log[\"opp_team_id\"] == teamID))]\n",
    "        # Iterate over the dataframe\n",
    "        for (index, row) in currDf.iterrows():\n",
    "            # Determine whether this is a home or away game\n",
    "            if (row[\"team_id\"] == teamID):\n",
    "                home = True\n",
    "            else:\n",
    "                home = False\n",
    "            # Case 1: Home back to back game \n",
    "            if (home and row[\"home_back_to_back\"] == 1):\n",
    "                bbGames += 1\n",
    "                if (row[\"wl_binary\"] == 1):\n",
    "                    bbWins += 1\n",
    "            # Case 2: Away back to back game\n",
    "            if(home == False and row[\"away_back_to_back\"] == 1):\n",
    "                bbGames += 1\n",
    "                if (row[\"wl_binary\"] == 0):\n",
    "                    bbWins += 1\n",
    "            # Otherwise we have regular games\n",
    "            else:\n",
    "                regGames += 1\n",
    "                if (home and row[\"wl_binary\"] == 1):\n",
    "                    regWins += 1\n",
    "                elif (home == False and row[\"wl_binary\"] == 0):\n",
    "                    regWins += 1\n",
    "    # Add the num of won and total games in the respective lists \n",
    "    bbList.append(bbWins)\n",
    "    bbList.append(bbGames)\n",
    "    regList.append(regWins)\n",
    "    regList.append(regGames)\n",
    "    return (bbList, regList)\n",
    "\n",
    "#print teamPercentages(1610612742, home_games)\n",
    "\n",
    "def leaguePercentages(game_log, season_id):\n",
    "    \"\"\" For all teams in the league, generate their win loss percentages for back to back and regular games \n",
    "        across all seasons beyond a specific season and add the result in a dictionary. \n",
    "    Input: \n",
    "        game_log (pd.Dataframe): Dataframe containing all the game logs (all games, not just home)\n",
    "        season_id (string): season id in which we only look at the results occuring at or after this season \n",
    "    Output:\n",
    "        returnDict: (string, (List, List)) where key represents the team name and value is the tuple of \n",
    "                                           lists. Each list contains the number of wins and total games played, \n",
    "                                           where the first list represents back to back games and the second list \n",
    "                                           represents regular games\n",
    "    \"\"\"\n",
    "    # Index out the seasons \n",
    "    newLog = game_log[game_log[\"season_id\"] >= season_id]\n",
    "    # Initialize the dictionary for all teams\n",
    "    returnDict = {}\n",
    "    teamList = newLog[\"team_id\"].unique()\n",
    "    # Iterate over all teams and call above helper function to generate the lists of win loss % for each team\n",
    "    for teamID in teamList:\n",
    "        returnDict[team] = teamPercentages(teamID, newLog)\n",
    "    return returnDict\n",
    "\n",
    "def hypothesisTest(bbList, regList):\n",
    "    \"\"\" Run a hypothesis test to see whether the true mean win loss percentage of regular games is higher than\n",
    "        the true mean win loss percentage of back to back games for a specific team over many seasons.\n",
    "    Input: \n",
    "        bbList (List): List containing the win loss percentages of a team for back to back games over many seasons\n",
    "        regList (List): List containing the win loss percentages of a team for regular games over many seasons \n",
    "    Output:\n",
    "        result: (Boolean) where 1 represents regular game win loss percentage being significantly greater than the \n",
    "                          win loss percentage for back to back games given the inputted data.\n",
    "    \"\"\"\n",
    "    # Get number of back to back and reg games \n",
    "    bbWins = bbList[0]\n",
    "    nBB = bbList[1]\n",
    "    regWins = regList[0]\n",
    "    nReg = regList[1]\n",
    "    # Get our win loss percentages for back to back and regular games \n",
    "    bbProp = bbWins / float(nBB)\n",
    "    regProp = regWins / float(nReg)\n",
    "    # Caluclate the pooled proportion and pooled standard deviation \n",
    "    pooledProp = (bbWins + regWins) / float(nBB + nReg)\n",
    "    pooledSE = np.sqrt(pooledProp * (1 - pooledProp) * ((1/float(nBB)) + (1/float(nReg))))\n",
    "    propDiff = regProp - bbProp\n",
    "    z = propDiff / float(pooledSE)\n",
    "    # Find the cutoff for alpha = 0.05 \n",
    "    cutoff = norm.ppf(0.95, loc = 0, scale = 1)\n",
    "    return z > cutoff \n",
    "    \n",
    "def testLeague(game_log, season_id):\n",
    "    \"\"\" For all teams in the league, run the hypothesis tests comparing win loss percentages between back to back games\n",
    "        and non back to back games. \n",
    "    Input: \n",
    "        game_log (pd.Dataframe): Dataframe containing all the game logs (all games, not just home)\n",
    "        season_id (string): season id in which we only look at the results occuring at or after this season  \n",
    "    Output:\n",
    "        result: (Float, Dictionary) Tuple containing an int and a dictionary. The float represents the percentage of teams\n",
    "                                    in which back to back games is significant from the hypothesis test. The dictionary \n",
    "                                    has keys being the team_id, and values as booleans of whether or not there was a \n",
    "                                    significant difference between the records\n",
    "    \"\"\"\n",
    "    # Index out the seasons \n",
    "    newLog = game_log[game_log[\"season_id\"] >= season_id]\n",
    "    # Initialize the dictionary for all teams\n",
    "    returnDict = {}\n",
    "    teamList = newLog[\"team_id\"].unique()\n",
    "    for team in teamList:\n",
    "        returnDict[team] = hypothesisTest(teamPercentages(team, newLog[newLog[\"season_id\"] >= season_id])[0], teamPercentages(team, all_games[all_games[\"season_id\"] >= season_id])[1])\n",
    "    # Find the proportion of teams in which this difference was significant across the league \n",
    "    sig = 0 \n",
    "    total = 0 \n",
    "    for team in returnDict:\n",
    "        if returnDict[team] == 1:\n",
    "            sig += 1\n",
    "        total += 1\n",
    "    percSig = (sig) / float(total)\n",
    "    print percSig\n",
    "    return (percSig, returnDict)\n",
    "\n",
    "#testLeague(home_games, \"22004\")\n",
    "testLeague(home_games, \"22005\")\n",
    "#testLeague(home_games, \"22006\")\n",
    "#testLeague(home_games, \"22007\")\n",
    "#testLeague(home_games, \"22008\")\n",
    "#testLeague(home_games, \"22009\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Results\n",
    "Below, we run hypothesis tests on cutoff seasons starting from 2004, all the way up to 2015. We graphically display this result. This graph seems to show that as there are more and more seasons, it appears that playing back to back games is less significant compared to playing regular games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the following imports \n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar\n",
    "\n",
    "# Initialize the results of running the hypothesis test above on many seasons\n",
    "resultsList = []\n",
    "seasons = [\"22004\", \"22005\", \"22006\", \"22007\", \"22008\", \"22009\", \"22010\", \"22011\", \"22012\", \"22013\", \"22014\", \"22015\"]\n",
    "# More readable list for the plot values \n",
    "readSeasons = [\"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]\n",
    "# Compute the proportion of teams in which playing back to back was significant for \n",
    "# on passing in seasons from 2004 to 2015\n",
    "for season in seasons:\n",
    "    resultsList.append(testLeague(home_games, season)[0])\n",
    "    \n",
    "# Create a new plot with a title and axis labels\n",
    "p = figure(title=\"Hypothesis Testing Over Cutoffs From 2004-2015\", x_axis_label='Season Cutoff', y_axis_label='% of Teams Back to Back Significant')\n",
    "\n",
    "# Add the line to the plot, specifying features of the graph \n",
    "p.line(readSeasons, resultsList, legend=\"% of Teams In Which Back to Back Significant\", line_width=2)\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "The above code ran the hypothesis test comparing win loss percentages between regular and back to back games across all teams in the league from the 2005 - 2016 season so far. As the results show, for an alpha level of 0.05, we see that there is statistically significant evidence to reject the null in favor of the alternative that teams have a worse record on back to back games compared to regular games, for 53% of teams since the 2005 season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Geographical Features\n",
    "For each game, we wish to record the travel distance the team took to get there from the prior game location. To do this, we will use the `geopy` library to get latitudes and longitudes and distance calculations. Note that certain teams have changed locations, so we have to be careful. The following teams have have changed location since 2005:\n",
    "1. New Orleans Hornets -> Oklahoma City (05-06, 06-07)\n",
    "2. Seattle Supersonics -> Oklahoma City Thunder (08-09 to Present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set base year\n",
    "temp_df_1 = all_games[all_games['season_id'] >= '22005']\n",
    "team_names = temp_df_1['team_name'].unique().tolist()\n",
    "print len(team_names), team_names\n",
    "\n",
    "team_id_list = temp_df_1['team_id'].unique().tolist()\n",
    "print len(team_id_list), team_id_list\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Orleans/Oklahoma City Hornets']\n",
    "no_okc_seasons = temp_df['season_id'].unique().tolist()\n",
    "print \"NO_OKC\", no_okc_seasons\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Charlotte Bobcats']\n",
    "bobcats = temp_df['season_id'].unique().tolist()\n",
    "print \"BOB\", bobcats\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Jersey Nets']\n",
    "nj = temp_df['season_id'].unique().tolist()\n",
    "print \"NJ\", nj\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Seattle SuperSonics']\n",
    "seattle = temp_df['season_id'].unique().tolist()\n",
    "print \"SUPER\", seattle\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'New Orleans Hornets']\n",
    "noh = temp_df['season_id'].unique().tolist()\n",
    "print \"NOH\", noh\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Oklahoma City Thunder']\n",
    "thunder = temp_df['season_id'].unique().tolist()\n",
    "print \"THUNDER\", thunder\n",
    "\n",
    "temp_df = temp_df_1[temp_df_1['team_name'] == 'Brooklyn Nets']\n",
    "bkn = temp_df['season_id'].unique().tolist()\n",
    "print \"BKN\", bkn\n",
    "\n",
    "# dictionary mapping of team_id to team_names?\n",
    "id_team = dict()\n",
    "for team_id in team_id_list:\n",
    "    temp_df = temp_df_1[temp_df_1['team_id'] == team_id]\n",
    "    id_team[team_id] = temp_df['team_name'].unique().tolist()\n",
    "print id_team\n",
    "\n",
    "# dictionary mapping of team_name to seasons\n",
    "team_seasons = dict()\n",
    "for team_name in team_names:\n",
    "    temp_df = temp_df_1[temp_df_1['team_name'] == team_name]\n",
    "    team_seasons[team_name] = temp_df['season_id'].unique().tolist()\n",
    "print team_seasons\n",
    "\n",
    "# sanity check\n",
    "for team_id in team_id_list:\n",
    "    names = id_team[team_id]\n",
    "    if len(names) == 0:\n",
    "        raise Fail(\"no names for ID\")\n",
    "    elif len(names) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        season_list = []\n",
    "        for name in names:\n",
    "            seasons = team_seasons[name]\n",
    "            season_list.append(seasons)\n",
    "            \n",
    "        common_years = list(reduce(set.intersection, map(set, season_list)))\n",
    "        print len(common_years), names, common_years\n",
    "        assert(len(common_years) == 0)\n",
    "            \n",
    "# ['Dallas Mavericks', 'New Orleans/Oklahoma City Hornets', 'Milwaukee Bucks', 'San Antonio Spurs', \n",
    "#  'Philadelphia 76ers', 'Phoenix Suns', 'Denver Nuggets', 'Sacramento Kings', 'Atlanta Hawks', 'Miami Heat', \n",
    "#  'Toronto Raptors', 'New Jersey Nets', 'Houston Rockets', 'Boston Celtics', 'Golden State Warriors', \n",
    "#  'Utah Jazz', 'Seattle SuperSonics', 'Portland Trail Blazers', 'Indiana Pacers', 'Minnesota Timberwolves', \n",
    "#  'Washington Wizards', 'Chicago Bulls', 'New York Knicks', 'Cleveland Cavaliers', 'Charlotte Bobcats', \n",
    "#  'Detroit Pistons', 'Memphis Grizzlies', 'Orlando Magic', 'Los Angeles Clippers', 'Los Angeles Lakers', \n",
    "#  'New Orleans Hornets', 'Oklahoma City Thunder', 'Brooklyn Nets', 'New Orleans Pelicans', 'Charlotte Hornets', \n",
    "#  'LA Clippers']\n",
    "\n",
    "name_location = {'Dallas Mavericks': 'Dallas, Texas',\n",
    "                'New Orleans/Oklahoma City Hornets': 'Oklahoma City, Oklahoma',\n",
    "                'Milwaukee Bucks': 'Milwaukee, Wisconsin',\n",
    "                'San Antonio Spurs': 'San Antonio, Texas',\n",
    "                'Philadelphia 76ers': 'Philadelphia, Pennsylvania',\n",
    "                'Phoenix Suns': 'Phoenix, Arizona',\n",
    "                'Denver Nuggets': 'Denver, Colorado',\n",
    "                'Sacramento Kings': 'Sacramento, California',\n",
    "                'Atlanta Hawks': 'Atlanta, Georgia',\n",
    "                'Miami Heat' : 'Miami, Florida', \n",
    "                'Toronto Raptors': 'Toronto, Ontario', \n",
    "                'New Jersey Nets': 'Newark, New Jersey', \n",
    "                'Houston Rockets': 'Houston, Texas', \n",
    "                'Boston Celtics': 'Boston, Massachusetts', \n",
    "                'Golden State Warriors' : 'Oakland, California', \n",
    "                'Utah Jazz': 'Salt Lake City, Utah', \n",
    "                'Seattle SuperSonics' : 'Seattle, Washington', \n",
    "                'Portland Trail Blazers': 'Portland, Oregon', \n",
    "                'Indiana Pacers' : 'Indianapolis, Indiana', \n",
    "                'Minnesota Timberwolves' : 'Minneapolis, Minnesota', \n",
    "                'Washington Wizards': 'Washington D.C., Virginia',\n",
    "                'Chicago Bulls' : 'Chicago, Illinois', \n",
    "                'New York Knicks': 'New York City, New York', \n",
    "                'Cleveland Cavaliers' : 'Cleveland, Ohio', \n",
    "                'Charlotte Bobcats' : 'Charlotte, North Carolina',\n",
    "                'Detroit Pistons' : 'Detroit, Michigan', \n",
    "                'Memphis Grizzlies' : 'Memphis, Tennessee', \n",
    "                'Orlando Magic' : 'Orlando, Florida', \n",
    "                'Los Angeles Clippers' : 'Los Angeles, California', \n",
    "                'Los Angeles Lakers' : 'Los Angleles, California', \n",
    "                'New Orleans Hornets' : 'New Orleans, Louisiana', \n",
    "                'Oklahoma City Thunder': 'Oklahoma City, Oklahoma', \n",
    "                'Brooklyn Nets': 'Brooklyn, New York', \n",
    "                'New Orleans Pelicans' : 'New Orleans, Louisiana', \n",
    "                'Charlotte Hornets' : 'Charlotte, North Carolina', \n",
    "                'LA Clippers' : 'Los Angeles, California'}\n",
    "\n",
    "def get_team_location(team_id, season_id):\n",
    "    \"\"\" Given a team id and the season_id, returns a string containing the location of the team stadium\n",
    "    Input: \n",
    "        team_id (int): team id\n",
    "        season_id (str): season id \n",
    "    Output:\n",
    "        (str) \n",
    "    \"\"\"\n",
    "    names = id_team[team_id]\n",
    "    \n",
    "    team_name = None\n",
    "    \n",
    "    for name in names:\n",
    "        seasons = team_seasons[name]\n",
    "        if season_id in seasons:\n",
    "            team_name = name\n",
    "            \n",
    "    assert(team_name != None)\n",
    "    \n",
    "    return name_location[team_name]\n",
    "\n",
    "location = get_team_location(1610612742, '22015')\n",
    "location1 = get_team_location(1610612749, '22015')\n",
    "\n",
    "print location, location1\n",
    "\n",
    "geolocator = Nominatim()\n",
    "geo_loc = geolocator.geocode(location)\n",
    "\n",
    "(lat1, long1) = (geo_loc.latitude, geo_loc.longitude)\n",
    "\n",
    "geo_loc1 = geolocator.geocode(location1)\n",
    "\n",
    "(lat2, long2) = (geo_loc1.latitude, geo_loc1.longitude)\n",
    "\n",
    "print vincenty((lat1,long1), (lat2,long2)).miles\n",
    "    \n",
    "#print Geocoder.geocode(location).valid_address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How has the NBA changed over the years?\n",
    "We want to examine the change of key statistics over time in the past 40 years of the NBA. \n",
    "1. How has the standard deviation of team wins in a given season changed over different seasons?\n",
    "2. How has the average point differential for a given season changed over different seasons?\n",
    "3. How has the difference between the mean point differential between top teams and bottom teams changed over different seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_team_wins_count(league_df, team_id, season_id):\n",
    "    \"\"\" Given a df containing ALL game logs (including home and away), \n",
    "        team_id and season_id, returns number of wins the team got that season\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "        team_id (int or string): player ID number\n",
    "        season_id (int or string): season ID number\n",
    "    Output:\n",
    "        (int): number of games team won in season\n",
    "    \"\"\"\n",
    "    \n",
    "    team_id = int(team_id)\n",
    "    season_id = str(season_id)\n",
    "    \n",
    "    #print league_df['season_id'].dtype\n",
    "    #print league_df['team_id'].dtype\n",
    "    \n",
    "    temp_df = league_df[(league_df['season_id'] == season_id) & (league_df['team_id'] == team_id)]\n",
    "    \n",
    "    temp_df = temp_df.sort_values('game_date')\n",
    "    \n",
    "    # get last game\n",
    "    last_game = temp_df.iloc[len(temp_df) - 1]\n",
    "    \n",
    "    #print last_game\n",
    "    #assert(last_game['home_game_count'] == 81 or last_game['away_game_count'] == 81)\n",
    "    \n",
    "    wins = 0\n",
    "    games_won_so_far = 0\n",
    "    if last_game['is_home']:\n",
    "        games_won_so_far = int(round(last_game['home_win_pct']*last_game['home_game_count']))\n",
    "    else:\n",
    "        games_won_so_far = int(round(last_game['away_win_pct']*last_game['away_game_count']))\n",
    "    wins = games_won_so_far + last_game['wl_binary']\n",
    "    \n",
    "    return wins\n",
    "    \n",
    "get_team_wins_count(all_games, \"1610612742\", \"22004\")\n",
    "\n",
    "def graph_stdev_wins(league_df):\n",
    "    \"\"\" Given a df containing ALL SORTED game logs (including home and away), \n",
    "        graphs stdev of team wins over time\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    stdevs = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        \n",
    "        team_list = season_df['team_id'].unique().tolist()\n",
    "        \n",
    "        win_counts = []\n",
    "        \n",
    "        for team in team_list:\n",
    "            team_wins = get_team_wins_count(league_df, team, season)\n",
    "            win_counts.append(team_wins)\n",
    "            \n",
    "        stdev = np.array(win_counts).std(ddof = 1)\n",
    "        #stdevs.append(season[1:], stdev)\n",
    "        seasons.append(int(season[1:]))\n",
    "        stdevs.append(stdev)\n",
    "        \n",
    "    # remove last, unfinished year\n",
    "    seasons = seasons[:len(seasons)- 1]\n",
    "    stdevs = stdevs[:len(stdevs) - 1]\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Sample Standard Deviation Of Games Won',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.plot(seasons, stdevs, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, stdevs, 1))(np.unique(seasons)))\n",
    "         \n",
    "graph_stdev_wins(all_games)\n",
    "\n",
    "def graph_avg_ptdiff(league_df):\n",
    "    \"\"\" Given a df containing ALL SORTED game logs (including home and away), \n",
    "        graphs average (absolute value) ptdiff over seasons\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    avg_pt_diffs = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        pt_diff = season_df['plus_minus'].values\n",
    "        pt_diff = np.apply_along_axis(lambda x: np.abs(x), 0, pt_diff)\n",
    "        seasons.append(int(season[1:]))\n",
    "        avg_pt_diffs.append(np.mean(pt_diff))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Average Point Differentials Over Seasons',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Average Point Differential')\n",
    "    plt.plot(seasons, avg_pt_diffs, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, avg_pt_diffs, 1))(np.unique(seasons)))\n",
    "\n",
    "graph_avg_ptdiff(all_games)\n",
    "    \n",
    "def mean_ptdiff_top_bottom():\n",
    "    pass\n",
    "\n",
    "def total_games_graph(league_df):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        graphs total games played throughout seasons\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (only HOME)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    total_games = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        #pt_diff = season_df['plus_minus'].values\n",
    "        #pt_diff = np.apply_along_axis(lambda x: np.abs(x), 0, pt_diff)\n",
    "        seasons.append(int(season[1:]))\n",
    "        total_games.append(len(season_df))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Total Games Played Over Different Seasons',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Games Played')\n",
    "    plt.plot(seasons, total_games, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, total_games, 1))(np.unique(seasons)))\n",
    "    \n",
    "total_games_graph(home_games)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Approach Performance\n",
    "The naive approach is to choose the team with the better record so far. If the records are the same, we will classify the home team as the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_approach_accuracy(home_games_df, season_id_list):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        season_id, returns accuracy of naive classification\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "        season_id (int or string): season ID number\n",
    "    Output:\n",
    "        (int): number of games team won in season\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for season_id in season_id_list:\n",
    "        season_id = str(season_id)\n",
    "\n",
    "        season_df = home_games_df[(home_games_df['season_id'] == season_id)]\n",
    "        for (index, row) in season_df.iterrows():\n",
    "            home_team_pct = row['home_win_pct']\n",
    "            away_team_pct = row['away_win_pct']\n",
    "            wl = row['wl_binary']\n",
    "            classification = 0\n",
    "\n",
    "            if (home_team_pct >= away_team_pct):\n",
    "                classification = 1\n",
    "            if classification == wl:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "    return correct/float(total)\n",
    "\n",
    "print naive_approach_accuracy(home_games,[\"22010\",\"22011\",\"22012\"])\n",
    "    \n",
    "def graph_naive(home_games_df):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        graph_naive graphs the naive classification accuracy across seasons\n",
    "    Input:\n",
    "        home_games_df (pandas.DataFrame): dataframe containing post-processed \n",
    "            league logs (HOME)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = home_games_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    naives = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        naives.append(naive_approach_accuracy(home_games_df, [season]))\n",
    "        #pt_diff = season_df['plus_minus'].values\n",
    "        #pt_diff = np.apply_along_axis(lambda x: np.abs(x), 0, pt_diff)\n",
    "        seasons.append(int(season[1:]))\n",
    "        #avg_pt_diffs.append(np.mean(pt_diff))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Naive Classification Accuracy',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(seasons, naives, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, naives, 1))(np.unique(seasons)))\n",
    "\n",
    "graph_naive(home_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "We wish to normalize our data for cleaner modeling, and to help SVM converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinyang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/kevinyang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/kevinyang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/kevinyang/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# home games\n",
    "# divide into training set, validation set, test set\n",
    "# training_set = home_games_with_cutoff[(home_games_with_cutoff['season_id'] >= \"22005\") &\n",
    "#                                      (home_games_with_cutoff['season_id'] <= \"22009\")]\n",
    "# validation_set = home_games[(home_games['season_id'] >= \"22010\") & \n",
    "#                             (home_games['season_id'] <= \"22012\")]\n",
    "# test_set = home_games[(home_games['season_id'] >= \"22013\") & \n",
    "#                       (home_games['season_id'] <= \"22016\")]\n",
    "\n",
    "training_set = df_with_elev_mileage_with_cutoff[(home_games_with_cutoff['season_id'] >= \"22005\") &\n",
    "                                     (home_games_with_cutoff['season_id'] <= \"22009\")]\n",
    "validation_set = df_with_elev_mileage[(home_games['season_id'] >= \"22010\") & \n",
    "                            (home_games['season_id'] <= \"22012\")]\n",
    "test_set = df_with_elev_mileage[(home_games['season_id'] >= \"22013\") & \n",
    "                      (home_games['season_id'] <= \"22016\")]\n",
    "\n",
    "def normalize(df, param_labels, soft=True):\n",
    "    \"\"\" Given a df containing game logs to be normalized, returns a new normalized dataframe\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing post-processed league logs\n",
    "        list (str): list of column labels to normalize\n",
    "        soft (bool): whether to do soft normalization or hard normalization\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    # soft normalization\n",
    "    if (soft):\n",
    "        for label in param_labels:\n",
    "            mean = np.mean(df[label])\n",
    "            std = (df[label]).std()\n",
    "            \n",
    "            new_row = df[label].apply(lambda x: (x-mean)/(2*std))\n",
    "    \n",
    "            df.loc[:,label] = new_row \n",
    "    # hard normalization\n",
    "    else:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "# RUN THIS IF YOU WANT NORMALIZED STUFF\n",
    "training_set = normalize(training_set, ['home_avg_pt_diff','away_avg_pt_diff', 'elevation','home_mileage','away_mileage'])\n",
    "validation_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff','elevation','home_mileage','away_mileage'])\n",
    "test_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff','elevation','home_mileage','away_mileage'])\n",
    "\n",
    "#training_set = normalize(training_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])\n",
    "#validation_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])\n",
    "#test_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "In addition to Linear and Logistic Regression, we wish to try support vector machines for classification of win-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_feature_matrix(df, features):\n",
    "    \"\"\" Given a normalized df, returns a matrix of features and the binary w/l response\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing post-processed, normalzied league logs\n",
    "        list (str): list of features to be included\n",
    "    Output:\n",
    "        (array-like, array-like)\n",
    "    \"\"\"\n",
    "    return (df[features].values, df['wl_binary'].values)\n",
    "\n",
    "# modify this as see fit\n",
    "features = ['home_win_pct', 'away_win_pct',\n",
    "           'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            'home_win_pct_as_home', 'home_back_to_back','away_back_to_back','elevation','away_mileage']\n",
    "\n",
    "training_matrix, training_response = create_feature_matrix(training_set, features)\n",
    "validation_matrix, validation_response = create_feature_matrix(validation_set, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=8, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run SVM\n",
    "#clf = SVC(C=1e4, kernel='linear')\n",
    "#clf = SVC(C = 2**(3), gamma = 2**(-15), kernel = 'linear')\n",
    "clf = LinearSVC(C=2**(3), loss='squared_hinge', dual = False, penalty = \"l1\", )\n",
    "clf.fit(training_matrix, training_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_pred = clf.predict(validation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675362318841\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def get_svm_accuracy(pred, actuals):\n",
    "    \"\"\" Given predictions and actuals, calculates prediction accuracy\n",
    "    Input:\n",
    "        pred (array-like): list of predictions\n",
    "        actuals (array-like): list of actual outputs\n",
    "    Output:\n",
    "        float\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(pred) == len(actuals))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i in xrange(len(pred)):\n",
    "        if pred[i] == actuals[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    return correct/float(total)\n",
    "\n",
    "print get_svm_accuracy(valid_pred, validation_response)\n",
    "\n",
    "# Run grid search to find the optimal gamma and C values \n",
    "def gridSearch():\n",
    "    cPower = -5\n",
    "    bestC = 0\n",
    "    bestG = 0\n",
    "    optimal = sys.minint \n",
    "    for c in xrange(11):\n",
    "        cVal = 2**(cPower)\n",
    "        gPower = -15 \n",
    "        for g in xrange(10):\n",
    "            gVal = 2**(gPower)\n",
    "            clf = SVC(C = cVal,gamma = gVal, kernel='linear')\n",
    "            clf.fit(training_matrix, training_response)\n",
    "            valid_pred = clf.predict(validation_matrix)\n",
    "            currVal = get_svm_accuracy(valid_pred, validation_response)\n",
    "            print currVal, gPower, cPower\n",
    "            if optimal < currVal:\n",
    "                optimal = currVal \n",
    "                bestC = cVal  \n",
    "                bestG = gVal\n",
    "            gPower += 2\n",
    "        cPower += 2\n",
    "    return (bestC, bestG)\n",
    "\n",
    "#gridSearch() # (9223372036854775807, 9223372036854775807) - (63, 63)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random code to count number of back to back wins\n",
    "print len(home_games[(home_games['team_id'] == 1610612742) &(home_games['wl_binary'] == 1)\n",
    "         & (home_games['season_id'] == \"22015\") & (home_games['home_back_to_back'] == 1)])\n",
    "\n",
    "print len(home_games[(home_games['opp_team_id'] == 1610612742) &(home_games['wl_binary'] == 0)\n",
    "         & (home_games['season_id'] == \"22015\") & (home_games['away_back_to_back'] == 1)])\n",
    "\n",
    "print len(home_games[(home_games['team_id'] == 1610612742)\n",
    "         & (home_games['season_id'] == \"22015\") & (home_games['home_back_to_back'] == 1)])\n",
    "\n",
    "print len(home_games[(home_games['opp_team_id'] == 1610612742)\n",
    "         & (home_games['season_id'] == \"22015\") & (home_games['away_back_to_back'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_SVC(C=1e4, gamma='auto'):\n",
    "    pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
