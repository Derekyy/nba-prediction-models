{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Game Predictions - Final Report\n",
    "## Kevin Yang, Eric Lee, Derek Young\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introduction\n",
    "The NBA (National Basketball Association) is an American based men's basketball league that is considered to be the best basketball league in the world. As of the 2016-2017 season, there are 30 teams divided into two conferences (and further divided into six divisions).\n",
    "\n",
    "Our main objective is to build prediction models for NBA team performance.\n",
    "\n",
    "On a broad level, we have decided to focus our project on predicting the outcome of a given nba game. On a high level, our approach will involve determining the most important features in determining game outcomes, and then train a supervised machine learning model on these features over many previous games. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Contents\n",
    "Below outlines the pipeline to predict NBA games.\n",
    "\n",
    "1. [Data Collection and Scraping](#Data Collection and Scraping)\n",
    "2. [Exploratory Data Analysis]()\n",
    "3. [Feature Selection]()\n",
    "4. [Cutoff and \"N\"-previous Game Selection]()\n",
    "5. [Naive Approach]()\n",
    "6. [Linear Regression Model](#Linear Regression Model)\n",
    "7. [Logistic Regression Model]()\n",
    "8. [Support Vector Machines]()\n",
    "9. [Concluding Thoughts]()\n",
    "\n",
    "While most of our project is written in Python, a certain subset was done in R, specifically modeling linear and logistic regression. Throughout the report, we will highlight snippets of code that were substantial to our results. All code can be found ____."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data Collection and Scraping'></a>\n",
    "### Data Collection\n",
    "\n",
    "We found that the best place to get our data was [stats.nba.com](http://stats.nba.com). First, we surveyed the webpage, finding the location and organization of data. Using Google Chrome Developer Tools, we were able to find the link structures and JSON responses containing useful data for our models; these methods will be made more clear in the code below.\n",
    "\n",
    "Once we found a scalable approach to get all team game data for any NBA season, we decided that it would be best if, upon scraping and collecting the appropriate data, that we store our data in a local `sqlite3` database for futher use. We found this to be a consistent and reliable approach to our data analysis, as our data does not run the risk of changing unexpectedly, and we do not have to worry about overloading any servers with too many requests. We write the functions `get_league_gamelogs`, `generate_year_list`, and `load_all_gamelogs` to collect and then store our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def get_league_gamelogs(season):\n",
    "    \"\"\" Given a season (string, ex: 2016-17), returns a (header, log_list) where the header represents a \n",
    "        key describing the format of the logs in log_list\n",
    "    Input:\n",
    "        season (str): season string, ex: '2016-17'\n",
    "    Output:\n",
    "        (list, dict)\n",
    "    \"\"\"\n",
    "    league_log_url = (\"http://stats.nba.com/stats/leaguegamelog?Counter=1000&DateFrom=&DateTo=&\" + \n",
    "                  \"Direction=DESC&LeagueID=00&PlayerOrTeam=T&Season=\" + str(season) + \n",
    "                  \"&SeasonType=Regular+Season&Sorter=PTS\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:39.0) Gecko/20100101 Firefox/39.0'}\n",
    "\n",
    "    # Request URL and parse JSON\n",
    "    response = requests.get(league_log_url, headers = headers)\n",
    "    response.raise_for_status() # Raise exception if invalid response\n",
    "    response_json = response.json()\n",
    "    log_list = response_json['resultSets'][0]['rowSet']\n",
    "    header = response_json['resultSets'][0]['headers']\n",
    "    \n",
    "    return (header, log_list)\n",
    "\n",
    "def generate_year_list(start, yrs):\n",
    "    \"\"\" Generate a year list to pass into load_all_gamelogs\n",
    "    Input:\n",
    "        start (int): The first year we are interested in loading\n",
    "        yrs (int): How many years since start that we are including\n",
    "    Output:\n",
    "        (List): List of years\n",
    "    \"\"\"\n",
    "    year_list = []\n",
    "    curr_yr = start\n",
    "    for i in xrange(yrs):\n",
    "        nextyr = curr_yr + 1 \n",
    "        year_list.append(str(curr_yr)+\"-\"+str(nextyr)[2:])\n",
    "        curr_yr = nextyr\n",
    "    return year_list\n",
    "    \n",
    "def load_all_gamelogs(conn, start, yrs):\n",
    "    \"\"\" Load nba gamelog data for the past yrs years as a games tables into an sqlite database given in conn\n",
    "    Input:\n",
    "        conn (sqlite3.Connection): Connection object corresponding to the database; used to perform SQL commands.\n",
    "        yrs (int): Number of years to include in table\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    year_list = generate_year_list(start,yrs)\n",
    "    \n",
    "    # Clear any existing league_log table\n",
    "    cursor.execute('drop table if exists league_log')\n",
    "    \n",
    "    # Create league_log table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS league_log (\n",
    "    season_id TEXT, team_id INTEGER, team_abbreviation TEXT, team_name TEXT, game_id INTEGER,\n",
    "    game_date INTEGER, matchup INTEGER, wl STRING, min INTEGER, fgm INTEGER, fga INTEGER,\n",
    "    fg_pct REAL, fg3m INTEGER, fg3a INTEGER, fg3_pct REAL, ftm INTEGER, fta INTEGER, ft_pct REAL,\n",
    "    oreb INTEGER, dreb INTEGER, reb INTEGER, ast INTEGER, stl INTEGER, blk INTEGER, tov INTEGER,\n",
    "    pf INTEGER, pts INTEGER, plus_minus INTEGER\n",
    "    )\"\"\")\n",
    "    \n",
    "    for year in year_list:\n",
    "        (header, log_list) = get_league_gamelogs(year)\n",
    "        \n",
    "        question_marks = \"(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ,?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        query_string = \"INSERT INTO league_log VALUES \" + question_marks\n",
    "        for log in log_list:\n",
    "            cursor.execute(query_string,\n",
    "                          (log[0],log[1],log[2],log[3],log[4],log[5],log[6],log[7],\n",
    "                          log[8], log[9], log[10], log[11], log[12], log[13], log[14],\n",
    "                          log[15],log[16], log[17], log[18], log[19], log[20], log[21],\n",
    "                          log[22], log[23], log[24], log[25], log[26], log[27]))\n",
    "            \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to database file\n",
    "conn = sqlite3.connect(r\"db/league.db\")\n",
    "conn.text_factory = str\n",
    "\n",
    "# Define relevant years\n",
    "start_year = 1946\n",
    "length = 2017 - start_year\n",
    "\n",
    "load_all_gamelogs(conn, start_year, length)\n",
    "\n",
    "# Load newly stored data into pandas DataFrame league_df\n",
    "league_df = pd.read_sql_query('SELECT * FROM league_log', conn)\n",
    "league_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    \"\"\" Given a DataFrame of league game logs, performs a few sanity checks based upon the number of games \n",
    "        in a season.\n",
    "    Input:\n",
    "        df (pd.DataFrame): league game logs\n",
    "    Output:\n",
    "        str\n",
    "    \"\"\"\n",
    "    year_list = df['season_id'].unique().tolist()\n",
    "    \n",
    "    for year in year_list:\n",
    "        df_temp = df[df['season_id'] == year]\n",
    "        \n",
    "        if year == '22011':\n",
    "            # Lockout year\n",
    "            assert(df_temp.shape[0] == 1980)\n",
    "        elif year == '22016':\n",
    "            # Current ongoing year\n",
    "            continue\n",
    "        elif year >= '22004':\n",
    "            # Normal 30 team, 82 game schedule\n",
    "            assert(df_temp.shape[0] == 2460) \n",
    "    return \"Passed!\"\n",
    "\n",
    "print validate_data(league_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now successfully collected and stored league log data for years ranging from `1946 - 2016`. Further, we have passed a few sanity checks to help ensure the correctness of our data. Notably, the head of league_df contains some NaN values; this is because there is a lack of data availability on certain older years on `stats.nba.com`. We print out the following to show more recent data from the 2005-06 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(league_df[league_df['season_id'] == \"22005\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation\n",
    "Before running any exploratory data analysis, we need to preprocess our dataframe to include a few new columns. This is because each row in our current dataframe only contains data on postgame stats (i.e. points scored, win/loss), and does not contain any data that can be used as predictors before the game started. Based upon intuition and inspiration from other sources (mainly Amorim Torres [1]) we wanted to add the following features/columns:\n",
    "\n",
    "1. is_home (indicator displaying 1 if the given team is playing at home, 0 otherwise)\n",
    "2. opp_team_id (opposing team identifier)\n",
    "3. wl_binary (indicator displaying 1 if the given team won, 0 otherwise)\n",
    "4. home_win_pct (win percentage of the home team prior to the current game)\n",
    "5. away_win_pct (win percentage of the away team prior to the current game)\n",
    "6. home_avg_pt_diff (average point differential of the home team prior to the current game)\n",
    "7. away_avg_pt_diff (average point differential of the away team prior to the current game)\n",
    "8. home_win_pct_N (win percentage of the home team in the last N games prior to the current game)\n",
    "9. away_win_pct_N (win percentage of the away team in the last N games prior to the current game)\n",
    "10. home_win_pct_as_home (win percentage of the home team as home prior to the current game)\n",
    "11. away_win_pct_as_away (win percentage of the away team as away prior to the current game)\n",
    "12. home_back_to_back (indicator displaying 1 if the home team just played the day prior, 0 otherwise)\n",
    "13. away_back_to_back (indicator displaying 1 if the away team just played the day prior, 0 otherwise)\n",
    "14. home_game_count (number of games the home team as played prior to the current game)\n",
    "15. away_game_count (number of games the away team as played prior to the current game)\n",
    "\n",
    "We note that since the dynamics of NBA teams change greatly from season to season, all these features will\n",
    "be season specific. For example, home_win_pct only considers the win percentage of the team in the games\n",
    "within the current season. To create these features, we note that some of the features are not time-sensitive\n",
    "(i.e. 1-3), while the other features 4-15 need to be ordered by time. Because of this, we will divide the\n",
    "preprocessing into two functions, `add_constant_features` and `add_variable_features`, which add the \n",
    "constant features and the time-sensitive features respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_constant_features(league_df):\n",
    "    \"\"\" Given a dataframe league_df, returns new league_df by converting the 'game_date' column to datetime if \n",
    "    necessary, and adds is_home indicator, opp_team_id, and wl_binary indicator\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Convert to datetime, note that this is in place\n",
    "    league_df['game_date'] = league_df['game_date'].apply(pd.to_datetime)\n",
    "    \n",
    "    # Add new columns\n",
    "    is_home = np.zeros(len(league_df), dtype=np.int64)\n",
    "    opp_team_id = np.zeros(len(league_df), dtype=np.int64)\n",
    "    wl_binary = np.zeros(len(league_df), dtype = np.int64)\n",
    "    \n",
    "    league_df = league_df.assign(is_home = is_home)\n",
    "    league_df = league_df.assign(opp_team_id = opp_team_id)\n",
    "    league_df = league_df.assign(wl_binary = wl_binary)\n",
    "    \n",
    "    \n",
    "    # Add home indicator variable\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        matchup = row['matchup']\n",
    "        if \"@\" in matchup:\n",
    "            league_df.set_value(index, \"is_home\", 0)\n",
    "        else:\n",
    "            league_df.set_value(index, \"is_home\", 1)\n",
    "            \n",
    "    # Add opposing team ID\n",
    "    for (index,row) in league_df.iterrows():\n",
    "        game_id = row['game_id']\n",
    "        team_id = row['team_id']\n",
    "        \n",
    "        # Find other game with the same game ID\n",
    "        df_game = league_df[league_df['game_id'] == game_id]\n",
    "        assert(len(df_game) == 2)\n",
    "        found_opp = False\n",
    "        for (inner_index,inner_row) in df_game.iterrows():\n",
    "            curr_team_id = inner_row['team_id']\n",
    "            if curr_team_id == team_id:\n",
    "                continue\n",
    "            else:\n",
    "                # Found opposing team, update opposing team ID\n",
    "                league_df.set_value(index, 'opp_team_id', curr_team_id)\n",
    "                found_opp = True\n",
    "        assert(found_opp)\n",
    "        \n",
    "    # Add binary representation of wins and losses\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        wl = row['wl']\n",
    "        if wl == 'W':\n",
    "            league_df.set_value(index, 'wl_binary', 1)\n",
    "        else:\n",
    "            league_df.set_value(index, 'wl_binary', 0)\n",
    "    \n",
    "    return league_df\n",
    "\n",
    "def add_variable_features(league_df, N=8):\n",
    "    \"\"\" Given a dataframe league_df, returns a new df containing extra columns for each new feature.\n",
    "        If new_years = true, adds features that only work for data frames containing data >= 2005\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        N (int): lookback parameter\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"    \n",
    "    lookback = N\n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    \n",
    "    # Add new columns\n",
    "    home_win_pct = np.zeros(len(new_df))\n",
    "    away_win_pct = np.zeros(len(new_df))\n",
    "    home_avg_pt_diff = np.zeros(len(new_df))\n",
    "    away_avg_pt_diff = np.zeros(len(new_df))\n",
    "    home_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_as_away = np.zeros(len(new_df))\n",
    "    home_win_pct_as_home = np.zeros(len(new_df))\n",
    "    home_back_to_back = np.zeros(len(new_df))\n",
    "    away_back_to_back = np.zeros(len(new_df))\n",
    "    home_game_count = np.zeros(len(new_df))\n",
    "    away_game_count = np.zeros(len(new_df))\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    new_df = new_df.assign(home_win_pct = home_win_pct)\n",
    "    new_df = new_df.assign(away_win_pct = away_win_pct)\n",
    "    new_df = new_df.assign(home_avg_pt_diff = home_avg_pt_diff)\n",
    "    new_df = new_df.assign(away_avg_pt_diff = away_avg_pt_diff)\n",
    "    new_df = new_df.assign(home_win_pct_N = home_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_N = away_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_as_away = away_win_pct_as_away)\n",
    "    new_df = new_df.assign(home_win_pct_as_home = home_win_pct_as_home)\n",
    "    new_df = new_df.assign(home_back_to_back = home_back_to_back)\n",
    "    new_df = new_df.assign(away_back_to_back = away_back_to_back)\n",
    "    new_df = new_df.assign(home_game_count = home_game_count)\n",
    "    new_df = new_df.assign(away_game_count = away_game_count)\n",
    "    \n",
    "    # add features\n",
    "    grouped = new_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        # Initialize dictionary containing wins and losses for each team\n",
    "        win_dict = dict()\n",
    "        lose_dict = dict()\n",
    "        running_dict = dict()\n",
    "        \n",
    "        # Stores list of game dates for each team\n",
    "        running_date_dict = dict()\n",
    "        \n",
    "        # Total plus minus so far\n",
    "        plus_minus_dict = dict()\n",
    "        \n",
    "        # Stores home and away game counts and w/l counts\n",
    "        wins_as_home = dict()\n",
    "        wins_as_away = dict()\n",
    "        games_as_home = dict()\n",
    "        games_as_away = dict()\n",
    "        \n",
    "        running_locations = dict()\n",
    "        \n",
    "        for team in season_df['team_id'].unique():\n",
    "            win_dict[team] = 0\n",
    "            lose_dict[team] = 0\n",
    "            running_dict[team] = []\n",
    "            plus_minus_dict[team] = 0\n",
    "            running_date_dict[team] = []\n",
    "            \n",
    "            # Track wins at home, at away, and total games at home, at away\n",
    "            wins_as_home[team] = 0\n",
    "            wins_as_away[team] = 0\n",
    "            games_as_home[team] = 0\n",
    "            games_as_away[team] = 0\n",
    "        \n",
    "        # Sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "        \n",
    "        seen_games = set()\n",
    "        \n",
    "        for (index, row) in season_df.iterrows():\n",
    "            is_home = row['is_home']\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            wl = row['wl']\n",
    "            game_id = row['game_id']\n",
    "            curr_team_plus_minus = row['plus_minus']\n",
    "            opp_team_plus_minus = -curr_team_plus_minus\n",
    "            game_date = row['game_date']\n",
    "            \n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            if is_home == 1:\n",
    "                home_team_id = team_id\n",
    "                away_team_id = opp_team_id\n",
    "            else:\n",
    "                home_team_id = opp_team_id\n",
    "                away_team_id = team_id\n",
    "                \n",
    "            # Update home_win_pct, away_win_pct\n",
    "            home_win_pct = 0\n",
    "            away_win_pct = 0\n",
    "\n",
    "            if win_dict[home_team_id] + lose_dict[home_team_id] > 0:\n",
    "                home_win_pct = (win_dict[home_team_id])/float(win_dict[home_team_id] + lose_dict[home_team_id])\n",
    "            if win_dict[away_team_id] + lose_dict[away_team_id] > 0:\n",
    "                away_win_pct = (win_dict[away_team_id])/float(win_dict[away_team_id] + lose_dict[away_team_id])\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct', home_win_pct)\n",
    "            new_df.set_value(index, 'away_win_pct', away_win_pct)\n",
    "            \n",
    "            # Update home_win_pct_N, away_win_pct_N\n",
    "            home_win_pct_N = 0\n",
    "            away_win_pct_N = 0\n",
    "            \n",
    "            home_games_count = len(running_dict[home_team_id])\n",
    "            away_games_count = len(running_dict[away_team_id])\n",
    "            \n",
    "            new_df.set_value(index, 'home_game_count', home_games_count)\n",
    "            new_df.set_value(index, 'away_game_count', away_games_count)\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                if home_games_count > lookback:\n",
    "                    lookback_games = running_dict[home_team_id][home_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[home_team_id]\n",
    "                home_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                if away_games_count > lookback:\n",
    "                    lookback_games = running_dict[away_team_id][away_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[away_team_id]\n",
    "                away_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_N', home_win_pct_N)\n",
    "            new_df.set_value(index, 'away_win_pct_N', away_win_pct_N)\n",
    "            \n",
    "            # Update home_avg_pt_diff, away_avg_pt_diff\n",
    "            home_avg_pt_diff = 0\n",
    "            away_avg_pt_diff = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[home_team_id]\n",
    "                home_avg_pt_diff = running_pt_diff/float(home_games_count)\n",
    "            if away_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[away_team_id]\n",
    "                away_avg_pt_diff = running_pt_diff/float(away_games_count)\n",
    "                \n",
    "            new_df.set_value(index, 'home_avg_pt_diff', home_avg_pt_diff)\n",
    "            new_df.set_value(index, 'away_avg_pt_diff', away_avg_pt_diff)\n",
    "            \n",
    "            # Update back-to-back indicators   \n",
    "            home_back_to_back = 0\n",
    "            away_back_to_back = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                most_recent_date = running_date_dict[home_team_id][home_games_count - 1]\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # Back-to-back\n",
    "                    home_back_to_back = 1\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                most_recent_date = running_date_dict[away_team_id][away_games_count - 1]\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # Back-to-back\n",
    "                    away_back_to_back = 1\n",
    "                    \n",
    "            new_df.set_value(index, 'home_back_to_back', home_back_to_back)\n",
    "            new_df.set_value(index, 'away_back_to_back', away_back_to_back)\n",
    "            \n",
    "            # Update home_win_pct_as_home, away_win_pct_as_away\n",
    "            home_win_pct_as_home = 0\n",
    "            away_win_pct_as_away = 0\n",
    "            \n",
    "            home_games_as_home = games_as_home[home_team_id]\n",
    "            away_games_as_away = games_as_away[away_team_id]\n",
    "            \n",
    "            if (home_games_as_home > 0):\n",
    "                home_win_pct_as_home = (wins_as_home[home_team_id])/float(home_games_as_home)\n",
    "            if (away_games_as_away > 0):\n",
    "                away_win_pct_as_away = (wins_as_away[away_team_id])/float(away_games_as_away)\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_as_home', home_win_pct_as_home)\n",
    "            new_df.set_value(index, 'away_win_pct_as_away', away_win_pct_as_away) \n",
    "                \n",
    "            # Update running stats\n",
    "            if (wl == 'W'):\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[team_id] += 1\n",
    "                    lose_dict[opp_team_id] += 1\n",
    "                    running_dict[team_id].append(1)\n",
    "                    running_dict[opp_team_id].append(0)\n",
    "                    \n",
    "                    # Update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_home[team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                    else:\n",
    "                        wins_as_away[team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                    \n",
    "            else:\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[opp_team_id] += 1\n",
    "                    lose_dict[team_id] += 1\n",
    "                    running_dict[opp_team_id].append(1)\n",
    "                    running_dict[team_id].append(0)\n",
    "                    \n",
    "                    # update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_away[opp_team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        \n",
    "                    else:\n",
    "                        wins_as_home[opp_team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "            if game_id in seen_games:\n",
    "                plus_minus_dict[team_id] += curr_team_plus_minus\n",
    "                plus_minus_dict[opp_team_id] += opp_team_plus_minus\n",
    "                running_date_dict[team_id].append(game_date)\n",
    "                running_date_dict[opp_team_id].append(game_date)\n",
    "                \n",
    "#                 if (new_years):\n",
    "#                     running_locations[home_team_id].append(curr_location)\n",
    "#                     running_locations[away_team_id].append(curr_location)\n",
    "                \n",
    "            seen_games.add(game_id)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games = add_variable_features(add_constant_features(league_df))\n",
    "home_games = all_games[all_games['is_home'] == 1]\n",
    "all_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can see some of the new columns we added. However, we see that most of the values are 0, which is expected since the head of the dataframe contains data from the beginning of a season. To display some of our results, we will show the dataframe tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookback Parameter (N) Tuning\n",
    "A crucial parameter in our model is our lookback parameter, which is used in the calcation of the `home_win_pct_N` and `away_win_pct_N` features. The idea behind these features is that team performance may be streaky, either hot or cold. Further, team dynamics change throughout the season, i.e. through injuries and potentially other roster changes. Thus, it is important to not only consider team performance throughout the entire season, but also the recent team performance.\n",
    "\n",
    "To determine which `N` value to use, we will run some basic tests. Naturally, we might ask: if we predicted game results solely on recent game performance, how well would we do for different `N`? By comparing these results, we can\n",
    "isolate the lookback variable and do simple comparisons between different parameter values. We note that this approach was inspired from work from Amorim Torres [1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use svg backend for better quality\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "\n",
    "def add_lookback_features(league_df, params):\n",
    "    \"\"\" Given a dataframe league_df and a list of natural numbers params, returns a new df containing \n",
    "        extra columns for each lookback parameter in params.\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        params (list): list containing positive integers\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\" \n",
    "    \n",
    "    # Ensure correct params formatting\n",
    "    for i in params:\n",
    "        assert (type(i) == int and i > 0)\n",
    "        \n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    \n",
    "    # Initialize new columns\n",
    "    for i in params:\n",
    "        lookback = i\n",
    "        \n",
    "        home_col_name = 'home_win_pct_' + str(i)\n",
    "        away_col_name = 'away_win_pct_' + str(i)\n",
    "        \n",
    "        new_df.loc[:,home_col_name] = np.zeros(len(new_df))\n",
    "        new_df.loc[:,away_col_name] = np.zeros(len(new_df))\n",
    "        \n",
    "        grouped = new_df.groupby(['season_id'])\n",
    "        groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "\n",
    "        for season_df in groupList:\n",
    "            # Initialize dictionary containing wins and losses for each team\n",
    "            running_dict = dict()\n",
    "\n",
    "            for team in season_df['team_id'].unique():\n",
    "                running_dict[team] = []\n",
    "\n",
    "            # Sort season by day\n",
    "            season_df = season_df.sort_values('game_date')\n",
    "\n",
    "            seen_games = set()\n",
    "            \n",
    "            for (index, row) in season_df.iterrows():\n",
    "                team_id = row['team_id']\n",
    "                opp_team_id = row['opp_team_id']\n",
    "                wl = row['wl']\n",
    "                game_id = row['game_id']\n",
    "                is_home = row['is_home']\n",
    "                \n",
    "                if is_home == 1:\n",
    "                    home_team_id = team_id\n",
    "                    away_team_id = opp_team_id\n",
    "                else:\n",
    "                    home_team_id = opp_team_id\n",
    "                    away_team_id = team_id\n",
    "                \n",
    "                # Update home_win_pct_N, away_win_pct_N\n",
    "                home_win_pct_N = 0\n",
    "                away_win_pct_N = 0\n",
    "                \n",
    "                home_games_count = len(running_dict[home_team_id])\n",
    "                away_games_count = len(running_dict[away_team_id])\n",
    "\n",
    "                if home_games_count > 0:\n",
    "                    if home_games_count > lookback:\n",
    "                        lookback_games = running_dict[home_team_id][home_games_count - lookback:]\n",
    "                    else:\n",
    "                        lookback_games = running_dict[home_team_id]\n",
    "                    home_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "\n",
    "                if away_games_count > 0:\n",
    "                    if away_games_count > lookback:\n",
    "                        lookback_games = running_dict[away_team_id][away_games_count - lookback:]\n",
    "                    else:\n",
    "                        lookback_games = running_dict[away_team_id]\n",
    "                    away_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "\n",
    "                new_df.set_value(index, home_col_name, home_win_pct_N)\n",
    "                new_df.set_value(index, away_col_name, away_win_pct_N)\n",
    "                \n",
    "                # Update running stats\n",
    "                if (wl == 'W'):\n",
    "                    if game_id in seen_games:\n",
    "                        running_dict[team_id].append(1)\n",
    "                        running_dict[opp_team_id].append(0)\n",
    "\n",
    "                else:\n",
    "                    if game_id in seen_games:\n",
    "                        running_dict[opp_team_id].append(1)\n",
    "                        running_dict[team_id].append(0)\n",
    "                        \n",
    "                seen_games.add(game_id)\n",
    "    return new_df\n",
    "\n",
    "def graph_lookback(league_df, params):\n",
    "    \"\"\" Given a dataframe league_df, a season_id, and a list of natural numbers params, graphs the effectiveness\n",
    "        of using each of the params as a naive classifier\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs, including the lookback columns from params\n",
    "        season_id (str): season identifier\n",
    "        params (list): sorted list containing positive integers\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\" \n",
    "    grouped = league_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        # Initialize dictionary counting number of correct classifications for each param i\n",
    "        correct_dict = dict()\n",
    "\n",
    "        for i in params:\n",
    "            correct_dict[i] = 0\n",
    "\n",
    "        # Sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "\n",
    "        #seen_games = set()\n",
    "        \n",
    "        season_id = \"\"\n",
    "\n",
    "        for (index, row) in season_df.iterrows():\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            wl = row['wl_binary']\n",
    "            game_id = row['game_id']\n",
    "            is_home = row['is_home']\n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            \n",
    "            for i in params:\n",
    "                home_col_name = 'home_win_pct_' + str(i)\n",
    "                away_col_name = 'away_win_pct_' + str(i)\n",
    "                \n",
    "                home_pct = row[home_col_name]\n",
    "                away_pct = row[away_col_name]\n",
    "                \n",
    "                if (is_home == 1 and wl == 1 and home_pct >= away_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 1 and wl == 0 and away_pct > home_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 0 and wl == 1 and away_pct > home_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 0 and wl == 0 and home_pct >= away_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                    \n",
    "        pct_list = []\n",
    "        for i in params:\n",
    "            pct_list.append(correct_dict[i]/float(len(season_df)))\n",
    "            \n",
    "        ax.plot(params, pct_list, label = season_id[1:])\n",
    "        \n",
    "    ax.set_xlabel(\"Lookback Parameter (N)\", fontsize=15)\n",
    "    ax.set_ylabel(\"Classification Accuracy\", fontsize=18)\n",
    "    \n",
    "    fig.suptitle('Classification Accuracy Using Different Lookback Parameters', fontsize = 18)\n",
    "    \n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        \n",
    "    plt.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games_lookback = add_lookback_features(all_games, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "all_games_lookback.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_df = all_games_lookback[all_games_lookback[\"season_id\"] >= \"22004\"]\n",
    "graph_lookback(temp_df, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel Distance (2005+)\n",
    "One potential useful feature is the distance traveled by a team to get to the current location. This is related to fatigue, as teams will likely be tired from the flights, and the time zone changes can be distorting. We wish to add features `home_mileage` and `away_mileage` to indicate the number of miles the team traveled to get to the current game.\n",
    "\n",
    "To do this, we will use the library geopy to get coordinates and to calculate distances (distance will be calculated using the vincenty formula). We will need to manually create dictionaries mapping teams to locations. Because these need to be manually created, we limit the year scope to include on 2005+. We do not think this limitation will be significant since we know that recent years are the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "# Only consider years after 2005\n",
    "temp_df = all_games[all_games['season_id'] >= '22005']\n",
    "team_names = temp_df['team_name'].unique().tolist()\n",
    "#print len(team_names), team_names\n",
    "\n",
    "team_id_list = temp_df['team_id'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping of team_id to team_name\n",
    "id_team = dict()\n",
    "for team_id in team_id_list:\n",
    "    temp_df_1 = temp_df[temp_df['team_id'] == team_id]\n",
    "    id_team[team_id] = temp_df_1['team_name'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping of team_name to seasons\n",
    "team_seasons = dict()\n",
    "for team_name in team_names:\n",
    "    temp_df_1 = temp_df[temp_df['team_name'] == team_name]\n",
    "    team_seasons[team_name] = temp_df_1['season_id'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping team name to location\n",
    "name_location = {'Dallas Mavericks': 'Dallas, Texas',\n",
    "                'New Orleans/Oklahoma City Hornets': 'Oklahoma City, Oklahoma',\n",
    "                'Milwaukee Bucks': 'Milwaukee, Wisconsin',\n",
    "                'San Antonio Spurs': 'San Antonio, Texas',\n",
    "                'Philadelphia 76ers': 'Philadelphia, Pennsylvania',\n",
    "                'Phoenix Suns': 'Phoenix, Arizona',\n",
    "                'Denver Nuggets': 'Denver, Colorado',\n",
    "                'Sacramento Kings': 'Sacramento, California',\n",
    "                'Atlanta Hawks': 'Atlanta, Georgia',\n",
    "                'Miami Heat' : 'Miami, Florida', \n",
    "                'Toronto Raptors': 'Toronto, Ontario', \n",
    "                'New Jersey Nets': 'Newark, New Jersey', \n",
    "                'Houston Rockets': 'Houston, Texas', \n",
    "                'Boston Celtics': 'Boston, Massachusetts', \n",
    "                'Golden State Warriors' : 'Oakland, California', \n",
    "                'Utah Jazz': 'Salt Lake City, Utah', \n",
    "                'Seattle SuperSonics' : 'Seattle, Washington', \n",
    "                'Portland Trail Blazers': 'Portland, Oregon', \n",
    "                'Indiana Pacers' : 'Indianapolis, Indiana', \n",
    "                'Minnesota Timberwolves' : 'Minneapolis, Minnesota', \n",
    "                'Washington Wizards': 'Washington D.C., Virginia',\n",
    "                'Chicago Bulls' : 'Chicago, Illinois', \n",
    "                'New York Knicks': 'New York City, New York', \n",
    "                'Cleveland Cavaliers' : 'Cleveland, Ohio', \n",
    "                'Charlotte Bobcats' : 'Charlotte, North Carolina',\n",
    "                'Detroit Pistons' : 'Detroit, Michigan', \n",
    "                'Memphis Grizzlies' : 'Memphis, Tennessee', \n",
    "                'Orlando Magic' : 'Orlando, Florida', \n",
    "                'Los Angeles Clippers' : 'Los Angeles, California', \n",
    "                'Los Angeles Lakers' : 'Los Angeles, California', \n",
    "                'New Orleans Hornets' : 'New Orleans, Louisiana', \n",
    "                'Oklahoma City Thunder': 'Oklahoma City, Oklahoma', \n",
    "                'Brooklyn Nets': 'Brooklyn, New York', \n",
    "                'New Orleans Pelicans' : 'New Orleans, Louisiana', \n",
    "                'Charlotte Hornets' : 'Charlotte, North Carolina', \n",
    "                'LA Clippers' : 'Los Angeles, California'}\n",
    "\n",
    "# Dictionary mapping location to (latitude, longitude)\n",
    "location_latlong = dict()\n",
    "geolocator = Nominatim()\n",
    "for key,value in name_location.iteritems():\n",
    "    geo_loc = geolocator.geocode(value)\n",
    "    (lat1, long1) = (geo_loc.latitude, geo_loc.longitude)\n",
    "    location_latlong[value] = (lat1,long1)\n",
    "    \n",
    "def get_team_location(team_id, season_id):\n",
    "    \"\"\" Given a team id and the season_id, returns a string containing the location of the team stadium\n",
    "    Input: \n",
    "        team_id (int): team id\n",
    "        season_id (str): season id \n",
    "    Output:\n",
    "        (str) \n",
    "    \"\"\"\n",
    "    names = id_team[team_id]\n",
    "    \n",
    "    team_name = None\n",
    "    \n",
    "    for name in names:\n",
    "        seasons = team_seasons[name]\n",
    "        #print seasons, name\n",
    "        if season_id in seasons:\n",
    "            team_name = name\n",
    "            \n",
    "    if team_name == None:\n",
    "        print (team_id, season_id, names)\n",
    "        assert(False)\n",
    "    \n",
    "    return name_location[team_name]\n",
    "\n",
    "def add_mileage(league_df):\n",
    "    geolocator = Nominatim()\n",
    "    seen_distances = dict()\n",
    "    \n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    new_df = new_df.assign(home_mileage = home_mileage)\n",
    "    new_df = new_df.assign(away_mileage = away_mileage)\n",
    "    \n",
    "\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    # Ddd features\n",
    "    grouped = new_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        running_locations = dict()\n",
    "        \n",
    "        for team in season_df['team_id'].unique():\n",
    "            # track list of locations played at\n",
    "            running_locations[team] = []\n",
    "        \n",
    "        # sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "        \n",
    "        seen_games = set()\n",
    "        \n",
    "        for (index, row) in season_df.iterrows():\n",
    "            is_home = row['is_home']\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            game_id = row['game_id']\n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            if is_home == 1:\n",
    "                home_team_id = team_id\n",
    "                away_team_id = opp_team_id\n",
    "            else:\n",
    "                home_team_id = opp_team_id\n",
    "                away_team_id = team_id\n",
    "                \n",
    "            \n",
    "            home_games_count = row['home_game_count']\n",
    "            away_games_count = row['away_game_count']\n",
    "            \n",
    "            home_mileage = 0\n",
    "            away_mileage = 0\n",
    "            \n",
    "            curr_location = get_team_location(home_team_id, season_id)\n",
    "\n",
    "            (curr_lat, curr_long) = location_latlong[curr_location]\n",
    "\n",
    "            if home_games_count > 0:\n",
    "                location_list = running_locations[home_team_id]\n",
    "                assert(len(location_list) == home_games_count)\n",
    "                last_location = location_list[len(location_list) - 1]\n",
    "                (last_lat, last_long) = location_latlong[last_location]\n",
    "\n",
    "                str1 = curr_location + last_location\n",
    "                str2 = last_location + curr_location\n",
    "\n",
    "                if str1 in seen_distances:\n",
    "                    home_mileage = seen_distances[str1]\n",
    "                elif str2 in seen_distances:\n",
    "                    home_mileage = seen_distances[str2]\n",
    "                else:\n",
    "                    home_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                    seen_distances[str1] = home_mileage\n",
    "\n",
    "            if away_games_count > 0:\n",
    "                location_list = running_locations[away_team_id]\n",
    "                assert(len(location_list) == away_games_count)\n",
    "                last_location = location_list[len(location_list) - 1]\n",
    "\n",
    "                (last_lat, last_long) = location_latlong[last_location]\n",
    "\n",
    "                str1 = curr_location + last_location\n",
    "                str2 = last_location + curr_location\n",
    "\n",
    "                if str1 in seen_distances:\n",
    "                    away_mileage = seen_distances[str1]\n",
    "                elif str2 in seen_distances:\n",
    "                    away_mileage = seen_distances[str2]\n",
    "                else:\n",
    "                    away_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                    seen_distances[str1] = away_mileage\n",
    "\n",
    "            new_df.set_value(index, 'home_mileage', home_mileage)\n",
    "            new_df.set_value(index, 'away_mileage', away_mileage)\n",
    "            \n",
    "            if game_id in seen_games:\n",
    "                running_locations[home_team_id].append(curr_location)\n",
    "                running_locations[away_team_id].append(curr_location)\n",
    "                \n",
    "            seen_games.add(game_id)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mileage_df = add_mileage(all_games[all_games['season_id']>='22005'])\n",
    "mileage_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "1. `http://homepages.cae.wisc.edu/~ece539/fall13/project/AmorimTorres_rpt.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$$$$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
