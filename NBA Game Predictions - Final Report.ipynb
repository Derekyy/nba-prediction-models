{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Game Predictions - Final Report\n",
    "## Kevin Yang, Eric Lee, Derek Young\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction\n",
    "The NBA ([National Basketball Association](http://nba.com)) is an American based men's basketball league that is considered to be the leading basketball league in the world. As of the 2016-2017 season, there are 30 teams divided into two conferences (and further divided into six divisions). Each team participates in 82 regular season games, with additional games for teams who make the playoffs, where seven-game series are played between contenders until a champion is determined.\n",
    "\n",
    "With technology at it's forefront, there has been a growth of data collection on NBA games, teams and players. NBA fans and analysts have access to almost any statistic imaginable that the league collects. Our main objective is to utilize machine learning techniques to predict which team will win each regular season game. We will focus on Linear Regression, Logistic Regression and Support Vector Machines for our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Report Contents\"></a>\n",
    "## Report Contents\n",
    "\n",
    "1. [Data Collection](#Data Collection)\n",
    "2. [Feature Creation](#Feature Creation)\n",
    "    1. [Preprocessing Constant Features](#Preprocessing)\n",
    "    2. [Adding Time-Sensitive Features](#Adding Time-Sesitive Features)\n",
    "3. [Exploratory Data Analysis](#EDA)\n",
    "    1. [Univariate Analysis](#Univariate Analysis)\n",
    "    1. [Bivariate Analysis](#Bivariate Analysis)\n",
    "    2. [Back-to-back games: Significance](#Back-to-Back)\n",
    "    3. [The NBA over Time](#The NBA over Time)\n",
    "4. [Feature Selection](#Feature Selection)\n",
    "    1. [Training Cutoff](#Training Cutoff)\n",
    "    2. [\"N-Previous Games\" Tuning](#N-Previous Games)\n",
    "5. [Additional Features](#Additional Features)\n",
    "    1. [Altitude](#Altitude)\n",
    "    2. [Travel Distance](#Travel Distance)\n",
    "6. [Modeling](#Modeling)\n",
    "    1. [Naive Approach](#Naive Approach)\n",
    "    2. [Linear Regression](#Linear Regression)\n",
    "    3. [Logistic Regression](#Logistic Regression)\n",
    "    4. [Support Vector Machines](#SVM)\n",
    "7. [Concluding Thoughts]()\n",
    "\n",
    "\n",
    "While most of our project is written in Python, a certain subset was done in R, specifically modeling linear and logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data Collection'></a>\n",
    "## 1. Data Collection\n",
    "\n",
    "We found our data on [stats.nba.com](http://stats.nba.com). First, we surveyed the webpage, finding the location and organization of data. Using Google Chrome Developer Tools, we found link structures and JSON responses containing useful data for our models (Shown in code below).\n",
    "\n",
    "Once we found a scalable approach to get all team game data for any NBA season, we decided that the best approach would be storing our data in a local `sqlite3` database upon scraping and collecting appropriate data. We found this to be a consistent and reliable approach to our data analysis, as our data does not run the risk of changing unexpectedly, and we do not have to worry about overloading any servers with too many requests. We write the functions `get_league_gamelogs`, `generate_year_list`, and `load_all_gamelogs` to collect and then store our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def get_league_gamelogs(season):\n",
    "    \"\"\" Given a season (string, ex: 2016-17), returns a (header, log_list) where the header represents a \n",
    "        key describing the format of the logs in log_list\n",
    "    Input:\n",
    "        season (str): season string, ex: '2016-17'\n",
    "    Output:\n",
    "        (list, dict)\n",
    "    \"\"\"\n",
    "    league_log_url = (\"http://stats.nba.com/stats/leaguegamelog?Counter=1000&DateFrom=&DateTo=&\" + \n",
    "                  \"Direction=DESC&LeagueID=00&PlayerOrTeam=T&Season=\" + str(season) + \n",
    "                  \"&SeasonType=Regular+Season&Sorter=PTS\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:39.0) Gecko/20100101 Firefox/39.0'}\n",
    "\n",
    "    # Request URL and parse JSON\n",
    "    response = requests.get(league_log_url, headers = headers)\n",
    "    response.raise_for_status() # Raise exception if invalid response\n",
    "    response_json = response.json()\n",
    "    log_list = response_json['resultSets'][0]['rowSet']\n",
    "    header = response_json['resultSets'][0]['headers']\n",
    "    \n",
    "    return (header, log_list)\n",
    "\n",
    "def generate_year_list(start, yrs):\n",
    "    \"\"\" Generate a year list to pass into load_all_gamelogs\n",
    "    Input:\n",
    "        start (int): The first year we are interested in loading\n",
    "        yrs (int): How many years since start that we are including\n",
    "    Output:\n",
    "        (List): List of years\n",
    "    \"\"\"\n",
    "    year_list = []\n",
    "    curr_yr = start\n",
    "    for i in xrange(yrs):\n",
    "        nextyr = curr_yr + 1 \n",
    "        year_list.append(str(curr_yr)+\"-\"+str(nextyr)[2:])\n",
    "        curr_yr = nextyr\n",
    "    return year_list\n",
    "    \n",
    "def load_all_gamelogs(conn, start, yrs):\n",
    "    \"\"\" Load nba gamelog data for the past yrs years as a games tables into an sqlite database given in conn\n",
    "    Input:\n",
    "        conn (sqlite3.Connection): Connection object corresponding to the database; used to perform SQL commands.\n",
    "        yrs (int): Number of years to include in table\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    year_list = generate_year_list(start,yrs)\n",
    "    \n",
    "    # Clear any existing league_log table\n",
    "    cursor.execute('drop table if exists league_log')\n",
    "    \n",
    "    # Create league_log table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS league_log (\n",
    "    season_id TEXT, team_id INTEGER, team_abbreviation TEXT, team_name TEXT, game_id INTEGER,\n",
    "    game_date INTEGER, matchup INTEGER, wl STRING, min INTEGER, fgm INTEGER, fga INTEGER,\n",
    "    fg_pct REAL, fg3m INTEGER, fg3a INTEGER, fg3_pct REAL, ftm INTEGER, fta INTEGER, ft_pct REAL,\n",
    "    oreb INTEGER, dreb INTEGER, reb INTEGER, ast INTEGER, stl INTEGER, blk INTEGER, tov INTEGER,\n",
    "    pf INTEGER, pts INTEGER, plus_minus INTEGER\n",
    "    )\"\"\")\n",
    "    \n",
    "    for year in year_list:\n",
    "        (header, log_list) = get_league_gamelogs(year)\n",
    "        \n",
    "        question_marks = \"(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ,?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        query_string = \"INSERT INTO league_log VALUES \" + question_marks\n",
    "        for log in log_list:\n",
    "            cursor.execute(query_string,\n",
    "                          (log[0],log[1],log[2],log[3],log[4],log[5],log[6],log[7],\n",
    "                          log[8], log[9], log[10], log[11], log[12], log[13], log[14],\n",
    "                          log[15],log[16], log[17], log[18], log[19], log[20], log[21],\n",
    "                          log[22], log[23], log[24], log[25], log[26], log[27]))\n",
    "            \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to database file\n",
    "conn = sqlite3.connect(r\"db/league.db\")\n",
    "conn.text_factory = str\n",
    "\n",
    "# Define relevant years\n",
    "start_year = 1946\n",
    "length = 2017 - start_year\n",
    "\n",
    "load_all_gamelogs(conn, start_year, length)\n",
    "\n",
    "# Load newly stored data into pandas DataFrame league_df\n",
    "league_df = pd.read_sql_query('SELECT * FROM league_log', conn)\n",
    "league_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    \"\"\" Given a DataFrame of league game logs, performs a few sanity checks based upon the number of games \n",
    "        in a season.\n",
    "    Input:\n",
    "        df (pd.DataFrame): league game logs\n",
    "    Output:\n",
    "        str\n",
    "    \"\"\"\n",
    "    year_list = df['season_id'].unique().tolist()\n",
    "    \n",
    "    for year in year_list:\n",
    "        df_temp = df[df['season_id'] == year]\n",
    "        \n",
    "        if year == '22011':\n",
    "            # Lockout year\n",
    "            assert(df_temp.shape[0] == 1980)\n",
    "        elif year == '22016':\n",
    "            # Current ongoing year\n",
    "            continue\n",
    "        elif year >= '22004':\n",
    "            # Normal 30 team, 82 game schedule\n",
    "            assert(df_temp.shape[0] == 2460) \n",
    "    return \"Passed!\"\n",
    "\n",
    "print validate_data(league_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now successfully collected and stored league log data for years ranging from `1946-2016`. Further, we have passed a few sanity checks to help ensure the correctness of our data. Notably, the head of league_df contains some NaN values; this is because there is a lack of data availability on certain older years on `stats.nba.com`. We print out the following to show more recent data from the 2005-06 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(league_df[league_df['season_id'] == \"22005\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Feature Creation'></a>\n",
    "## 2. Feature Creation\n",
    "Before any exploratory data analysis, we need to preprocess our dataframe to include a few new columns. This is because each row in our current dataframe only contains data on postgame stats (i.e. points scored, win/loss), and does not contain any data that can be used as predictors before the game started. Based upon intuition and inspiration from other sources (mainly Amorim Torres [1]) we wanted to add the following features/columns:\n",
    "\n",
    "1. is_home (1 if the team is playing at home, 0 otherwise)\n",
    "2. opp_team_id (opposing team identifier)\n",
    "3. wl_binary (1 if the team won, 0 otherwise)\n",
    "4. home_win_pct (win percentage of the home team prior to the current game)\n",
    "5. away_win_pct (win percentage of the away team prior to the current game)\n",
    "6. home_avg_pt_diff (average point differential of the home team prior to the current game)\n",
    "7. away_avg_pt_diff (average point differential of the away team prior to the current game)\n",
    "8. home_win_pct_N (win percentage of the home team in the last N games prior to the current game)\n",
    "9. away_win_pct_N (win percentage of the away team in the last N games prior to the current game)\n",
    "10. home_win_pct_as_home (win percentage of the home team as home prior to the current game)\n",
    "11. away_win_pct_as_away (win percentage of the away team as away prior to the current game)\n",
    "12. home_back_to_back (1 if the home team just played the day prior, 0 otherwise)\n",
    "13. away_back_to_back (1 if the away team just played the day prior, 0 otherwise)\n",
    "14. home_game_count (# games the home team as played prior to the current game)\n",
    "15. away_game_count (# games the away team as played prior to the current game)\n",
    "\n",
    "Since the dynamics of NBA teams change greatly from season to season, all these features will\n",
    "be season specific. For example, home_win_pct only considers the win percentage of the team in the games\n",
    "within the current season. To create these features, we note that some of the features are not time-sensitive\n",
    "(i.e. 1-3), while the other features 4-15 need to be ordered by time. Because of this, we will divide the\n",
    "preprocessing into two functions, `add_constant_features` and `add_variable_features`, which add the \n",
    "constant features and the time-sensitive features respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preprocessing'></a>\n",
    "### 2A. Preprocessing Constant Features\n",
    "First add the constant features (1-3 in the above list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_constant_features(league_df):\n",
    "    \"\"\" Given a dataframe league_df, returns new league_df by converting the 'game_date' column to datetime if \n",
    "    necessary, and adds is_home indicator, opp_team_id, and wl_binary indicator\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Convert to datetime, note that this is in place\n",
    "    league_df['game_date'] = league_df['game_date'].apply(pd.to_datetime)\n",
    "    \n",
    "    # Add new columns\n",
    "    is_home = np.zeros(len(league_df), dtype=np.int64)\n",
    "    opp_team_id = np.zeros(len(league_df), dtype=np.int64)\n",
    "    wl_binary = np.zeros(len(league_df), dtype = np.int64)\n",
    "    \n",
    "    league_df = league_df.assign(is_home = is_home)\n",
    "    league_df = league_df.assign(opp_team_id = opp_team_id)\n",
    "    league_df = league_df.assign(wl_binary = wl_binary)\n",
    "    \n",
    "    \n",
    "    # Add home indicator variable\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        matchup = row['matchup']\n",
    "        if \"@\" in matchup:\n",
    "            league_df.set_value(index, \"is_home\", 0)\n",
    "        else:\n",
    "            league_df.set_value(index, \"is_home\", 1)\n",
    "            \n",
    "    # Add opposing team ID\n",
    "    for (index,row) in league_df.iterrows():\n",
    "        game_id = row['game_id']\n",
    "        team_id = row['team_id']\n",
    "        \n",
    "        # Find other game with the same game ID\n",
    "        df_game = league_df[league_df['game_id'] == game_id]\n",
    "        assert(len(df_game) == 2)\n",
    "        found_opp = False\n",
    "        for (inner_index,inner_row) in df_game.iterrows():\n",
    "            curr_team_id = inner_row['team_id']\n",
    "            if curr_team_id == team_id:\n",
    "                continue\n",
    "            else:\n",
    "                # Found opposing team, update opposing team ID\n",
    "                league_df.set_value(index, 'opp_team_id', curr_team_id)\n",
    "                found_opp = True\n",
    "        assert(found_opp)\n",
    "        \n",
    "    # Add binary representation of wins and losses\n",
    "    for (index, row) in league_df.iterrows():\n",
    "        wl = row['wl']\n",
    "        if wl == 'W':\n",
    "            league_df.set_value(index, 'wl_binary', 1)\n",
    "        else:\n",
    "            league_df.set_value(index, 'wl_binary', 0)\n",
    "    \n",
    "    return league_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Adding Time-Sesitive Features'></a>\n",
    "### 2B. Adding Time Sensitive Features\n",
    "Continue adding to our dataframe (4-15 in the list above). We use N = 8 as our lookback parameter (discused in the next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_variable_features(league_df, N=8):\n",
    "    \"\"\" Given a dataframe league_df, returns a new df containing extra columns for each new feature.\n",
    "        If new_years = true, adds features that only work for data frames containing data >= 2005\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        N (int): lookback parameter\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"    \n",
    "    lookback = N\n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    \n",
    "    # Add new columns\n",
    "    home_win_pct = np.zeros(len(new_df))\n",
    "    away_win_pct = np.zeros(len(new_df))\n",
    "    home_avg_pt_diff = np.zeros(len(new_df))\n",
    "    away_avg_pt_diff = np.zeros(len(new_df))\n",
    "    home_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_N = np.zeros(len(new_df))\n",
    "    away_win_pct_as_away = np.zeros(len(new_df))\n",
    "    home_win_pct_as_home = np.zeros(len(new_df))\n",
    "    home_back_to_back = np.zeros(len(new_df))\n",
    "    away_back_to_back = np.zeros(len(new_df))\n",
    "    home_game_count = np.zeros(len(new_df))\n",
    "    away_game_count = np.zeros(len(new_df))\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    new_df = new_df.assign(home_win_pct = home_win_pct)\n",
    "    new_df = new_df.assign(away_win_pct = away_win_pct)\n",
    "    new_df = new_df.assign(home_avg_pt_diff = home_avg_pt_diff)\n",
    "    new_df = new_df.assign(away_avg_pt_diff = away_avg_pt_diff)\n",
    "    new_df = new_df.assign(home_win_pct_N = home_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_N = away_win_pct_N)\n",
    "    new_df = new_df.assign(away_win_pct_as_away = away_win_pct_as_away)\n",
    "    new_df = new_df.assign(home_win_pct_as_home = home_win_pct_as_home)\n",
    "    new_df = new_df.assign(home_back_to_back = home_back_to_back)\n",
    "    new_df = new_df.assign(away_back_to_back = away_back_to_back)\n",
    "    new_df = new_df.assign(home_game_count = home_game_count)\n",
    "    new_df = new_df.assign(away_game_count = away_game_count)\n",
    "    \n",
    "    # add features\n",
    "    grouped = new_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        # Initialize dictionary containing wins and losses for each team\n",
    "        win_dict = dict()\n",
    "        lose_dict = dict()\n",
    "        running_dict = dict()\n",
    "        \n",
    "        # Stores list of game dates for each team\n",
    "        running_date_dict = dict()\n",
    "        \n",
    "        # Total plus minus so far\n",
    "        plus_minus_dict = dict()\n",
    "        \n",
    "        # Stores home and away game counts and w/l counts\n",
    "        wins_as_home = dict()\n",
    "        wins_as_away = dict()\n",
    "        games_as_home = dict()\n",
    "        games_as_away = dict()\n",
    "        \n",
    "        running_locations = dict()\n",
    "        \n",
    "        for team in season_df['team_id'].unique():\n",
    "            win_dict[team] = 0\n",
    "            lose_dict[team] = 0\n",
    "            running_dict[team] = []\n",
    "            plus_minus_dict[team] = 0\n",
    "            running_date_dict[team] = []\n",
    "            \n",
    "            # Track wins at home, at away, and total games at home, at away\n",
    "            wins_as_home[team] = 0\n",
    "            wins_as_away[team] = 0\n",
    "            games_as_home[team] = 0\n",
    "            games_as_away[team] = 0\n",
    "        \n",
    "        # Sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "        \n",
    "        seen_games = set()\n",
    "        \n",
    "        for (index, row) in season_df.iterrows():\n",
    "            is_home = row['is_home']\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            wl = row['wl']\n",
    "            game_id = row['game_id']\n",
    "            curr_team_plus_minus = row['plus_minus']\n",
    "            opp_team_plus_minus = -curr_team_plus_minus\n",
    "            game_date = row['game_date']\n",
    "            \n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            if is_home == 1:\n",
    "                home_team_id = team_id\n",
    "                away_team_id = opp_team_id\n",
    "            else:\n",
    "                home_team_id = opp_team_id\n",
    "                away_team_id = team_id\n",
    "                \n",
    "            # Update home_win_pct, away_win_pct\n",
    "            home_win_pct = 0\n",
    "            away_win_pct = 0\n",
    "\n",
    "            if win_dict[home_team_id] + lose_dict[home_team_id] > 0:\n",
    "                home_win_pct = (win_dict[home_team_id])/float(win_dict[home_team_id] + lose_dict[home_team_id])\n",
    "            if win_dict[away_team_id] + lose_dict[away_team_id] > 0:\n",
    "                away_win_pct = (win_dict[away_team_id])/float(win_dict[away_team_id] + lose_dict[away_team_id])\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct', home_win_pct)\n",
    "            new_df.set_value(index, 'away_win_pct', away_win_pct)\n",
    "            \n",
    "            # Update home_win_pct_N, away_win_pct_N\n",
    "            home_win_pct_N = 0\n",
    "            away_win_pct_N = 0\n",
    "            \n",
    "            home_games_count = len(running_dict[home_team_id])\n",
    "            away_games_count = len(running_dict[away_team_id])\n",
    "            \n",
    "            new_df.set_value(index, 'home_game_count', home_games_count)\n",
    "            new_df.set_value(index, 'away_game_count', away_games_count)\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                if home_games_count > lookback:\n",
    "                    lookback_games = running_dict[home_team_id][home_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[home_team_id]\n",
    "                home_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                if away_games_count > lookback:\n",
    "                    lookback_games = running_dict[away_team_id][away_games_count - lookback:]\n",
    "                else:\n",
    "                    lookback_games = running_dict[away_team_id]\n",
    "                away_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_N', home_win_pct_N)\n",
    "            new_df.set_value(index, 'away_win_pct_N', away_win_pct_N)\n",
    "            \n",
    "            # Update home_avg_pt_diff, away_avg_pt_diff\n",
    "            home_avg_pt_diff = 0\n",
    "            away_avg_pt_diff = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[home_team_id]\n",
    "                home_avg_pt_diff = running_pt_diff/float(home_games_count)\n",
    "            if away_games_count > 0:\n",
    "                running_pt_diff = plus_minus_dict[away_team_id]\n",
    "                away_avg_pt_diff = running_pt_diff/float(away_games_count)\n",
    "                \n",
    "            new_df.set_value(index, 'home_avg_pt_diff', home_avg_pt_diff)\n",
    "            new_df.set_value(index, 'away_avg_pt_diff', away_avg_pt_diff)\n",
    "            \n",
    "            # Update back-to-back indicators   \n",
    "            home_back_to_back = 0\n",
    "            away_back_to_back = 0\n",
    "            \n",
    "            if home_games_count > 0:\n",
    "                most_recent_date = running_date_dict[home_team_id][home_games_count - 1]\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # Back-to-back\n",
    "                    home_back_to_back = 1\n",
    "                \n",
    "            if away_games_count > 0:\n",
    "                most_recent_date = running_date_dict[away_team_id][away_games_count - 1]\n",
    "                \n",
    "                if game_date.toordinal() - most_recent_date.toordinal() == 1:\n",
    "                    # Back-to-back\n",
    "                    away_back_to_back = 1\n",
    "                    \n",
    "            new_df.set_value(index, 'home_back_to_back', home_back_to_back)\n",
    "            new_df.set_value(index, 'away_back_to_back', away_back_to_back)\n",
    "            \n",
    "            # Update home_win_pct_as_home, away_win_pct_as_away\n",
    "            home_win_pct_as_home = 0\n",
    "            away_win_pct_as_away = 0\n",
    "            \n",
    "            home_games_as_home = games_as_home[home_team_id]\n",
    "            away_games_as_away = games_as_away[away_team_id]\n",
    "            \n",
    "            if (home_games_as_home > 0):\n",
    "                home_win_pct_as_home = (wins_as_home[home_team_id])/float(home_games_as_home)\n",
    "            if (away_games_as_away > 0):\n",
    "                away_win_pct_as_away = (wins_as_away[away_team_id])/float(away_games_as_away)\n",
    "                \n",
    "            new_df.set_value(index, 'home_win_pct_as_home', home_win_pct_as_home)\n",
    "            new_df.set_value(index, 'away_win_pct_as_away', away_win_pct_as_away) \n",
    "                \n",
    "            # Update running stats\n",
    "            if (wl == 'W'):\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[team_id] += 1\n",
    "                    lose_dict[opp_team_id] += 1\n",
    "                    running_dict[team_id].append(1)\n",
    "                    running_dict[opp_team_id].append(0)\n",
    "                    \n",
    "                    # Update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_home[team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                    else:\n",
    "                        wins_as_away[team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                    \n",
    "            else:\n",
    "                if game_id in seen_games:\n",
    "                    win_dict[opp_team_id] += 1\n",
    "                    lose_dict[team_id] += 1\n",
    "                    running_dict[opp_team_id].append(1)\n",
    "                    running_dict[team_id].append(0)\n",
    "                    \n",
    "                    # update home team and away team w/l\n",
    "                    if is_home == 1:\n",
    "                        wins_as_away[opp_team_id] += 1\n",
    "                        games_as_away[opp_team_id] += 1\n",
    "                        games_as_home[team_id] += 1\n",
    "                        \n",
    "                    else:\n",
    "                        wins_as_home[opp_team_id] += 1\n",
    "                        games_as_home[opp_team_id] += 1\n",
    "                        games_as_away[team_id] += 1\n",
    "            if game_id in seen_games:\n",
    "                plus_minus_dict[team_id] += curr_team_plus_minus\n",
    "                plus_minus_dict[opp_team_id] += opp_team_plus_minus\n",
    "                running_date_dict[team_id].append(game_date)\n",
    "                running_date_dict[opp_team_id].append(game_date)\n",
    "                \n",
    "#                 if (new_years):\n",
    "#                     running_locations[home_team_id].append(curr_location)\n",
    "#                     running_locations[away_team_id].append(curr_location)\n",
    "                \n",
    "            seen_games.add(game_id)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games = add_variable_features(add_constant_features(league_df))\n",
    "home_games = all_games[all_games['is_home'] == 1]\n",
    "all_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, we can see some of the new columns we added. However, we see that most of the values are 0, which is expected since the head of the dataframe contains data from the beginning of a season. To display some of our results, we will show the dataframe tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='EDA'></a>\n",
    "## 3. Exploratory Data Analysis\n",
    "We do exploratory data analysis to provide useful insight when deciding what type of variables are useful predictors. Our EDA examines variables both univariately and bi-variately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Univariate Analysis'></a>\n",
    "### 3A. Univariate Analysis\n",
    "We note from the below figure:\n",
    "- our response variable `plus-minus` is unimodal around 0 points and normally distributed \n",
    "- predictor variables `home/away_win_pct` and `home/away_win_pct_N`  are unimodal around 50% and normally distributed \n",
    "- `home_win_pct_as_home` is right skewed, with mode at around 60%\n",
    "- `away_win_pct_as_away` is left skewed, with mode at around 40%\n",
    "- most games are not back to back\n",
    "- there are two teams (Denver Nuggets and Utah Jazz) that have stadiums at very high elevations\n",
    "- it is more common for a team to travel relatively shorter distances than longer distances (right skewed distributions for both `home_mileage` and `away_mileage`\n",
    "<img src=\"univariate.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Bivariate Analysis'></a>\n",
    "### 3B. Bivariate Analysis\n",
    "Based on personal intuition and understanding of the NBA, we listed out some variables that we wanted to explore, knowing that these variables could be important factors in predicting our response. For the following variables, we explored bivariate scatterplots, graphing the home team's data on the y axis against the away team's data on the x axis. For our plots concerning the home and away win/loss percentage in the previous N games, we choose 8 games for the purpose of these graphs. A more detailed analysis on how we pick N is discussed in a different section.\n",
    "\n",
    "1. Home W/L Percentage\n",
    "2. Away W/L Percentage\n",
    "3. Home Average Point Differential\n",
    "4. Away Average Point Differential\n",
    "5. Home W/L Percentage in Previous N Games \n",
    "6. Away W/L Percentage in Previous N Games \n",
    "7. Away W/L Percentage as Away Team\n",
    "8. Home W/L Percentage as Home Team\n",
    "\n",
    "Running these graphs over multiple seasons and eyeballing the plots gave us similar results. As an example, we display graphs for the most recently completed season (2015-16). Games that were won by the home team are blue while lost games are red. Hovering over each point displays the home team, the teams matched up, and an boolean value of whether or not the away team was playing a back to back game (1 for back to back, 0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar\n",
    "from bokeh.charts import Scatter\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Plot of Home W/L Percentage vs. Away W/L Percentage\n",
    "#all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "all_years_id = home_games[\"season_id\"].unique()\n",
    "# Look at the previous completed season\n",
    "#testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "testYear =  home_games[(home_games[\"season_id\"] ==\"22015\")]\n",
    "\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource \n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Win/Loss % Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Team W/L %'\n",
    "p.yaxis.axis_label = 'Home Team W/L %'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct\"], testYear[\"home_win_pct\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "# Add a line of slope one to visually divide points\n",
    "p.line([0, 1], [0, 1], line_width=2, color = \"black\")\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"WinLoss.png\", width = 500, height = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home Avg Pt Diff vs. Away Avg Pt Diff\n",
    "#all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "all_years_id = home_games[\"season_id\"].unique()\n",
    "# Look at the previous completed season\n",
    "#testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "testYear =  home_games[(home_games[\"season_id\"] ==\"22015\")]\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Avg Pt Diff Year \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Team Avg Pt Diff'\n",
    "p.yaxis.axis_label = 'Home Teams Avg Pt Diff'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_avg_pt_diff\"], testYear[\"home_avg_pt_diff\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "# Add a line of slope one to visually divide points\n",
    "p.line([-15, 15], [-15, 15], line_width=2, color = \"black\")\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AvgPtDiff.png\", width = 500, height = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home W/L Percentage Previous N Games vs. Away W/L Percentage Previous N games\n",
    "#all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "all_years_id = home_games[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "#testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "testYear =  home_games[(home_games[\"season_id\"] ==\"22015\")]\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Vs. Away - Win/Loss % Last 8 Games \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Team Win/Loss % Last 8 Games'\n",
    "p.yaxis.axis_label = 'Home Team Win/Loss % Last 8 Games'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct_N\"], testYear[\"home_win_pct_N\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "p.line([0, 1], [0, 1], line_width=2, color = \"black\")\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"WinLossLastN.png\", width = 500, height = 500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of Home Team W/L Percentage as Home vs. Away W/L Percentage as Away \n",
    "#all_years_id = home_games_with_cutoff[\"season_id\"].unique()\n",
    "all_years_id = home_games[\"season_id\"].unique()\n",
    "# Hard code the year we are looking at for now\n",
    "#testYear =  home_games_with_cutoff[(home_games_with_cutoff[\"season_id\"] ==\"22015\")]\n",
    "testYear =  home_games[(home_games[\"season_id\"] ==\"22015\")]\n",
    "# Based on home team, color losses as red and wins as blue \n",
    "colormap = {'L': 'red', 'W': 'blue', }\n",
    "colors = [colormap[x] for x in testYear[\"wl\"]]\n",
    "\n",
    "# Import the nba dataframe of the given year as ColumnDataSource\n",
    "source = ColumnDataSource(data=testYear)\n",
    "\n",
    "# Variables we want to show in the hover: university name and ranking\n",
    "hover = HoverTool(tooltips=[(\"Home\", \"@team_abbreviation\"), (\"Game\", \"@matchup\"), (\"Away BB\", \"@away_back_to_back\")])\n",
    "\n",
    "# Add in labels to the graph\n",
    "yearNum = \"2015\"\n",
    "title = \"Home Win % as Home vs Away Win % as Away \" + yearNum\n",
    "p = figure(title = title, tools = [hover, \"resize\", \"box_zoom\", \"reset\"])\n",
    "p.xaxis.axis_label = 'Away Team Win/Loss as Away Team'\n",
    "p.yaxis.axis_label = 'Home Team Win/Loss as Home Team'\n",
    "\n",
    "# Plot the points for the graph\n",
    "p.circle(testYear[\"away_win_pct_as_away\"], testYear[\"home_win_pct_as_home\"], color=colors, fill_alpha=0.2, size=10, source = source)\n",
    "p.line([0, 1], [0, 1], line_width=2, color = \"black\")\n",
    "\n",
    "# Display inline\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"HomeAsHome%.png\", width = 500, height = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all plots, we see that games above the line clearly tend to have more wins that games below the line. This tells us that teams with higher win/loss percentages, avg. pt differentials, win/loss percentages in the last 8 games, and higher win/loss percentage as the home/away team are more likely to win matchups. These patterns in the graphs supports the idea that these variables are important predictors for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Back-to-Back'></a>\n",
    "### 3C. Hypothesis Testing: Is Back to Back \n",
    "Another variable that we believed to be an important predictor was whether or not teams playing in the current matchup had just played a game the day before, as teams playing consequtive games are likely to be more tired and more likely to lose. \n",
    "\n",
    "We evaluate this claim with hypothesis testing. For each team in the league, we will look back several seasons and calculate their win/loss percentages for regular games and back to back games. We then run a difference in proportions hypothesis test to see whether or not there is a statistically significant difference between these percentages. Because we already intuitively believe that playing back to back games will lower any given team's chances of winning, this hypothesis test will be one sided. The hypothesis test below was run at an alpha level of 0.05. \n",
    "#### Null Hypothesis: \n",
    "The true difference in this team's win/loss percentages between regular games and back to back games is zero.\n",
    "#### Alternative Hypothesis: \n",
    "The true difference in this team's win/loss percentages between regular games and back to back games is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "def teamPercentages(teamID, game_log):\n",
    "    \"\"\" Given a team id (int) returns a (list, list) representing win loss percentages for back to back \n",
    "        and regular games\n",
    "    Input:\n",
    "        teamID (int): team_id number\n",
    "        game_log (pd.DataFrame): Game_log that which lists all the home games \n",
    "    Output:\n",
    "        (list, list): Tuple of lists where each list contains the number of wins and number of games played for a \n",
    "                      given category, where the first list represents back to back games and the second list \n",
    "                      represents regular games.\n",
    "    \"\"\"\n",
    "    seasons = game_log[\"season_id\"].unique()\n",
    "    # Initialize lists which store the percentages for back to back games and regular games for each season\n",
    "    bbList = []\n",
    "    regList = []\n",
    "    # Initialize counters for games \n",
    "    bbWins = 0 \n",
    "    bbGames = 0\n",
    "    regWins = 0\n",
    "    regGames = 0\n",
    "    # Iterate through all seasons of the dataframe \n",
    "    for season in seasons:\n",
    "        # Get dataframe that only contains games from this season of the team of interest\n",
    "        currDf = game_log[(game_log[\"season_id\"] == season) & ((game_log[\"team_id\"] == teamID) | (game_log[\"opp_team_id\"] == teamID))]\n",
    "        # Iterate over the dataframe\n",
    "        for (index, row) in currDf.iterrows():\n",
    "            # Determine whether this is a home or away game\n",
    "            if (row[\"team_id\"] == teamID):\n",
    "                home = True\n",
    "            else:\n",
    "                home = False\n",
    "            # Case 1: Home back to back game \n",
    "            if (home and row[\"home_back_to_back\"] == 1):\n",
    "                bbGames += 1\n",
    "                if (row[\"wl_binary\"] == 1):\n",
    "                    bbWins += 1\n",
    "            # Case 2: Away back to back game\n",
    "            if(home == False and row[\"away_back_to_back\"] == 1):\n",
    "                bbGames += 1\n",
    "                if (row[\"wl_binary\"] == 0):\n",
    "                    bbWins += 1\n",
    "            # Otherwise we have regular games\n",
    "            else:\n",
    "                regGames += 1\n",
    "                if (home and row[\"wl_binary\"] == 1):\n",
    "                    regWins += 1\n",
    "                elif (home == False and row[\"wl_binary\"] == 0):\n",
    "                    regWins += 1\n",
    "    # Add the num of won and total games in the respective lists \n",
    "    bbList.append(bbWins)\n",
    "    bbList.append(bbGames)\n",
    "    regList.append(regWins)\n",
    "    regList.append(regGames)\n",
    "    return (bbList, regList)\n",
    "\n",
    "def leaguePercentages(game_log, season_id):\n",
    "    \"\"\" For all teams in the league, generate their win loss percentages for back to back and regular games \n",
    "        across all seasons from data from a given season onwards, storing the result in a dictionary. \n",
    "    Input: \n",
    "        game_log (pd.Dataframe): Dataframe containing all the home games\n",
    "        season_id (string): season id in which we only look at the results occuring at or after this season \n",
    "    Output:\n",
    "        returnDict: (string, (List, List)) where key represents the team name and value is a tuple of \n",
    "                                           lists. Each list contains the number of wins and total games played, \n",
    "                                           where the first list represents back to back games and the second list \n",
    "                                           represents regular games\n",
    "    \"\"\"\n",
    "    # Index out the seasons \n",
    "    newLog = game_log[game_log[\"season_id\"] >= season_id]\n",
    "    # Initialize the dictionary for all teams\n",
    "    returnDict = {}\n",
    "    teamList = newLog[\"team_id\"].unique()\n",
    "    # Iterate over all teams and call above helper function to generate the lists of win loss % for each team\n",
    "    for teamID in teamList:\n",
    "        returnDict[team] = teamPercentages(teamID, newLog)\n",
    "    return returnDict\n",
    "\n",
    "def hypothesisTest(bbList, regList):\n",
    "    \"\"\" Run a hypothesis test to see whether the true mean win loss percentage of regular games is higher than\n",
    "        the true mean win loss percentage of back to back games for a specific team over many seasons (alpha = 0.05).\n",
    "    Input: \n",
    "        bbList (List): List containing the win loss percentages of a team for back to back games over many seasons\n",
    "        regList (List): List containing the win loss percentages of a team for regular games over many seasons \n",
    "    Output:\n",
    "        result: (Boolean) where 1 represents regular game win loss percentage being significantly greater than the \n",
    "                          win loss percentage for back to back games given the inputted data.\n",
    "    \"\"\"\n",
    "    # Get number of back to back and reg games \n",
    "    bbWins = bbList[0]\n",
    "    nBB = bbList[1]\n",
    "    regWins = regList[0]\n",
    "    nReg = regList[1]\n",
    "    # Get our win loss percentages for back to back and regular games \n",
    "    bbProp = bbWins / float(nBB)\n",
    "    regProp = regWins / float(nReg)\n",
    "    # Caluclate the pooled proportion and pooled standard deviation \n",
    "    pooledProp = (bbWins + regWins) / float(nBB + nReg)\n",
    "    pooledSE = np.sqrt(pooledProp * (1 - pooledProp) * ((1/float(nBB)) + (1/float(nReg))))\n",
    "    propDiff = regProp - bbProp\n",
    "    z = propDiff / float(pooledSE)\n",
    "    # Find the cutoff for alpha = 0.05 \n",
    "    cutoff = norm.ppf(0.95, loc = 0, scale = 1)\n",
    "    return z > cutoff \n",
    "    \n",
    "def testLeague(game_log, season_id):\n",
    "    \"\"\" For all teams in the league, run the hypothesis tests comparing win loss percentages between regular and \n",
    "        back to back games.\n",
    "    Input: \n",
    "        game_log (pd.Dataframe): Dataframe containing home game logs \n",
    "        season_id (string): season_id in which we only look at the results occuring at or after this season  \n",
    "    Output:\n",
    "        result: (Float, Dictionary) Tuple containing an int and a dictionary. The float represents the percentage of teams\n",
    "                                    in which back to back games is significant from the hypothesis test. The dictionary \n",
    "                                    has keys being the team_id, and values as booleans of whether or not there was a \n",
    "                                    significant difference between the records\n",
    "    \"\"\"\n",
    "    # Index out the seasons \n",
    "    newLog = game_log[game_log[\"season_id\"] >= season_id]\n",
    "    # Initialize the dictionary for all teams\n",
    "    returnDict = {}\n",
    "    teamList = newLog[\"team_id\"].unique()\n",
    "    for team in teamList:\n",
    "        returnDict[team] = hypothesisTest(teamPercentages(team, newLog[newLog[\"season_id\"] >= season_id])[0], teamPercentages(team, all_games[all_games[\"season_id\"] >= season_id])[1])\n",
    "    # Find the proportion of teams in which this difference was significant across the league \n",
    "    sig = 0 \n",
    "    total = 0 \n",
    "    for team in returnDict:\n",
    "        if returnDict[team] == 1:\n",
    "            sig += 1\n",
    "        total += 1\n",
    "    percSig = (sig) / float(total)\n",
    "    # Print the percentage of teams in which back to back is a significant variable \n",
    "    print percSig\n",
    "    return (percSig, returnDict)\n",
    "\n",
    "testLeague(home_games, \"22005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "We ran the hypothesis test comparing win/loss percentages between regular and back to back games across all teams in the league from the 2005 season to the games that have occured in the current (2016-2017) season. For data collected from the 2005 season and on, for alpha=0.05, we see that there is statistically significant evidence to reject the null in favor of the alternative that teams have a worse record on back to back games compared to regular games for 53% of teams in the league. Thus, we decide that back to back is a significant predictor that should be included in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='The NBA over Time'></a>\n",
    "### 3D. How has the NBA changed over the years?\n",
    "We want to examine how key statistics have changed over the past 40 seasons of the NBA:\n",
    "1. Standard deviation of team wins in a given season\n",
    "2. Average point differential \n",
    "3. Difference between the mean point differential between top teams and bottom teams\n",
    "\n",
    "Knowing how the league has changed in terms of these potential predictors is key to better understanding and optimizing our model to how the league currently operates, and whether certain variables are likely vary a lot throughout different seasons. Below we generate visualizations on these different values across the past 40 seasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "def get_team_wins_count(league_df, team_id, season_id):\n",
    "    \"\"\" Given a df containing ALL game logs (including home and away), \n",
    "        team_id and season_id, returns number of wins the team got that season\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "        team_id (int or string): player ID number\n",
    "        season_id (int or string): season ID number\n",
    "    Output:\n",
    "        (int): number of games team won in season\n",
    "    \"\"\" \n",
    "    team_id = int(team_id)\n",
    "    season_id = str(season_id)\n",
    "    \n",
    "    temp_df = league_df[(league_df['season_id'] == season_id) & (league_df['team_id'] == team_id)]\n",
    "    temp_df = temp_df.sort_values('game_date')\n",
    "    \n",
    "    # get last game\n",
    "    last_game = temp_df.iloc[len(temp_df) - 1]\n",
    "\n",
    "    wins = 0\n",
    "    games_won_so_far = 0\n",
    "    if last_game['is_home']:\n",
    "        games_won_so_far = int(round(last_game['home_win_pct']*last_game['home_game_count']))\n",
    "    else:\n",
    "        games_won_so_far = int(round(last_game['away_win_pct']*last_game['away_game_count']))\n",
    "    wins = games_won_so_far + last_game['wl_binary']\n",
    "    return wins\n",
    "    \n",
    "get_team_wins_count(all_games, \"1610612742\", \"22004\")\n",
    "\n",
    "def graph_stdev_wins(league_df):\n",
    "    \"\"\" Given a df containing ALL SORTED game logs (including home and away), \n",
    "        graphs stdev of team wins over time\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    stdevs = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        team_list = season_df['team_id'].unique().tolist()\n",
    "        win_counts = []\n",
    "        for team in team_list:\n",
    "            team_wins = get_team_wins_count(league_df, team, season)\n",
    "            win_counts.append(team_wins)\n",
    "        stdev = np.array(win_counts).std(ddof = 1)\n",
    "        seasons.append(int(season[1:]))\n",
    "        stdevs.append(stdev)\n",
    "        \n",
    "    # remove last, unfinished year\n",
    "    seasons = seasons[:len(seasons)- 1]\n",
    "    stdevs = stdevs[:len(stdevs) - 1]\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Standard Deviation Of Games Won',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.plot(seasons, stdevs, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, stdevs, 1))(np.unique(seasons)))\n",
    "         \n",
    "graph_stdev_wins(all_games)\n",
    "\n",
    "def graph_avg_ptdiff(league_df):\n",
    "    \"\"\" Given a df containing ALL SORTED game logs (including home and away), \n",
    "        graphs average (absolute value) ptdiff over seasons\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    avg_pt_diffs = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        pt_diff = season_df['plus_minus'].values\n",
    "        pt_diff = np.apply_along_axis(lambda x: np.abs(x), 0, pt_diff)\n",
    "        seasons.append(int(season[1:]))\n",
    "        avg_pt_diffs.append(np.mean(pt_diff))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Average Point Differentials Over Seasons',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Average Point Differential')\n",
    "    plt.plot(seasons, avg_pt_diffs, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, avg_pt_diffs, 1))(np.unique(seasons)))\n",
    "\n",
    "graph_avg_ptdiff(all_games)\n",
    "    \n",
    "def total_games_graph(league_df):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        graphs total games played throughout seasons\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (only HOME)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = league_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    total_games = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        seasons.append(int(season[1:]))\n",
    "        total_games.append(len(season_df))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Total Games Played Over Different Seasons',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Games Played')\n",
    "    plt.plot(seasons, total_games, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, total_games, 1))(np.unique(seasons)))\n",
    "    \n",
    "total_games_graph(home_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two plots show that the standard deviation of games won and average point differentials have wave-like patterns that are only slowly increasing as a whole. The increasing trend of the standard deviation of the number of games won shows us that there exists a larger spread of games won throughout the league within a season as we move to more current seasons, perhaps indicating larger gaps between good and bad teams in the league. This could possibly be due to the increasing number of teams in the league. Similarly, the increasing trend in average point differential also supports this idea of a larger gap between good and bad teams, as average point differntials are larger in more current seasons. \n",
    "\n",
    "These effects, however, do not seem particularly large, as the overall increase for the standard deviation of games won and average point differential are 4 and 0.5, respectively.\n",
    "\n",
    "We notice a larger effect in the total games played. The number of games has been increasing from seasons 1940-1990; afterwards it levels off. The last point on the graph represents the current season, which is still in progress. Years 1989 and 2011 show dips in the plot due to being lockout seasons, resulting in condensed schedules. This is important in considering which seasons to include in our data. Seasons 1990 and after are a lot more similar to the number of total games played currently, while going back each year becomes increasingly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Feature Selection'></a>\n",
    "## 4. Feature Selection\n",
    "Now that we have done some initial data analysis, we would like to fine tune a couple of our features. Specifically, we take a look at the `home-win percentage` and `N-Previous games home-win percentage`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Training Cutoff'></a>\n",
    "### 4A. Training Cutoff\n",
    "\n",
    "While we have data on the running home win percentage for any particular season, we still have to take caution about games that are played at the beginning of the season. When there are not many games yet played, the home win percentage can flucuate wildly (i.e 100% to 50% to 66%). To prevent some of the noise in this particular features, we would like to cut off \"N\" number of games at the start of the season. To determine what this \"N\" is, we plot the change in home-win-percentage against the number of games played. To get a sufficient sample size, we use all and seasons from the 1947 all the way to the present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_cutoff_value(df):\n",
    "    \"\"\" Given a dataframe of game logs, display a graph showing the change \n",
    "        in win percentage per team as a season progresses\n",
    "    Input:\n",
    "        df (pd.DataFrame): Game_log\n",
    "    Output:\n",
    "        (None)\n",
    "    \"\"\"\n",
    "    all_years_id = home_games[\"season_id\"].unique()\n",
    "    for year in all_years_id:\n",
    "        curr_year = home_games[(home_games[\"season_id\"] ==year)]\n",
    "        all_teams = curr_year[\"team_abbreviation\"].unique()\n",
    "        for team in all_teams:\n",
    "            newdf = curr_year[(curr_year[\"team_abbreviation\"] ==team)]\n",
    "            temp = newdf['home_win_pct'] - newdf['home_win_pct'].shift(-1) # difference in win_pct\n",
    "            plt.plot(newdf[\"home_game_count\"],temp)\n",
    "    plt.axis([0,82,-1,1])\n",
    "    plt.xlabel('Games Played')\n",
    "    plt.ylabel('Change in Win-Percentage')\n",
    "    plt.title('Win-Percentage change vs Games Played (all teams from 1947 onwards)')\n",
    "\n",
    "check_cutoff_value(home_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide on a cutoff of N = 10. This allows us to discount the first couple of \"inaccurate\" win-percentages yet still leave us with enough games to train on in a particular season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='N-Previous Games'></a>\n",
    "### 4B. Lookback Parameter (N) Tuning\n",
    "A crucial parameter in our model is our lookback parameter, which is used in the calcation of the `home_win_pct_N` and `away_win_pct_N` features. The idea behind these features is that team performance may be streaky. Further, team dynamics change throughout the season, i.e. through injuries and roster changes. Thus, it is important to not only consider team performance throughout the entire season, but also the recent team performance.\n",
    "\n",
    "Naturally, we might ask: if we predicted game results solely on recent game performance, how well would we do for different `N`? By comparing these results, we can\n",
    "isolate the lookback variable and do simple comparisons between different parameter values. We note that this approach was inspired from work from Amorim Torres [1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use svg backend for better quality\n",
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "\n",
    "def add_lookback_features(league_df, params):\n",
    "    \"\"\" Given a dataframe league_df and a list of natural numbers params, returns a new df containing \n",
    "        extra columns for each lookback parameter in params.\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs\n",
    "        params (list): list containing positive integers\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\" \n",
    "    \n",
    "    # Ensure correct params formatting\n",
    "    for i in params:\n",
    "        assert (type(i) == int and i > 0)\n",
    "        \n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    \n",
    "    # Initialize new columns\n",
    "    for i in params:\n",
    "        lookback = i\n",
    "        \n",
    "        home_col_name = 'home_win_pct_' + str(i)\n",
    "        away_col_name = 'away_win_pct_' + str(i)\n",
    "        \n",
    "        new_df.loc[:,home_col_name] = np.zeros(len(new_df))\n",
    "        new_df.loc[:,away_col_name] = np.zeros(len(new_df))\n",
    "        \n",
    "        grouped = new_df.groupby(['season_id'])\n",
    "        groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "\n",
    "        for season_df in groupList:\n",
    "            # Initialize dictionary containing wins and losses for each team\n",
    "            running_dict = dict()\n",
    "\n",
    "            for team in season_df['team_id'].unique():\n",
    "                running_dict[team] = []\n",
    "\n",
    "            # Sort season by day\n",
    "            season_df = season_df.sort_values('game_date')\n",
    "\n",
    "            seen_games = set()\n",
    "            \n",
    "            for (index, row) in season_df.iterrows():\n",
    "                team_id = row['team_id']\n",
    "                opp_team_id = row['opp_team_id']\n",
    "                wl = row['wl']\n",
    "                game_id = row['game_id']\n",
    "                is_home = row['is_home']\n",
    "                \n",
    "                if is_home == 1:\n",
    "                    home_team_id = team_id\n",
    "                    away_team_id = opp_team_id\n",
    "                else:\n",
    "                    home_team_id = opp_team_id\n",
    "                    away_team_id = team_id\n",
    "                \n",
    "                # Update home_win_pct_N, away_win_pct_N\n",
    "                home_win_pct_N = 0\n",
    "                away_win_pct_N = 0\n",
    "                \n",
    "                home_games_count = len(running_dict[home_team_id])\n",
    "                away_games_count = len(running_dict[away_team_id])\n",
    "\n",
    "                if home_games_count > 0:\n",
    "                    if home_games_count > lookback:\n",
    "                        lookback_games = running_dict[home_team_id][home_games_count - lookback:]\n",
    "                    else:\n",
    "                        lookback_games = running_dict[home_team_id]\n",
    "                    home_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "\n",
    "                if away_games_count > 0:\n",
    "                    if away_games_count > lookback:\n",
    "                        lookback_games = running_dict[away_team_id][away_games_count - lookback:]\n",
    "                    else:\n",
    "                        lookback_games = running_dict[away_team_id]\n",
    "                    away_win_pct_N = sum(lookback_games)/float(len(lookback_games))\n",
    "\n",
    "                new_df.set_value(index, home_col_name, home_win_pct_N)\n",
    "                new_df.set_value(index, away_col_name, away_win_pct_N)\n",
    "                \n",
    "                # Update running stats\n",
    "                if (wl == 'W'):\n",
    "                    if game_id in seen_games:\n",
    "                        running_dict[team_id].append(1)\n",
    "                        running_dict[opp_team_id].append(0)\n",
    "\n",
    "                else:\n",
    "                    if game_id in seen_games:\n",
    "                        running_dict[opp_team_id].append(1)\n",
    "                        running_dict[team_id].append(0)\n",
    "                        \n",
    "                seen_games.add(game_id)\n",
    "    return new_df\n",
    "\n",
    "def graph_lookback(league_df, params):\n",
    "    \"\"\" Given a dataframe league_df, a season_id, and a list of natural numbers params, graphs the effectiveness\n",
    "        of using each of the params as a naive classifier\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing league logs, including the lookback columns from params\n",
    "        season_id (str): season identifier\n",
    "        params (list): sorted list containing positive integers\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\" \n",
    "    grouped = league_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        # Initialize dictionary counting number of correct classifications for each param i\n",
    "        correct_dict = dict()\n",
    "\n",
    "        for i in params:\n",
    "            correct_dict[i] = 0\n",
    "\n",
    "        # Sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "\n",
    "        #seen_games = set()\n",
    "        \n",
    "        season_id = \"\"\n",
    "\n",
    "        for (index, row) in season_df.iterrows():\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            wl = row['wl_binary']\n",
    "            game_id = row['game_id']\n",
    "            is_home = row['is_home']\n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            \n",
    "            for i in params:\n",
    "                home_col_name = 'home_win_pct_' + str(i)\n",
    "                away_col_name = 'away_win_pct_' + str(i)\n",
    "                \n",
    "                home_pct = row[home_col_name]\n",
    "                away_pct = row[away_col_name]\n",
    "                \n",
    "                if (is_home == 1 and wl == 1 and home_pct >= away_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 1 and wl == 0 and away_pct > home_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 0 and wl == 1 and away_pct > home_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                elif (is_home == 0 and wl == 0 and home_pct >= away_pct):\n",
    "                    correct_dict[i] += 1\n",
    "                    \n",
    "        pct_list = []\n",
    "        for i in params:\n",
    "            pct_list.append(correct_dict[i]/float(len(season_df)))\n",
    "            \n",
    "        ax.plot(params, pct_list, label = season_id[1:])\n",
    "        \n",
    "    ax.set_xlabel(\"Lookback Parameter (N)\", fontsize=15)\n",
    "    ax.set_ylabel(\"Classification Accuracy\", fontsize=18)\n",
    "    \n",
    "    fig.suptitle('Classification Accuracy Using Different Lookback Parameters', fontsize = 18)\n",
    "    \n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        \n",
    "    plt.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_games_lookback = add_lookback_features(all_games, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "all_games_lookback.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_df = all_games_lookback[all_games_lookback[\"season_id\"] >= \"22004\"]\n",
    "graph_lookback(temp_df, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of the above graph, and prediction accuracies for each model (done below), we decide that the best option is N=11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Additional Features'></a>\n",
    "## 5. Additional Features\n",
    "While building our model, we decided to add additional features that could be possibly significant in predicting win/losses. Both of these features are implemented in [fivethirtyeight's](http://fivethirtyeight.com/features/how-our-2015-16-nba-predictions-work/) 2015-16 NBA prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Altitude'></a>\n",
    "### 5A. Altitude\n",
    "A potiential feature is the altitude of the stadium. The Denver Nuggets and Utah Jazz have stadiums that are at very high elevations (5280 ft and 4226 ft, respectively). At these elevations, it is thought that vistor teams have a possible disadvantage due to the fact they are not accustomed to lower oxygen levels. While this hypothesis constantly debated, it is true that the home team consistently has a larger home court advantage compared to other teams.\n",
    "\n",
    "Since there are only 30 teams in the current NBA League, it was simpler to manually check elevations at each stadium. Below we insert the altitude column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temp_df = home_games_with_cutoff[home_games_with_cutoff['season_id']>=\"22005\"]\n",
    "temp_df = all_games[all_games['season_id'] >= '22005']\n",
    "#temp_df = new_years_df[new_years_df['is_home'] == 1]\n",
    "\n",
    "temp_df.head()\n",
    "altitude = {'Chicago Stags': 615, 'Buffalo Braves': 600, 'Washington Bullets': 400, 'Toronto Huskies': 249, \n",
    "            'Los Angeles Lakers': 233, 'Chicago Bulls': 615, 'Washington Capitols': 200, 'Providence Steamrollers': 75, \n",
    "            'Charlotte Bobcats': 751, 'Capital Bullets': 200, 'New Orleans Pelicans': 13, 'San Diego Rockets': 62, \n",
    "            'Milwaukee Hawks': 617, 'Philadelphia 76ers': 39, 'Philadelphia Warriors': 39, 'Chicago Packers': 615, \n",
    "            'New Orleans Jazz': 20, 'Detroit Pistons': 961, 'Boston Celtics': 141, 'Miami Heat': 24, \n",
    "            'Minneapolis Lakers': 830, 'Orlando Magic': 82, 'Portland Trail Blazers': 50, 'Rochester Royals': 505, \n",
    "            'Golden State Warriors': 43, 'Sheboygan Redskins': 630, 'New York Knicks': 33, 'St. Louis Hawks': 465, \n",
    "            'Indianapolis Olympians': 715, 'Washington Wizards': 205, 'Kansas City Kings': 910, 'Utah Jazz': 4226, \n",
    "            'Ft. Wayne Zollner Pistons': 600, 'Pittsburgh Ironmen': 1365, 'New Jersey Nets': 33, 'New York Nets': 33, \n",
    "            'Dallas Mavericks': 430, 'Sacramento Kings': 30, 'New Orleans/Oklahoma City Hornets': 20, \n",
    "            'Los Angeles Clippers': 305, 'San Antonio Spurs': 650, 'Vancouver Grizzlies': 171, \n",
    "            'Oklahoma City Thunder': 1201, 'Waterloo Hawks': 1079, 'Charlotte Hornets': 751, 'Anderson Packers': 879, \n",
    "            'Syracuse Nationals': 380, 'Kansas City-Omaha Kings': 910, 'Cincinnati Royals': 482, 'Cleveland Rebels': 653, \n",
    "            'Milwaukee Bucks': 617, 'Phoenix Suns': 39, 'LA Clippers': 305, 'Memphis Grizzlies': 337, \n",
    "            'Tri-Cities Blackhawks': 1050, 'Toronto Raptors': 249, 'Houston Rockets': 43, 'New Orleans Hornets': 13, \n",
    "            'Chicago Zephyrs': 594, 'Minnesota Timberwolves': 830, 'Detroit Falcons': 600, 'Indiana Pacers': 715, \n",
    "            'San Diego Clippers': 62, 'Seattle SuperSonics': 518, 'Cleveland Cavaliers': 653, 'Atlanta Hawks': 1050, \n",
    "            'Brooklyn Nets': 33, 'Indianapolis Jets': 715, 'Baltimore Bullets': 480, 'San Francisco Warriors': 52, \n",
    "            'St. Louis Bombers': 465, 'Denver Nuggets': 5280}\n",
    "altitude_dict = {}\n",
    "curr_names = temp_df[\"team_name\"].tolist()\n",
    "for key in altitude:\n",
    "    if key not in curr_names:\n",
    "        continue\n",
    "    else:\n",
    "        filtered_df = temp_df[temp_df['team_name'] == key]\n",
    "        cor_id = filtered_df[\"team_id\"].iloc[0]\n",
    "        altitude_dict[str(cor_id)] = altitude[key]\n",
    "### adding a new elevation column\n",
    "elevation = np.zeros(len(temp_df), dtype = np.int64)\n",
    "temp_df = temp_df.assign(elevation = elevation)\n",
    "\n",
    "for (index, row) in temp_df.iterrows():\n",
    "        location = row['is_home']\n",
    "        if location == 1: # at home\n",
    "            alt = altitude_dict[str(row[\"team_id\"])]\n",
    "            temp_df.set_value(index, 'elevation', alt)\n",
    "        else:\n",
    "            alt = altitude_dict[str(row[\"opp_team_id\"])]\n",
    "            temp_df.set_value(index, 'elevation', alt)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Travel Distance'></a>\n",
    "### 5B. Travel Distance (2005+)\n",
    "Another potential useful feature is the distance traveled by a team to get to the current location. This is related to fatigue, as teams will likely be tired from the flights, and the time zone changes can be distorting. We wish to add features `home_mileage` and `away_mileage` to indicate the number of miles the team traveled to get to the current game.\n",
    "\n",
    "To do this, we will use the library geopy to get coordinates and to calculate distances (distance will be calculated using the vincenty formula). We will need to manually create dictionaries mapping teams to locations. Because these need to be manually created, we limit the year scope to include on 2005+. We do not think this limitation will be significant since we know that recent years are the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "# Only consider years after 2005\n",
    "#temp_df = all_games[all_games['season_id'] >= '22005']\n",
    "team_names = temp_df['team_name'].unique().tolist()\n",
    "#print len(team_names), team_names\n",
    "\n",
    "team_id_list = temp_df['team_id'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping of team_id to team_name\n",
    "id_team = dict()\n",
    "for team_id in team_id_list:\n",
    "    temp_df_1 = temp_df[temp_df['team_id'] == team_id]\n",
    "    id_team[team_id] = temp_df_1['team_name'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping of team_name to seasons\n",
    "team_seasons = dict()\n",
    "for team_name in team_names:\n",
    "    temp_df_1 = temp_df[temp_df['team_name'] == team_name]\n",
    "    team_seasons[team_name] = temp_df_1['season_id'].unique().tolist()\n",
    "\n",
    "# Dictionary mapping team name to location\n",
    "name_location = {'Dallas Mavericks': 'Dallas, Texas',\n",
    "                'New Orleans/Oklahoma City Hornets': 'Oklahoma City, Oklahoma',\n",
    "                'Milwaukee Bucks': 'Milwaukee, Wisconsin',\n",
    "                'San Antonio Spurs': 'San Antonio, Texas',\n",
    "                'Philadelphia 76ers': 'Philadelphia, Pennsylvania',\n",
    "                'Phoenix Suns': 'Phoenix, Arizona',\n",
    "                'Denver Nuggets': 'Denver, Colorado',\n",
    "                'Sacramento Kings': 'Sacramento, California',\n",
    "                'Atlanta Hawks': 'Atlanta, Georgia',\n",
    "                'Miami Heat' : 'Miami, Florida', \n",
    "                'Toronto Raptors': 'Toronto, Ontario', \n",
    "                'New Jersey Nets': 'Newark, New Jersey', \n",
    "                'Houston Rockets': 'Houston, Texas', \n",
    "                'Boston Celtics': 'Boston, Massachusetts', \n",
    "                'Golden State Warriors' : 'Oakland, California', \n",
    "                'Utah Jazz': 'Salt Lake City, Utah', \n",
    "                'Seattle SuperSonics' : 'Seattle, Washington', \n",
    "                'Portland Trail Blazers': 'Portland, Oregon', \n",
    "                'Indiana Pacers' : 'Indianapolis, Indiana', \n",
    "                'Minnesota Timberwolves' : 'Minneapolis, Minnesota', \n",
    "                'Washington Wizards': 'Washington D.C., Virginia',\n",
    "                'Chicago Bulls' : 'Chicago, Illinois', \n",
    "                'New York Knicks': 'New York City, New York', \n",
    "                'Cleveland Cavaliers' : 'Cleveland, Ohio', \n",
    "                'Charlotte Bobcats' : 'Charlotte, North Carolina',\n",
    "                'Detroit Pistons' : 'Detroit, Michigan', \n",
    "                'Memphis Grizzlies' : 'Memphis, Tennessee', \n",
    "                'Orlando Magic' : 'Orlando, Florida', \n",
    "                'Los Angeles Clippers' : 'Los Angeles, California', \n",
    "                'Los Angeles Lakers' : 'Los Angeles, California', \n",
    "                'New Orleans Hornets' : 'New Orleans, Louisiana', \n",
    "                'Oklahoma City Thunder': 'Oklahoma City, Oklahoma', \n",
    "                'Brooklyn Nets': 'Brooklyn, New York', \n",
    "                'New Orleans Pelicans' : 'New Orleans, Louisiana', \n",
    "                'Charlotte Hornets' : 'Charlotte, North Carolina', \n",
    "                'LA Clippers' : 'Los Angeles, California'}\n",
    "\n",
    "# Dictionary mapping location to (latitude, longitude)\n",
    "location_latlong = dict()\n",
    "geolocator = Nominatim()\n",
    "for key,value in name_location.iteritems():\n",
    "    geo_loc = geolocator.geocode(value)\n",
    "    (lat1, long1) = (geo_loc.latitude, geo_loc.longitude)\n",
    "    location_latlong[value] = (lat1,long1)\n",
    "    \n",
    "def get_team_location(team_id, season_id):\n",
    "    \"\"\" Given a team id and the season_id, returns a string containing the location of the team stadium\n",
    "    Input: \n",
    "        team_id (int): team id\n",
    "        season_id (str): season id \n",
    "    Output:\n",
    "        (str) \n",
    "    \"\"\"\n",
    "    names = id_team[team_id]\n",
    "    \n",
    "    team_name = None\n",
    "    \n",
    "    for name in names:\n",
    "        seasons = team_seasons[name]\n",
    "        #print seasons, name\n",
    "        if season_id in seasons:\n",
    "            team_name = name\n",
    "            \n",
    "    if team_name == None:\n",
    "        print (team_id, season_id, names)\n",
    "        assert(False)\n",
    "    \n",
    "    return name_location[team_name]\n",
    "\n",
    "def add_mileage(league_df):\n",
    "    geolocator = Nominatim()\n",
    "    seen_distances = dict()\n",
    "    \n",
    "    new_df = league_df.sort_values('game_date')\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    new_df = new_df.assign(home_mileage = home_mileage)\n",
    "    new_df = new_df.assign(away_mileage = away_mileage)\n",
    "    \n",
    "\n",
    "    home_mileage = np.zeros(len(new_df))\n",
    "    away_mileage = np.zeros(len(new_df))\n",
    "    \n",
    "    # Ddd features\n",
    "    grouped = new_df.groupby(['season_id'])\n",
    "    groupList = [grouped.get_group(x) for x in grouped.groups]\n",
    "    \n",
    "    for season_df in groupList:\n",
    "        running_locations = dict()\n",
    "        \n",
    "        for team in season_df['team_id'].unique():\n",
    "            # track list of locations played at\n",
    "            running_locations[team] = []\n",
    "        \n",
    "        # sort season by day\n",
    "        season_df = season_df.sort_values('game_date')\n",
    "        \n",
    "        seen_games = set()\n",
    "        \n",
    "        for (index, row) in season_df.iterrows():\n",
    "            is_home = row['is_home']\n",
    "            team_id = row['team_id']\n",
    "            opp_team_id = row['opp_team_id']\n",
    "            game_id = row['game_id']\n",
    "            season_id = row['season_id']\n",
    "            \n",
    "            if is_home == 1:\n",
    "                home_team_id = team_id\n",
    "                away_team_id = opp_team_id\n",
    "            else:\n",
    "                home_team_id = opp_team_id\n",
    "                away_team_id = team_id\n",
    "                \n",
    "            \n",
    "            home_games_count = row['home_game_count']\n",
    "            away_games_count = row['away_game_count']\n",
    "            \n",
    "            home_mileage = 0\n",
    "            away_mileage = 0\n",
    "            \n",
    "            curr_location = get_team_location(home_team_id, season_id)\n",
    "\n",
    "            (curr_lat, curr_long) = location_latlong[curr_location]\n",
    "\n",
    "            if home_games_count > 0:\n",
    "                location_list = running_locations[home_team_id]\n",
    "                assert(len(location_list) == home_games_count)\n",
    "                last_location = location_list[len(location_list) - 1]\n",
    "                (last_lat, last_long) = location_latlong[last_location]\n",
    "\n",
    "                str1 = curr_location + last_location\n",
    "                str2 = last_location + curr_location\n",
    "\n",
    "                if str1 in seen_distances:\n",
    "                    home_mileage = seen_distances[str1]\n",
    "                elif str2 in seen_distances:\n",
    "                    home_mileage = seen_distances[str2]\n",
    "                else:\n",
    "                    home_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                    seen_distances[str1] = home_mileage\n",
    "\n",
    "            if away_games_count > 0:\n",
    "                location_list = running_locations[away_team_id]\n",
    "                assert(len(location_list) == away_games_count)\n",
    "                last_location = location_list[len(location_list) - 1]\n",
    "\n",
    "                (last_lat, last_long) = location_latlong[last_location]\n",
    "\n",
    "                str1 = curr_location + last_location\n",
    "                str2 = last_location + curr_location\n",
    "\n",
    "                if str1 in seen_distances:\n",
    "                    away_mileage = seen_distances[str1]\n",
    "                elif str2 in seen_distances:\n",
    "                    away_mileage = seen_distances[str2]\n",
    "                else:\n",
    "                    away_mileage = vincenty((last_lat,last_long), (curr_lat,curr_long)).miles\n",
    "                    seen_distances[str1] = away_mileage\n",
    "\n",
    "            new_df.set_value(index, 'home_mileage', home_mileage)\n",
    "            new_df.set_value(index, 'away_mileage', away_mileage)\n",
    "            \n",
    "            if game_id in seen_games:\n",
    "                running_locations[home_team_id].append(curr_location)\n",
    "                running_locations[away_team_id].append(curr_location)\n",
    "                \n",
    "            seen_games.add(game_id)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mileage_df = add_mileage(all_games[all_games['season_id']>='22005'])\n",
    "mileage_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Modeling'></a>\n",
    "## 6. Modeling\n",
    "We are finally ready to do some predictions! We train our models on 2005-06 to 2009-10 (5 seasons - 5393 games) and we validate on 2010-11 to 2012-13 (3 seasons - 3450 games). Note that code for Linear Regression and Logistic Regression is in the R file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Naive Approach'></a>\n",
    "### 6A. Naive Approach\n",
    "The naive approach is to choose the team with the better record so far. If the records are the same, we will classify the home team as the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_approach_accuracy(home_games_df, season_id_list):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        season_id, returns accuracy of naive classification\n",
    "    Input:\n",
    "        league_df (pandas.DataFrame): dataframe containing post-processed league logs (both HOME and AWAY)\n",
    "        season_id (int or string): season ID number\n",
    "    Output:\n",
    "        (int): number of games team won in season\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for season_id in season_id_list:\n",
    "        season_id = str(season_id)\n",
    "\n",
    "        season_df = home_games_df[(home_games_df['season_id'] == season_id)]\n",
    "        for (index, row) in season_df.iterrows():\n",
    "            home_team_pct = row['home_win_pct']\n",
    "            away_team_pct = row['away_win_pct']\n",
    "            wl = row['wl_binary']\n",
    "            classification = 0\n",
    "\n",
    "            if (home_team_pct >= away_team_pct):\n",
    "                classification = 1\n",
    "            if classification == wl:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "    return correct/float(total)\n",
    "\n",
    "print naive_approach_accuracy(home_games,[\"22010\",\"22011\",\"22012\"])\n",
    "    \n",
    "def graph_naive(home_games_df):\n",
    "    \"\"\" Given a df containing ALL HOME game logs, \n",
    "        graph_naive graphs the naive classification accuracy across seasons\n",
    "    Input:\n",
    "        home_games_df (pandas.DataFrame): dataframe containing post-processed \n",
    "            league logs (HOME)\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    season_list = home_games_df['season_id'].unique().tolist()\n",
    "    seasons = []\n",
    "    naives = []\n",
    "    for season in season_list:\n",
    "        season_df = league_df[league_df['season_id'] == season]\n",
    "        naives.append(naive_approach_accuracy(home_games_df, [season]))\n",
    "        #pt_diff = season_df['plus_minus'].values\n",
    "        #pt_diff = np.apply_along_axis(lambda x: np.abs(x), 0, pt_diff)\n",
    "        seasons.append(int(season[1:]))\n",
    "        #avg_pt_diffs.append(np.mean(pt_diff))\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Naive Classification Accuracy',fontsize=12)\n",
    "    plt.xlabel('Season Starting Year')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(seasons, naives, seasons, \n",
    "                  np.poly1d(np.polyfit(seasons, naives, 1))(np.unique(seasons)))\n",
    "\n",
    "graph_naive(home_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Linear Regression Model'></a>\n",
    "### 6B. Linear Regression Model\n",
    "\n",
    "Our first approach of modeling our features was to use a multivariate linear regression model.\n",
    "\n",
    "$$y_{i} = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n-1}x_{n-1}$$\n",
    "More consisely,\n",
    "$$ y_{i} = \\sum_{i=1}^{n} \\theta_{i} x_{i}$$\n",
    "\n",
    "To predict `plus_minus`, we include the following features in our model:\n",
    "- home_win_pct\n",
    "- away_win_pct\n",
    "- home_win_pct_N\n",
    "- away_win_pct_N\n",
    "- home_back_to_back\n",
    "- away_back_to_back\n",
    "- home_win_pct_as_home\n",
    "- away_win_pct_as_away\n",
    "- away_back_to_back*away_win_pct_as_away\n",
    "- elevation\n",
    "- elevation*home_win_pct_as_home\n",
    "- home_mileage\n",
    "\n",
    "Note that we decided to not include certain features. We noticed that `home_avg_pt_diff` and `away_avg_pt_diff` both had very high multicollinearity (r-squared = 0.98) against `home_win_pct` and `away_win_pct`, repectively, we disregarded these features. `home_avg_pt_diff` and `away_avg_pt_diff`.\n",
    "In addition we added interaction terms between `away_back_to_back` and `away_win_pct_as_away` as well as `elevation` and `home_win_pct_as_home`.\n",
    "We checked that our model followed linear assumptions by checking residual plots against each feature as well as a Q-Q plot for normality assumptions. A lambda value of 1 in a boxcox shows that there is no need to transform our response variable.\n",
    "<img src=\"resids2.png\"> <img src=\"qqandboxcox.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Logistic Regression Model'></a>\n",
    "### 6C. Logistic Regression Model\n",
    "Our second approach is using a binary logistic regression model. Our response variable is win or loss.\n",
    "\n",
    "To predict win/loss, we use the following features:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SVM'></a>\n",
    "### 6D. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to Linear and Logistic Regression, we to try support vector machines for classification of win-loss. We first normalize our data for cleaner modeling, and faster SVM convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# home games\n",
    "# divide into training set, validation set, test set\n",
    "\n",
    "training_set = df_with_elev_mileage_with_cutoff[(home_games_with_cutoff['season_id'] >= \"22005\") &\n",
    "                                        (home_games_with_cutoff['season_id'] <= \"22009\")]\n",
    "validation_set = df_with_elev_mileage[(home_games['season_id'] >= \"22010\") & \n",
    "                            (home_games['season_id'] <= \"22012\")]\n",
    "test_set = df_with_elev_mileage[(home_games['season_id'] >= \"22013\") & \n",
    "                      (home_games['season_id'] <= \"22016\")]\n",
    "\n",
    "def normalize(df, param_labels):\n",
    "    \"\"\" Given a df containing game logs to be normalized, returns a new normalized dataframe\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing post-processed league logs\n",
    "        list (str): list of column labels to normalize\n",
    "        soft (bool): whether to do soft normalization or hard normalization\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    for label in param_labels:\n",
    "        mean = np.mean(df[label])\n",
    "        std = (df[label]).std()\n",
    "\n",
    "        new_row = df[label].apply(lambda x: (x-mean)/(2*std))\n",
    "\n",
    "        df.loc[:,label] = new_row \n",
    "    return df\n",
    "\n",
    "# RUN THIS IF YOU WANT NORMALIZED STUFF\n",
    "training_set = normalize(training_set, ['home_avg_pt_diff','away_avg_pt_diff', 'elevation','home_mileage','away_mileage'])\n",
    "validation_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff','elevation','home_mileage','away_mileage'])\n",
    "test_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff','elevation','home_mileage','away_mileage'])\n",
    "\n",
    "#training_set = normalize(training_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])\n",
    "#validation_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])\n",
    "#test_set = normalize(validation_set, ['home_avg_pt_diff','away_avg_pt_diff', 'home_win_pct', \"away_win_pct\", 'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            #'home_win_pct_as_home', 'home_back_to_back','away_back_to_back'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_matrix(df, features):\n",
    "    \"\"\" Given a normalized df, returns a matrix of features and the binary w/l response\n",
    "    Input:\n",
    "        df (pandas.DataFrame): dataframe containing post-processed, normalzied league logs\n",
    "        list (str): list of features to be included\n",
    "    Output:\n",
    "        (array-like, array-like)\n",
    "    \"\"\"\n",
    "    return (df[features].values, df['wl_binary'].values)\n",
    "\n",
    "# modify this as see fit\n",
    "features = ['home_win_pct', 'away_win_pct',\n",
    "           'home_win_pct_N', 'away_win_pct_N','away_win_pct_as_away',\n",
    "            'home_win_pct_as_home', 'home_back_to_back','away_back_to_back','elevation','away_mileage']\n",
    "\n",
    "training_matrix, training_response = create_feature_matrix(training_set, features)\n",
    "validation_matrix, validation_response = create_feature_matrix(validation_set, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran SVM three different times on different parameters in order to test our results. We first ran SVC and used grid search to find optimal values for C and gamma, which we used the second time. Using the same C value, we found that the third SVM with squard hinge loss had the highest result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run SVM\n",
    "clf = SVC(C=1e4, kernel='linear')\n",
    "clf1 = SVC(C = 2**(3), gamma = 2**(-15), kernel = 'linear')\n",
    "clf2 = LinearSVC(C=2**(3), loss='squared_hinge', dual = False, penalty = \"l1\", )\n",
    "\n",
    "clf.fit(training_matrix, training_response)\n",
    "clf1.fit(training_matrix, training_response)\n",
    "clf2.fit(training_matrix, training_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_pred = clf.predict(validation_matrix)\n",
    "valid_pred2 = clf2.predict(validation_matrix)\n",
    "valid_pred3 = clf3.predict(validation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def get_svm_accuracy(pred, actuals):\n",
    "    \"\"\" Given predictions and actuals, calculates prediction accuracy\n",
    "    Input:\n",
    "        pred (array-like): list of predictions\n",
    "        actuals (array-like): list of actual outputs\n",
    "    Output:\n",
    "        float\n",
    "    \"\"\"\n",
    "    assert(len(pred) == len(actuals))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in xrange(len(pred)):\n",
    "        if pred[i] == actuals[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct/float(total)\n",
    "\n",
    "print get_svm_accuracy(valid_pred, validation_response)\n",
    "print get_svm_accuracy(valid_pred2, validation_response)\n",
    "print get_svm_accuracy(valid_pred3, validation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run grid search to find the optimal gamma and C values \n",
    "def gridSearch():\n",
    "    cPower = -5\n",
    "    bestC = 0\n",
    "    bestG = 0\n",
    "    optimal = sys.minint \n",
    "    for c in xrange(11):\n",
    "        cVal = 2**(cPower)\n",
    "        gPower = -15 \n",
    "        for g in xrange(10):\n",
    "            gVal = 2**(gPower)\n",
    "            clf = SVC(C = cVal,gamma = gVal, kernel='linear')\n",
    "            clf.fit(training_matrix, training_response)\n",
    "            valid_pred = clf.predict(validation_matrix)\n",
    "            currVal = get_svm_accuracy(valid_pred, validation_response)\n",
    "            print currVal, gPower, cPower\n",
    "            if optimal < currVal:\n",
    "                optimal = currVal \n",
    "                bestC = cVal  \n",
    "                bestG = gVal\n",
    "            gPower += 2\n",
    "        cPower += 2\n",
    "    return (bestC, bestG)\n",
    "\n",
    "#gridSearch() # - (63, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best prediction accuracy for SVM turned out to be ____."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Linear Regression Model'></a>\n",
    "## 7. Final Results and Concluding Thoughts\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Method</th>\n",
    "    <th>Validation Accuracy Rate</th>\n",
    "    <th>Test Set Accuracy Rate</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Naive Approach</td>\n",
    "    <td>Maria Anders</td>\n",
    "    <td>Germany</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Linear Regression</td>\n",
    "    <td>Francisco Chang</td>\n",
    "    <td>Mexico</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Logistic Regression</td>\n",
    "    <td>Roland Mendel</td>\n",
    "    <td>Austria</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Support Vector Machines</td>\n",
    "    <td>Helen Bennett</td>\n",
    "    <td>UK</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "1. `http://homepages.cae.wisc.edu/~ece539/fall13/project/AmorimTorres_rpt.pdf`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
